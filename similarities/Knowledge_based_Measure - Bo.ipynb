{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import wordnet_ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all documents as every debate paragraphs over all debates\n",
    "all_documents = []\n",
    "import os\n",
    "for filename in os.listdir('../For Against Scripts'):\n",
    "    file = pd.read_csv('../For Against Scripts/' + filename)\n",
    "    for script in file.script:\n",
    "        all_documents.append(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents = pd.Series(all_documents).apply(lambda x: x.lower()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(w, all_documents):\n",
    "    df = sum([w in x for x in all_documents])\n",
    "    N = len(all_documents)\n",
    "    try:\n",
    "        return math.log(N/df)\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "def sim(w1, w2, brown_ic):\n",
    "    ## error will occur when words passed in is invalid word\n",
    "    try:\n",
    "        w1_syn = wn.synsets(w1, pos=wn.NOUN)[0]\n",
    "        w2_syn = wn.synsets(w2, pos=wn.NOUN)[0]\n",
    "        sim_value = w1_syn.res_similarity(w2_syn, brown_ic)\n",
    "        if sim_value > 100:\n",
    "            return 0\n",
    "        else:\n",
    "            return sim_value\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the max similarity between a word and a sentence\n",
    "##     - w: a word in string\n",
    "##     - T: a sentence in string\n",
    "def maxSim(w, T, brown_ic):\n",
    "    return pd.Series([sim(w, word, brown_ic) for word in T.split()]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the similarity between two sentences\n",
    "##     - T1: a sentence in string\n",
    "##     - T2: a sentence in string\n",
    "def sim_Sentences(T1, T2, idfs1, idfs2):\n",
    "    T1 = T1.lower()\n",
    "    T2 = T2.lower()\n",
    "    max_sims_1 = np.array([maxSim(w1, T2, brown_ic) for w1 in T1.split()])\n",
    "    numberator1 = sum(max_sims_1*np.array(idfs1))\n",
    "    denominator1 = sum(idfs1)\n",
    "    max_sims_2 = np.array([maxSim(w2, T1, brown_ic) for w2 in T2.split()])\n",
    "    numberator2 = sum(max_sims_2*np.array(idfs2))\n",
    "    denominator2 = sum(idfs2)\n",
    "\n",
    "    toReturn = (numberator1/denominator1 + numberator2/denominator2)/2\n",
    "    return toReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_result = pd.read_csv('../results_data/final_live.csv')\n",
    "online_result = pd.read_csv('../results_data/final_online.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d20191112\n",
      "Nothing to be removed from for\n",
      "d20191029\n",
      "Nothing to be removed from for\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d20191022\n",
      "Nothing to be removed from for\n",
      "d20190917\n",
      "Nothing to be removed from for\n",
      "d20190802\n",
      "Nothing to be removed from for\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d20190628\n",
      "Nothing to be removed from for\n",
      "d20190418\n",
      "Nothing to be removed from for\n",
      "d20190413\n",
      "Nothing to be removed from for\n",
      "d20190328\n",
      "Nothing to be removed from for\n",
      "d20190304\n",
      "Nothing to be removed from for\n",
      "d20190211\n",
      "Nothing to be removed from for\n",
      "d20190131\n",
      "Nothing to be removed from for\n",
      "d20190116\n",
      "Nothing to be removed from for\n",
      "d20181111\n",
      "Nothing to be removed from for\n",
      "d20181101\n",
      "Nothing to be removed from for\n",
      "d20181011\n",
      "Nothing to be removed from for\n",
      "d20180926\n",
      "Nothing to be removed from for\n",
      "d20180628\n",
      "Nothing to be removed from for\n",
      "d20180626\n",
      "Nothing to be removed from for\n",
      "d20180623\n",
      "Nothing to be removed from for\n",
      "d20180514\n",
      "Nothing to be removed from for\n",
      "d20180502\n",
      "Nothing to be removed from for\n",
      "d20180421\n",
      "Nothing to be removed from for\n",
      "d20180417\n",
      "Nothing to be removed from for\n",
      "d20180327\n",
      "Nothing to be removed from for\n",
      "d20180309\n",
      "Nothing to be removed from for\n",
      "d20180206\n",
      "Nothing to be removed from for\n",
      "d20171207\n",
      "Nothing to be removed from for\n",
      "d20171024\n",
      "Nothing to be removed from for\n",
      "d20171003\n",
      "Nothing to be removed from for\n",
      "d20170928\n",
      "Nothing to be removed from for\n",
      "d20170606\n",
      "Nothing to be removed from for\n",
      "d20170510\n",
      "Nothing to be removed from for\n",
      "d20170406\n",
      "Nothing to be removed from for\n",
      "d20170322\n",
      "Nothing to be removed from for\n",
      "d20170301\n",
      "Nothing to be removed from for\n",
      "d20170208\n",
      "Nothing to be removed from for\n",
      "d20170201\n",
      "Nothing to be removed from for\n",
      "d20170111\n",
      "Nothing to be removed from for\n",
      "d20161207\n",
      "Nothing to be removed from for\n",
      "d20161129\n",
      "Nothing to be removed from for\n",
      "d20161114\n",
      "Nothing to be removed from for\n",
      "d20161026\n",
      "Nothing to be removed from for\n",
      "d20161013\n",
      "Nothing to be removed from for\n",
      "d20160926\n",
      "Nothing to be removed from for\n",
      "d20160913\n",
      "Nothing to be removed from for\n",
      "d20160907\n",
      "Nothing to be removed from for\n",
      "d20160608\n",
      "Nothing to be removed from for\n",
      "d20160504\n",
      "Nothing to be removed from for\n",
      "d20160406\n",
      "Nothing to be removed from for\n",
      "d20160309\n",
      "Nothing to be removed from for\n",
      "d20160301\n",
      "Nothing to be removed from for\n",
      "d20160203\n",
      "Nothing to be removed from for\n",
      "d20160113\n",
      "Nothing to be removed from for\n",
      "d20151203\n",
      "Nothing to be removed from for\n",
      "d20151118\n",
      "Nothing to be removed from for\n",
      "d20151110\n",
      "Nothing to be removed from for\n",
      "d20151102\n",
      "Nothing to be removed from for\n",
      "d20151027\n",
      "Nothing to be removed from for\n",
      "d20151014\n",
      "Nothing to be removed from for\n",
      "d20150916\n",
      "Nothing to be removed from for\n",
      "d20150809\n",
      "Nothing to be removed from for\n",
      "d20150602\n",
      "Nothing to be removed from for\n",
      "d20150526\n",
      "Nothing to be removed from for\n",
      "d20150513\n",
      "Nothing to be removed from for\n",
      "d20150415\n",
      "Nothing to be removed from for\n",
      "d20150331\n",
      "Nothing to be removed from for\n",
      "d20150311\n",
      "Nothing to be removed from for\n",
      "d20150224\n",
      "Nothing to be removed from for\n",
      "d20150211\n",
      "Nothing to be removed from for\n",
      "d20150115\n",
      "Nothing to be removed from for\n",
      "d20141203\n",
      "Nothing to be removed from for\n",
      "d20141113\n",
      "Nothing to be removed from for\n",
      "d20141022\n",
      "Nothing to be removed from for\n",
      "d20141007\n",
      "Nothing to be removed from for\n",
      "d20140930\n",
      "Nothing to be removed from for\n",
      "d20140909\n",
      "Nothing to be removed from for\n",
      "d20140626\n",
      "Nothing to be removed from for\n",
      "d20140507\n",
      "Nothing to be removed from for\n",
      "d20140409\n",
      "Nothing to be removed from for\n",
      "d20140402\n",
      "Nothing to be removed from for\n",
      "d20140312\n",
      "Nothing to be removed from for\n",
      "d20140305\n",
      "Nothing to be removed from for\n",
      "d20140227\n",
      "Nothing to be removed from for\n",
      "d20140212\n",
      "Nothing to be removed from for\n",
      "d20140115\n",
      "Nothing to be removed from for\n",
      "d20131204\n",
      "Nothing to be removed from for\n",
      "d20131120\n",
      "Nothing to be removed from for\n",
      "d20131114\n",
      "Nothing to be removed from for\n",
      "d20131030\n",
      "Nothing to be removed from for\n",
      "d20131018\n",
      "Nothing to be removed from for\n",
      "d20131016\n",
      "Nothing to be removed from for\n",
      "d20130910\n",
      "Nothing to be removed from for\n",
      "d20130809\n",
      "Nothing to be removed from for\n",
      "d20130619\n",
      "Nothing to be removed from for\n",
      "d20130508\n",
      "Nothing to be removed from for\n",
      "d20130417\n",
      "Nothing to be removed from for\n",
      "d20130403\n",
      "Nothing to be removed from for\n",
      "d20130313\n",
      "Nothing to be removed from for\n",
      "d20130213\n",
      "Nothing to be removed from for\n",
      "d20130116\n",
      "Nothing to be removed from for\n",
      "d20121205\n",
      "Nothing to be removed from for\n",
      "d20121114\n",
      "Nothing to be removed from for\n",
      "d20121024\n",
      "Nothing to be removed from for\n",
      "d20121010\n",
      "Nothing to be removed from for\n",
      "d20121004\n",
      "Nothing to be removed from for\n",
      "d20120912\n",
      "Nothing to be removed from for\n",
      "d20120701\n",
      "Nothing to be removed from for\n",
      "d20120508\n",
      "Nothing to be removed from for\n",
      "d20120417\n",
      "Nothing to be removed from for\n",
      "d20120207\n",
      "Nothing to be removed from for\n",
      "d20120110\n",
      "Nothing to be removed from for\n",
      "d20111115\n",
      "Nothing to be removed from for\n",
      "d20111025\n",
      "Nothing to be removed from for\n",
      "d20111012\n",
      "Nothing to be removed from for\n",
      "d20111004\n",
      "Nothing to be removed from for\n",
      "d20110920\n",
      "Nothing to be removed from for\n",
      "d20110907\n",
      "Nothing to be removed from for\n",
      "d20110608\n",
      "Nothing to be removed from for\n",
      "d20110510\n",
      "Nothing to be removed from for\n",
      "d20110503\n",
      "Nothing to be removed from for\n",
      "d20110405\n",
      "Nothing to be removed from for\n",
      "d20110315\n",
      "Nothing to be removed from for\n",
      "d20110215\n",
      "Nothing to be removed from for\n",
      "d20110111\n",
      "Nothing to be removed from for\n",
      "d20101122\n",
      "Nothing to be removed from for\n",
      "d20101110\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-3cedb66b4b1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;31m#print('J against', j)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magainst_main_points\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0msentence_sim_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim_Sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_passage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midfs_against\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midfs_passage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0;31m#print(sentence_sim_score)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mside\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'for'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-123-2f08b891e413>\u001b[0m in \u001b[0;36msim_Sentences\u001b[0;34m(T1, T2, idfs1, idfs2)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#print(numberator1, denominator1, numberator2, denominator2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtoReturn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnumberator1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdenominator1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumberator2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdenominator2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtoReturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "pred_results = []\n",
    "online_winners = []\n",
    "live_winners = []\n",
    "\n",
    "for test_id in live_result.id:\n",
    "    print(test_id)\n",
    "    main_points = open('../Main Points/main_points_' + test_id).read().split('\\n')\n",
    "\n",
    "    break_point = main_points.index(\"Against The Motion\")\n",
    "    for_main_points = main_points[1:break_point]\n",
    "    against_main_points = main_points[break_point+1:]\n",
    "    script_df = pd.read_csv('../For Against Scripts/' + 'for_against_scripts_' + test_id + '.csv')\n",
    "\n",
    "    try:\n",
    "        for_main_points.remove('')\n",
    "    except:\n",
    "        print('Nothing to be removed from for')\n",
    "    try:\n",
    "        against_main_points.remove('')\n",
    "    except:\n",
    "        print('Nothing to be removed from against')\n",
    "    \n",
    "    ## create idfs ahead to avoid duplicated computation in sim_Sentences\n",
    "    ##     - S: the sentence whose idf of each word is to be calculated \n",
    "    ##     - all_documents: document corpus that idf is relied upon.\n",
    "    def idfs_cal(S, all_documents):\n",
    "        idfs = [idf(w, all_documents) for w in S.split()]\n",
    "        return idfs\n",
    "\n",
    "    idfs_for = [idfs_cal(s, all_documents) for s in for_main_points]\n",
    "    idfs_against = [idfs_cal(s, all_documents) for s in against_main_points]\n",
    "    idfs_passage = [idfs_cal(s, all_documents) for s in script_df.script]\n",
    "    \n",
    "    # We have a maximum of 6 main points for each side\n",
    "    sim_results = []\n",
    "    for i in script_df.index:\n",
    "        sim_result_one_row = []\n",
    "        side = script_df.loc[i].side\n",
    "\n",
    "        target_passage = script_df.loc[i].script\n",
    "\n",
    "        for j in range(len(for_main_points)):\n",
    "            point = for_main_points[j]\n",
    "            sentence_sim_score = sim_Sentences(point, target_passage, idfs_for[j], idfs_passage[i])\n",
    "            if side == 'for':\n",
    "                sim_result_one_row.append(sentence_sim_score)\n",
    "            else:\n",
    "                sim_result_one_row.append(-sentence_sim_score)\n",
    "\n",
    "        for j in range(len(against_main_points)):\n",
    "            point = against_main_points[j]\n",
    "            sentence_sim_score = sim_Sentences(point, target_passage, idfs_against[j], idfs_passage[i])\n",
    "            if side == 'for':\n",
    "                sim_result_one_row.append(-sentence_sim_score)\n",
    "            else:\n",
    "                sim_result_one_row.append(sentence_sim_score) \n",
    "        sim_results.append(sim_result_one_row)\n",
    "        \n",
    "    online_winner = online_result[online_result['id'] == test_id].winner\n",
    "    live_winner = live_result[live_result['id'] == test_id].winner\n",
    "    pred_result = pd.Series([sum(row) for row in sim_results]).dropna().sum()\n",
    "    \n",
    "    online_winners.append(online_winner)\n",
    "    live_winners.append(live_winner)\n",
    "    pred_results.append(pred_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_winners = [x.tolist() for x in online_winners]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_winners = np.array(online_winners).reshape(1,-1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_winners = online_winners[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_online = [x != 'undecided' for x in online_winners]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results_bool = (np.array(pred_results) > 0)\n",
    "pred_results_bool = np.where(pred_results_bool == True, 'against', pred_results_bool)\n",
    "pred_results_bool = np.where(pred_results_bool == 'False', 'for', pred_results_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "## online accuracy\n",
    "valid_online = pd.Series(online_winners)[filter_online]\n",
    "valid_result = pd.Series(pred_results_bool)[filter_online]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5428571428571428"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(valid_online == valid_result)/len(valid_online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#live_winners = [x.tolist() for x in live_winners]\n",
    "#live_winners = np.array(live_winners).reshape(1,-1).tolist()\n",
    "#live_winners = live_winners[0]\n",
    "filter_live = [x != 'undecided' for x in live_winners]\n",
    "## live accuracy\n",
    "valid_live = pd.Series(live_winners)[filter_live]\n",
    "valid_result = pd.Series(pred_results_bool)[filter_live]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5213675213675214"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(valid_live == valid_result)/len(valid_live)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
