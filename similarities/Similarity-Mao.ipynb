{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Text Similarities\n",
    "\n",
    "This document focuses on single debate and computes similarities between debate text and for/against main points. We aim to find the correlation of similarity scores and win/lose results. \n",
    "\n",
    "Steps:\n",
    "1. Choose a single debate to be analyzed\n",
    "2. Fetch main points and debate speeches from both sides\n",
    "3. Compare both sides's similarity towards the main points\n",
    "\n",
    "This approach can be extended to all debates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fetch Single Debate\n",
    "\n",
    "Debate is selected with its unique debate ID (d+date) and index in the meta data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "meta = pd.read_csv('../Meta Data/metadata_appended_main_points.csv', index_col='id')\n",
    "result = pd.read_csv('../results_data/final_live.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default debate id and index, can be a different one\n",
    "debate_id = 'd20171003'\n",
    "debate = meta.loc[debate_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debate ID:  d20171003 \n",
      "Topic:  Western Democracy Is Threatening Suicide\n",
      "\n",
      "FOR main points:\n",
      "1 ) xenophobia, racism, and nationalism are on the rise. from support of far-right candidates in france and brexit in europe to the rise of donald trump in the u.s., people around the world are embracing policies and attitudes that are inconsistent with liberal democracy.\n",
      "2 ) the liberal world order is losing ground. long a beacon of democracy around the world, the united states is turning its back on global institutions and leaving room for alternative powers, such as china and russia, to seize influence.\n",
      "3 ) fed up with the economic challenges of globalism and dismayed by the power of the political elite, westerners are embracing social change over political stability and – increasingly – considering alternatives to elected democratic leadership.\n",
      "4 ) with his executive orders on immigration, attacks on the free press, condemnation of court decisions, and firing of james comey, president donald trump has challenged democratic traditions and exposed weaknesses in america's political system.\n",
      "\n",
      "AGAINST main points:\n",
      "1 ) the populism and nationalism that brought about donald trump and brexit does not pose a threat to liberal democracy. rather, these events represent the legitimate exercise of power by frustrated voters who feel their nations have gone off-course.\n",
      "2 ) the trump administration has strengthened democratic institutions both at home and abroad. rather than ceding power to an unconventional leader, institutions ranging from global governance organizations to local courts have gained popular support and kept the white house in check.\n",
      "3 ) a resurgence of far-right ideologues has energized citizens around the world to engage in the democratic process. through support of establishment political parties and civil society organizations, these citizens are strengthening their democracies and combating the xenophobia and racism that has long-been present in their countries and in politics.\n",
      "4 ) western democracy is not merely defined by american global leadership. america's allies, including france and germany, are poised to assume the role of safeguards of the liberal world order as the united states turns inward.\n"
     ]
    }
   ],
   "source": [
    "# This prints a nicely formatted single debate info from meta\n",
    "print('Debate ID: ', debate_id, '\\nTopic: ', debate['title'])\n",
    "\n",
    "# Also constructs a list of main points for both sides\n",
    "fmains = []\n",
    "print('\\nFOR main points:')\n",
    "for i, fmain in enumerate(ast.literal_eval(debate['For_Main_Points']), start=1):\n",
    "    fmains.append(fmain.lower())\n",
    "    print(i, ')', fmain.lower())\n",
    "    \n",
    "amains = []\n",
    "print('\\nAGAINST main points:')\n",
    "for i, amain in enumerate(ast.literal_eval(debate['against_Main_Points']), start=1):\n",
    "    amains.append(amain.lower())\n",
    "    print(i, ')', amain.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINNTER:  for\n"
     ]
    }
   ],
   "source": [
    "print('WINNTER: ', result.loc[debate_id]['winner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Speech Text Cleaning on Single Debate\n",
    "\n",
    "Fetch the speeches from both sides of a single debate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR side speeches:  30\n",
      "AGAINST side speeches:  30\n"
     ]
    }
   ],
   "source": [
    "# Fetch the debate scripts\n",
    "scripts = pd.read_csv('../For Against Scripts/for_against_scripts_' + debate_id + '.csv')\n",
    "\n",
    "# Construct lists of the speeches by both sides. \n",
    "flist = [s for s in scripts.loc[scripts['side'] == 'for']['script']]\n",
    "print('FOR side speeches: ', len(flist))\n",
    "alist = [s for s in scripts.loc[scripts['side'] == 'against']['script']]\n",
    "print('AGAINST side speeches: ', len(alist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning:** I'd tokenzie all words and sentences, remove puntuations and stopwords. Refer to the cleaning scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# This returns cleaned list of words from given speech string\n",
    "def cleanwords(speech, debug=False): \n",
    "    # tokenize words without punctuations\n",
    "    words = word_tokenize(speech.translate(str.maketrans('', '', string.punctuation)))\n",
    "    # remove meaninglesss words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    cleaned_words = [w.lower() for w in words if w.lower() not in stop_words]\n",
    "    # remove duplicate words\n",
    "    cleaned_words = list(set(cleaned_words))\n",
    "    if debug:\n",
    "        print('Number of cleaned words:', len(cleaned_words), ', removed words:', len(words) - len(cleaned_words))\n",
    "    return cleaned_words\n",
    "\n",
    "# This returns cleaned list of sentences from given speech string\n",
    "def cleansents(speech, debug=False):  \n",
    "    # tokenized sentences without punctuations\n",
    "    sentences = sent_tokenize(speech)\n",
    "    sentences = [s.translate(str.maketrans('', '', string.punctuation)).lower() for s in sentences]\n",
    "    if debug:\n",
    "        print('Number of cleaned sentences:', len(sentences))\n",
    "    return sentences\n",
    "\n",
    "# This returns list of cleanwords and cleansents from list of speeches\n",
    "def clean(speeches):\n",
    "    cwlst = []\n",
    "    cslst = []\n",
    "    for s in speeches:\n",
    "        cwlst.append(cleanwords(s))\n",
    "        cslst.append(cleansents(s))\n",
    "    return cwlst, cslst\n",
    "\n",
    "# This retuns cleanwords and cleansents from main points\n",
    "def mclean(mains):\n",
    "    speech = \"\"\n",
    "    for m in mains:\n",
    "        speech += m + ' '\n",
    "    cwords = cleanwords(speech)\n",
    "    csents = cleansents(speech)\n",
    "    return cwords, csents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The matrix of cleaned words/sentences of each speech from both sides\n",
    "fcwlst, fcslst = clean(flist)\n",
    "acwlst, acslst = clean(alist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cleaned sentences and words from main points as one single speech\n",
    "mfcwords, mfcsents = mclean(fmains)\n",
    "macwords, macsents = mclean(amains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Similarities\n",
    "\n",
    "This section tries multiple similarity measures to compare speeches with main points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Jaccard Similarity\n",
    "Naive implementation that only checks the intersection of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This computes the intersection; input are two lists of words\n",
    "def jaccard(query, document):\n",
    "    intersection = set(query).intersection(set(document))\n",
    "    union = set(query).union(set(document))\n",
    "    return len(intersection)/len(union)\n",
    "\n",
    "# This averages the jaccard similarities between each speech and the main point\n",
    "#    - cwlst: clean word matrix\n",
    "#    - mcwords: cleaned word list of main point of a side\n",
    "def jaccard_avg(cwlst, mcwords):\n",
    "    s = 0\n",
    "    for cw in cwlst:\n",
    "        jac = jaccard(cw, mcwords)\n",
    "        s += jac\n",
    "    return s / len(cwlst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICT: for 0.006642677729184979\n",
      "ACTUAL:  for\n"
     ]
    }
   ],
   "source": [
    "# Most basic prediction\n",
    "fsim = jaccard_avg(fcwlst, mfcwords)\n",
    "asim = jaccard_avg(acwlst, macwords)\n",
    "if  fsim > asim:\n",
    "    print('PREDICT: for', fsim - asim)\n",
    "else:\n",
    "    print('PREDICT: against', fsim - asim)\n",
    "print('ACTUAL: ', result.loc[debate_id]['winner'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
