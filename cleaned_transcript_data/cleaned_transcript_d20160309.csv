,Speaker,Script
0,Andrew Keen,"Well, I certainly expect a better outcome, because our voters are humans rather than machines . So I'm trusting you to do a good job tonight, all of you out there."
1,James Hughes,"Transhumanism is the belief that our descendants will be strange and wonderful, that humanity is a work in progress, that we can use technology to be smarter and happier and live longer and healthier."
2,James Hughes,"My partner is the renaissance woman, Martine Rothblatt."
3,Martine Rothblatt,Thank you.
4,Jaron Lanier,"Hey. I can't possibly be talking about artificial intelligence right now without remembering Marvin Mi nsky who is my dear mentor who just passed away very recently. And Marvin was infinitely sweet to me. And decades ago we would have the same argument, more or less. The spirit was a little different though because back then it seemed a little clearer where the line was between the philosophy and the technology. So Marvin would argue the hard AI position and he was largely the author of a lot of the ideas that I suppose I find myselfarguing against now. Oh, but he loved to argue. And I just remember these arguments with such joy. And I wish that people who have come along since retained that sense of open -mindedness and didn't take it all so seriously. I feel as though the ideas about AI have evolved into something of an o rthodoxy, where they started off as an element of good humor and camaraderie. And I regret seeing that. And I wonder if similar progressions happened with some of our great religious and philosophical traditions. It's been interesting to see it. So, fr om my perspective, as a practitioner, I must add, I -- my friends and I sold the Machine Vision company to Google. I'm in the thick of it. I'm not anti -AI algorithms. I make them, you know ? And I'm fascinated by them. So, from my perspective, there has to be a division made between the work itself -- the engineering and the science on the one hand, and then on the other, the storytelling about it, the narrative that we have about it, the fantasy life of it -- perhaps the religion of it. These are two distinct things. It doesn't mean one is good and one is bad, but they're just different sorts of beasts. So, to say, ""What is the promise of an area of research?"" We fundamentally don't know. It's research. It's basic research. We just ob served gravity waves for the first time. Does that mean we'll suddenly have anti -gravity devices ? Well, you know, maybe someday. We have absolutely no clue what we're going to discover. And in the same sense, we currently don't know what a thought is, in terms of scientific description. We can kind of find collections of neurons that seem to active at certain times. It's provocative. We can replicate certain functions. It's provocative. Do we understand how brains work? No. And yet, the work is fascinating, the work is important. A lot of our existential threats as a species involve great complexity. We wouldn't even know about climate change if it weren't for masses of sensors networked together that would allow us to get a big picture. We would be blind to our perils without it. So, to say that there isn't promise in pursuing science information systems and sensing systems, and algorithms to understand it all, like the -- it would be crazy to argue that. I can't imagine any serio us person taking that position. So, the only form of this proposition that I can possibly argue against is this other realm, th e fantasy life, the culture. And here, I do find myself not enjoying it. And I'd like to just say a few things about where it fails. And this is rather personal, perhaps , but I will share it with you. One issue is, as an engineer, if I say, ""Oh, I'm making this algorithm into something that's intelligent,"" or conscious, or whatever -- or cultured, or whatever it is -- form an engineering point of view, I can't define those terms. So, it makes me nuts. I have no baseline. And this is a really crucial, crucial point. A lot of the systems you call smartsystems are kind of derailed from the empirical process. As an example, I frequently review student work. And some people say, ""Well, here I've made an intelligent system. For instance I saw a machine that makes beverages."" And it had quite fancy software. And it's to choose the beverage for a person. People found it hard to use. And what I'm saying is nobody cares how fancy your algorithm is. The only thing you can measure is how well the machine works, in the end. So, if you don't define a baseline that's measurable, you're off in fantasy land. And this -- t his might seem like a bit of a wonky point to you, but it's absolutely crucial. Engineering without clear concrete grounding in reality goes off the rails and does become dangerous. So, for a more important example, if you have some sort of d rone that goes around killing the wrong people, whether it did so because of an intelligent algorithm that made the wrong decisions, or just because it's malfunctioning -- who cares ? That distinction is not actionable or meaningful. The only thing that m atters is whether people can use machines that we design responsibly, with intention. That is the meaningful question. Everything else is fantasy. And so, adding this whole layer about power transcending and everything, it's -- it just confuses matters. There is an economic angle to it. I love automatic machine translation. I love that you can go online and get something converted to German automatically. My own lab does that. We have real -time Skype translation now. But the only way we do it is by scraping the efforts of millions of translators who don't even know what's happening to them to get the examples. And in order to have the fantasy that this thing is a free -standing creature, we're pretending t hese other people don't exist and we're creating potentially a massive wave of technology -driven unemployment that doesn't need to happen. We shouldn't be shrinking the economy over a fantasy, if we just acknowledge that the people are just contributing in new ways. Their Go games are informing a Go algorithm. Pay those people instead of having to resort to some sort of weird socialist solution. You know, this fantasy of these artificial creatures makes us ignore our own lives, our own contributions. And so, it creates a needless eco nomic peril -- absolutely silly. But then I have to say something else. I understand that for many people, these ideas of AI have become very tender and dear to them. They've become part of the way they think about their lives, and their loved ones, and their future. They think they might become immortal or something. I have absolutely no interest in ridiculing or opposing that. I absolutely believe in religious free dom, and I would never, never, never speak against somebody's beliefs. I respect them. All I askfor is the separation of church and state. Without a separation of church and state, there can be no religious freedom. Never more true than when it comes to AI."
5,Martine Rothblatt,"Thank you. It's my pleasure to speak on -- in f avor of the motion that we should trust the promise of artificial intelligence. And in thinking about this question, I thought the major theme sort of orbited around three key words. And these words came to me when I asked myself, ""Well, what do we mean by the promise of AI?"" As Jaron said so well, there are so many different words thrown around. Define your terms. So, to me, the promise of AI revolves around the three terms: replication, and application, and then fascination. So, with regard to replic ation, the promise of AI is that we will be able to replicate the human mind. And that is a -- you know, a startling statement. It's a -- kind of an awe -inspiring statement, because, I think, for most of us, for all the beauty and credulousne ss that we have about life around us, human minds are just like the most awesome things anybody can imagine. So now we're talking about replicating. The promise of AI is that we can replicate the human mind. But I believe that this promise will be fulfilled because we're not talking about replicating the structure of the human brain with the hundreds and billions of different subtle neural connections, of which, as Jaron says, we have slight knowledge. Instead, we're talking about replicating the functi on of a human mind, much in the way that we're not able to replicate a bird, that we're able to replicate flight. And certainly, the flight that we have with an airplane or helicopter is not the same as the flight of a hummingbird, but it's flight nonethe less. And the promise of artificial intelligence is not that we will replicate every little nuance of a biologically -human mind, but it will be a replication of human consciousness,nevertheless. The second term that to me kind of embraces the concept of the promise of artificial intelligence is the term application. So, from replication to application. What do we mean? The promise of AI is that this stuff will be good for things, that we will really have uses for artificial intelligence. Otherwise, why bother developing it? And in fact, lots of people all over the world are enthralled with the promise of AI. We talk about it being helpful in helping to navigate our airspace, our ground space, our traffic. We talk about it being helpful in terms of health care, discovering cures for new diseases -- for -- new cures for diseases. The application of artificial intelligence that I find most amazing is the application of it to diseases of the mind, specifically diseases such as dementia and Alzheimer's. And if we are able to go ahead and de velop artificial intelligence so that it can serve as a kind of mental wheelchair, something that a person that has lost a lot of the faculties of their mind can instead rely upon because it provides a pretty damn good replication of their thoughts, of their responses, of their ability to recognize loved ones and respond to one, the ability to talk and form sentences and have an interior sense of reality. That promise of artificial intelligenc e, I believe, will come to pass because there's an enormous demand for it. Everybody who thinks about it wants to contribute to it in some part, small or large, depending on their capability and their skills. So I think it's all of the incredible applica tions of AI that will pull AI forward into the future and realize its potential. Finally, once we've replicated our minds and once we've been able to develop applications that makes these AIs so useful to us and such an important part of our l ife, far more than a personal digital assistant, far more than a great educational tool. In fact, it's a mind. It's something that we develop a relationship with. The next thing that comes to me is fascination. We will love these AIs. We'll love them in the same way that we love our cats and our dogs, that we love our friends, ones that we see distantly or the ones that we see frequently, because if it is a replicated human mind it'll have all the cool features of human minds, being able to answer ques tions, be able to really frame the rest of the sentence before a sentence is finished, be able to feel empathy and when we're sad help us feel better and we're happy join in that joy. Now part of the fascination of AI is that I believe the fas cination part will only attach to the friendly AI, and this is why I believe when people offer a promise of AI as it being friendly and not be kind of the scary AI that you see out of Hollywood, I think that is a reality that we can expect to pass. Our fascination with AI will be for the AI that is friendly to us. We have no fascination with cars that don't stop when you put on yourbrake. In fact, we run from them. We have no fascination with stoves that when you turn on the stove they explode. We don't buy those. AI will arise in a natural environment in which humans are the agents of selection. We will select for the friendly AI and we will stamp out the unfriendly AI. So I believe that the promise of AI will be a good one and we should believe it because the environment in which AI evolves will be a human selection environment and the mass activities of hundreds of millions of people will select for the friendliest AI. This does not mean that there will never be bad AI. This does not mean that there will never be broken applications and that some replicated minds will be as messed up as people who are suffering from something like an antisocial personality disorder, but ultimately it will be the efforts of millions of individual hacke rs throughout the world in a decentralized process drawn forward by the promise of the positive applications of AI, such as helping to save relatives and loved ones that will result in a beautiful AI that will be the fascination of all of us and therefore will be a definite survivor in the future to come. Thank you."
6,Andrew Keen,"Thank you, John. So this is a big deal. V ery, very big deal. You just heard Martine given an extremely good speech in which she talked about replicating the human mind. Nobody laughed. You all sat there. You took that seriously, the notion that wecan replicate our minds, that they'll live forever in the cloud or some other digital space is not outrageous. Jaron might argue it's not practical at this very moment, but it isn't outrageous. This is a huge issue. The notion that we can replicate ourselves, our intelligence, our bein g, our identities, our souls, whatever other word you want to use. So this is not a debate irrel evant to the future. Indeed, it is probably the central debate of the 21st century for better or worse. Important to remind ourselves of this debate, we are not talking about trusting artificial intelligence. That is not what Jaron and I are arguing against. We're arguing that we shouldn't trust the promise of artificial intelligence. We're not against the technology in itself. That is not the subject of the debate tonight. Jaron talked about the Separation of Church and State. We talked about this over lunch today. What I think he means is that we need to separate the science from the belief. And, all too often in this enormously important debate about whether or not we should trust the promise of artificial intelligence, of smart machines that are indeed so smart that they are able to replicate us as a species both collectively and individually, Jaron is arguing that we're muddling them up. Jaron is arguing that there's too much state in the church and too much church in the state. And the philosophers are intervening. The philosophers are telling us that this science is good, is moral, is liberating. And that's, I think, the argument that our team is making, or certainly that I am making. It is that there's a problem not with the technology but with its promise, with the ideology around that technology. We already heard a little bit about it from Martine who talked about so mething called ""good versus bad "" AI. I have no idea who she can make those moral judgments. I have no idea how you moralize I -- AI unless you humanize it, which itself is deeply problematic. But the problem today, I think, is that the philosophers ha ve got hold of this technology and they're presenting it as liberation theology. At least some of them are. We've been through this, of course, before in the middle of the 19th century in the midst of industrial revolution. The philosophers got hold of that. Marx thought the Industrial Revolution would free us from work, would free us from inequality. He was of course entirely wrong. And we have a similar kind of discourse, a similar kind of philosophical debate emerging today about the promise of AI. We're told that this AI will liberate us from our bodies. That's really what Martine is saying, that we'll live forever, that our minds will be replicated, they'll be up in the cloud. We'll never die. If we go insane, if we get Alzheimer's , somehow our essence, our kernel will remain. We're told that AI will liberate us from work because we'll have these smart machines which will do our labor for us. They'll drive our cars. They'll do our medicine. We'll go to an artificial intelligent agent, an algorithm to be taught. Perhaps one benefit is we'll avoid lawyers, but apart from lawyers, I worry deeply about the impact of AI on the expert professions of the 19th and 20th century. T he very professions that represent the backbone of our economy. The problem with this promise is it's not being thought through. It's being thought through philosophically, idealistically. We're not thinking about it in the context of the real world. We're not thinking about it in the way in which these technologies -- and we've already had a great deal of example of this during the digital revolution, that in spite of all the great promise of the Internet, and I've written extensively about this -- in spite of all its great promise of democracy and egalitarianism and opportunity, it's actually created new elites. The promise of artificial intelligence, these grand philosophical frameworks, they forget about the realities. Jaron already talked about the art -- the AI of language being owned and peo ple of labor being appropriated. Who is going to own these platforms ? Will it be Google ? We all love Google, of course, in some ways. And yet, Google is the largest, the most valuable, the most powerful company in the world. Google are the ones who just made the breakthrough when it comes to this artific ial agent being able to play Go. Google is pouring billions of dollars into AI, as is Facebook, as is Amazon, as are the other giants of Silicon Valley. Do you trust these guys to benefit mankind? Do you think they care about us ? These aren't bad people or bad companies, but they're focused on profit. They're focused on monopoly. They're focused on owning that technology. We haven't t hought this stuff through. The promise is scary. The promise is that the technology is moving way faster than we are -- politically, culturally, existentially. We're not ready for this yet. We're not ready to replicate ourselves, whether it 's in 50 or 100 years. We haven't thought it through. We can't imagine the cultural, the social, the economic impact. We haven't thought about AI and the way it will destroy labor, destroy jobs. What are we going to do when we have these machines that do everything for us ? How are we going to create value ? How are we going to feed and clothe ourselves in a world where all this technology will be owned by increasingly monopolistic companies ? So, we can't, at themoment, trust AI. We can't trust its promise. One day, perhaps. But there are a lot of problems still to be resolved. And for the moment, I would strongly argue that you should not trust the promise of AI. Thank you."
7,James Hughes,"So, it's been very useful. We've narrowed down to, I think, what is an intelligible question, because obviously, Martine and I don't want to defend the most extreme hyperbole in this debate. But there is an ideological question around promise. And it's an ideological question that I would frame as the promise of human intelligence itself. And that is that artificial intelligence is a crystallization, a condensation, a manifestation of human intelligence, an extension of our capacity. And the promise is the same promise that we have been suggesting since the Enlightenment, that human beings, by taking control, by understanding how we think, and understanding the world -- that we can take control of the natural, and political, and social circumstances that determine our affairs and make a better world. Now, the anarchist philosopher John Zerzan , I think, has the most trenchant critique of this. He thinks we went off the rails when we invented symbolic thought. As soon as we began to have lan guage, we were downloading the contents of our minds onto external storage media and uploading them again through our eyes -- we became cyborgs. That was the beginning of the end of the human project. I would argue that if you share my intuition that it' s better to be alive in the 21st century than to have been one of our hunter -gatherer or peasant ancestors, an intuition that it's better not to have a gutful of intestinal worms, better to live to 80, better to have literacy, better to be less likely to b e killed in a violent death, less likely to live in a life of slavery and oppression -- there is something about modernity, and this promise of the Enlightenment, that I think we should explore. And artificial intelligence, I would argue -- I have a slightly different definition that Martine does. I would argue that artificial intelligence has been with us for a while. Artificial intelligence can be reframed as the codification of the way that we do things together. Civilization is a form of artificial intelligence. It's what allows us to build cathedrals, and aqueducts, and banking systems. It's what allowed us to create laws and universities, and standard operating procedures. And today, that crystallization is taking the form of workers figuring out how to make things faster, and better, and smarter. And yes, change in the nature of work and ways that we should discuss. Today, artificial intelligence is applied to our genomes, to our healthcare systems, to trying to figure out how to diagnose and treat disease in ways that yes, no one physician or nurse will ever be able to comprehend, that we will be able to put in the hands of every healthcare provider and in the hands of ourselves. Those tools which will allow us the empowerment of understanding our own bodies. And this AI today is allowing us to understand the ecosystem, allowing us to understand the myriad of consequences that we are wrought -- that we have wrought on the ecosyste m, to mitigate, to predict, and to reverse those trends. It is also armies figuring out who to kill and how to kill the most efficiently. It is also advertisers and totalitarian governments figuring out how to suppress dissent and how to manipulate opini ons. It is stockbrokers trying to figure out the best ways to exploit workers and accumulate wealth into the hands of the .1%. So, reason and technology can be applied to all these different ends. And the question of the difference between one end and t he other is a value difference. It is a difference that comes out of the values, as I said, of the Enlightenment. If we fight for free and equal societies in the future, the applications of technology -- including artificial intelligence, will be applied in free and equal ways. But our decisions to be pessimistic about artificial intelligence will have no effect on the application by China or North Korea, or other authoritarian regimes. It is our own embrace in liberal democracy of these pow erful tools, making our society as strong and as effective as possible that will determine its future. So, future AI will allow us to understand the complexity of the genome, unlock health and longevity for our children. It will not determine whether the re's universal access to health care. That is on us. Future AI will allow us to displace routine labor and make possible abundance and leisure for all. But it will not tax the rich. It will not determine if we create a safety net, and universal basic income so that we can all benefit from that universal abundance. That is on us. Future AI will allow us to make better collective decisions, to understand the consequences of our actions. But it will not determine whether we have a totalitarian governmen t or a democratic one. That is on us. Focusing on AI as either a panacea or a cause of social ills is a distraction from the political project that will allow us to use AI and all technologies for good versus ill. It's the flip side. Technol ogy itself does not determine these outcomes. We need to focus on creating the political contexts so that these powerful tools, the productive tools that we've been working on for tens of thousands of years, will be applied in the best possible way. So, I urge you to vote against this proposition, the proposition that we not trust the promise of AI, because if you do vote for it, you are voting against the promise of human intelligence itself. Thank you. John Donva n: Thank you, James Hughes. And that concludes Round 1 of this Intelligence Squared U.S. debate, where our motion is Don't Trust the Promise of Artificial Intelligence. Now we move on to Round 2. And in Round 2, the debaters address one ano ther in turn and they take questions from me and from you, our live audience here in New York, at the 92nd Street Y. The motion is Don't Trust the Promise of Artificial Intelligence. We've heard Jaron Lanier and Andrew Keen argue that ""don't trust"" side. They're saying that the central debate of the 21st century will be this one -- that they are not against the technology itself, but they are against the promise, as it has been laid out. They just say that the implications of this world of AI are not be ing thought through, that -- it's less about the technology, actually, than about a belief system -- and a self -deluding one, they say, at that. They also point out that most of us -- or those of us who are in the expert classes are very likely to be out of a job, that the whole issue has been oversold. The threat to expert professions is real, and that the promise itself is actually scary. The team arguing against the motion -- and that is to say, they are arguing to trust it -- Martine Roth blatt and James Hughes -- they are actually describing artificial intelligence, when all is said and done, really, as no more than a set of tools -- tools equal to other tools that we have used throughout history. They say that the promise of artificial i ntelligence itself is obvious. It's the promise that the human being can create technology that can make a better world, not a new story. They laid out the vision of replicating a human mind, not in its structure, but in its function. And they say that an artificial intelligence -- if managed by us, and the choice to manage is ours, has the potential to be good, to be useful, to navigate, to cure -- especially to cure diseases ofthe minds, and that it can evolve in an organic and friendly way. So, what we have here is obviously already a discussion, and quite a complex one that is as much about physics as it about metaphysics, and as much about technology as it is about philosophy. And we're going to cut through -- cut some of the arguments that have been made into smaller pieces and present them again to take some of what each debater has said to the other side. And I want to take first to Jaron Lanier -- your opponents have said, quote unquote, ""We will love the artificial intelligences in our lives."" A really powerful assertion of their bottom line that what's there has great promise. It's going to do great good. We're going to become comfo rtable. We're going to become familiar. They will not be alien. They will be part -- something that is part of our world such that we are glad they are there and they are not unnatural. Will we love the artificial intelligences ? Or at least can you respond to your opponents ’ assertion to that point?"
8,Jaron Lanier,"You know, people are -- we're social. We want to be decent and if we're presented with an artificial character, even the ones that exist today, the Siri or the Cortana, we'll be deferent to them. We'll give them a shot. We find it funny. They're cute. And it can be harmless. If you take it too seriously the problem is that you kind of lower yourself to make the computer seem smarter and we see zillions of examples of this. A big one going on now in education i s teaching to the test because the -- you know, you teach to make yourself look good to the algorithm rather than the actual teaching and the algorithm doesn't quite capture it, and that's just one example of many. I'd like to respond in sort of an unusua l way. If you're interacting with Siri or Cortana you might think well, I'm not that different. I'm just a more complicated version of a Siri, in virtual reality this other technology you might be familiar with, I've had exactly the opposite experience. When you're in VR you can turn into some weird creature. You can turn into some weird crab or something and the whole world can change and yet you remain there hanging and I feel as if you notice that your consciousness is this real thing. And I find th at experience just amaz ing. When everything becomes mutable suddenly you realize wow, there is some consciousness thing that's not j ust mechanism, at least to me, and I understand this is a personal belief and we can argue ourselves into the ground round and round about this thing. But what I want to say is that if what technologists are doing is telling people hey, you're not so special, our machines are just like you, we shouldn't be surprised if people then respond by saying well, we don't trust your medicine. We don't trust your modernity ,and I see kind of a unified backlash against arrogance in everything from the anti -vaccine movement to fundamentalist --"
9,Martine Rothblatt,"Thanks. I have no doubt that we will love o ur AIs just as much as we love our pets, which we also create and end up making themselves into a relationship with us. I could not disagree more with Andrew. I mean, I just imagine that he's creating AIs , this fearful creature that will take our jobs away and it reminds me of somebody standing up in the middle of the 15th Century and saying you know, don't trust the promise of the printing press. The scribes shall have nothing to inscribe. And instead -- and you could paint this whole same parade of horribles, you know, the church will control all the printing presses. Instead we've had a of cognization. We have a new type of person called a bibliophile that loves books and we will have AI philes that will love our AIs. This is, as James said, an enormously empowering and liberating force of AI, and what's most important is that we the people make sure that access to AI is available to everyone and since it will be the hackers, millions of them, d ispersed throughout the world that create this AI out of open source software, I think there is nothing to fear and I would argue against the motion."
10,Andrew Keen,Sorry. Say that again. John Donvan:Was -- were you fairly characterized there ? Are you against printing presses ? Or would you have been ?
11,Andrew Keen,"As a writer absolutely. So, yeah, this is a typical kind of argument that we always fall into in these kinds of debates. Jaron and I will say we have to worry about this stuff. We have to worry that it's not doing what it says it's going to do. And then someone like Martine will come along and say oh, you're just whiners, pessimists. Just look at history. Just look at the history, for example, of the printing press. I don't know how many jobs, by the way, the invention of the printing press caused and one of the consequences , of course, of the printing press was the reformation and the Hundred Years War and a lot of other kind of suffering. So, it's a rather muddy consequence firstly. That's the first problem. The second problem is more substantial. Because he's making an evangelical spiritual argument. His argument is hopeful. He's saying well, in the past it's always worked out okay, so it will work out again in the future. And he's absolutely wrong when it comes to technology and jobs. The fact is most major economies, most researchers, most people who spend their living figuring out what we're going to do in this world cannot figure out what people are going to do. He talks about cuddly AIs. That's not a job. There's no labor there. He talks about open source , absolutely nonsense. Open source technology has had no successful in today's digital world. The four largest companies in the world today, the four most valuable companies in the world today are Facebook, Google, Microsoft, and A pple. And these four companies are the owners of the platforms of our networked age. Where's open source at ? Open source is just another ideological dream. It never happens and it -- I doubt it will ever happen."
12,James Hughes,"Sure. Well, see, I believe in technological unemployme nt. It's actually -- I've been trying to make the argument for a decade now that -- of the inevitability of technological unemployment and that we need to start anticipating it. It's actually a hard argument to make right now because employments beginning to pick up again. But I believe in this inevitability. But I'm one of those lefty folks who I've heard the last 200 years think that eventually freeing us all from wage slavery might be a good idea. And that if, in fact, people started to see that -- the inevitability of the elimination of work, that we might all wrap our minds around the concept that there might be something better to do than all have wage slave jobs. Just as we wrapped our mind around social security and Medicare and Med icaid and the British National Health Service and so forth, the progress of social welfare legislation is, yes, that bad stuff happens like the industrial revolution and then we responded. So I think that we have to sort of imagine that we'll be able to do that again because people are already talking about what the necessary response is to technological unemployment should be."
13,James Hughes,"Like to see go away ? I don't -- I think there is probably no definition of futility of it other than -- no worse definition than knowing that the machine next to you could do the job that you're doing faster, better, and safe r, but that you're forced to do it because somebody says, ""You can't use that machine."" So, yes, I think in the future there will beall kinds of machines that do all the jobs. I basically -- I think that everything that we do will eventually be done bet ter and faster and safer by machines. But the things that are most immune right now are the creative jobs. So, you know, my daughter's an opera singer. She's probably relatively immune. I -- you know, if opera could be replaced, it would ha ve been replaced by record players and radio a long time ago. So I think, ye s. I think there will be many things that will be replaced. And what it will do is free us up like Andrew proposed to the Marxian vision that we'll be able to be farme rs in the morning and poets in the afternoon if that's what we want to do, a life of true choice. That's the vision of the future I have."
14,Jaron Lanier,"So, look, there are two problems with this. First off, there's a pheno menon I call, ""premature mystery reduction,"" which is when we pretend we have something working that we really don't. So right now, most AI actually depends on scooping up things that people do, including the Go program today which is looking at people's Go games, and the machine translation example. Now -- we want to pretend that there's this AI behind the curtain that's freestanding. But, actually, there's millions of people there, too. Now, the problem with saying, ""Well, we'll ju st pay everybody a basic income and then pretend they're not valuable,"" when they are is -- it's -- first of all, it's a lie. Secondly, it --"
15,Jaron Lanier,"It's a lie because they're still needed. I mean, this is like crazy."
16,Jaron Lanier,"Well, he's wrong, technically. I'm sorry I have to pull that on you. The truth is that in order to make machine language work, you have to scrape millions and millions of real translations every single day to keep up with current events and frameworks. So what -- so you're factually wrong to say that they're not needed. Now, if someday -- you could say, ""Well, somebody maybe they wo n't be needed."" But, you know, the problem ofthat is this premature mystery reduction. I mean, yeah, someday we might be able to float because we understand gravity better o r something. I am an optimist. I don't want to believe that we'll always be stuck with our current level of knowledge. So I'm -- in a sense, I'm a transhumanist. But I just believe that it's a fundamental unknown what the timeline is. That's what science is. Science is what we don't know. So we don't know. A nd so we shouldn't pretend we know. That's lying to ourselves. It's undignified. It's petty. It's silly. It's childish. But also -- I'm sorry, but -- you know, but -- -- the other -- the other --"
17,James Hughes,"But there are things -- J aron Lanier: But, but, but, but, but, but, but no, no, no. There's a peril. T here's also great peril in what you're suggesting. If we say, ""Instead of taking the dignified path and admitting that people are still needed, if we pretend they're not needed and then we have some agency that doles out basic income to them as if they weren't needed, you really think that thing's not going to be a magnet for corruption? Every history lesson teaches us that, that's a huge peril. J ohn Donvan: Okay, I'm going to break in there."
18,Jaron Lanier,Don't step into that problem.
19,Martine Rothblatt,"we’re down talking about facts and figures here, because I don't think that the facts support the idea that new technological innovation, such as AI, result in mass unemployment. In fact, there are today, with our global population of almost 8 billion people, vastly more pe ople employed doing things than there ever were in the annals of history. You could imagine that before the turn of the 20th century, back in the 1900s, over 95 percent of all people were on farms. And somebody would make a very sensible argu ment, saying, ""We can't allow in tractors and things that steal our techniques for harvesting vegetables and food, because then all these farmers would be out of work."" Instead, now we have less than 10 percent of the global population raising food. The average nutritional content of everybody, on average, is much higher. And there's vastly more people doing vastly more interesting jobs and passions than ever before. We are an intelligent, creative species. It is in our DNA to solve problems . We wouldn't be here today if we weren't super good problem solvers. In the past, we were farmers, and then carpentry. Now, coding is the new carpentry. We will figure out new and amazing things to do."
20,Andrew Keen,"No I . Look, there's nothing wrong with -- John, there's nothing wrong with optimism. I mean, as long as you're optimistic about -- and you're realistic. And by the way, Jaron , I didn't know you were transhumanist. If I'd have known, I wouldn't be on your team. Jaron Lanier I meant, you know, within the context of how unknown it all is, you know?"
21,Andrew Keen,But the unknown unknown. Right? That's transhumanism. Jaron Lanier Yeah . I’m a Rumsfeldian transhumani st.
22,Andrew Keen,"now. And by the way, I have no idea --"
23,Andrew Keen,"-- what our te am -- our t eams seem split . On the one han d, we have one guy saying that he's celebrating the elimination of work. And then Martine is saying that actually, we're going to innovate so much that everyone will have new jobs. So, you guys have got to make up your mind, whether you're for or against --"
24,Andrew Keen,-- jobs.
25,James Hughes,And we will have artificial intelligence taking care of us.
26,Andrew Keen,But can -- John Donvan:All right. Andrew --
27,Andrew Keen,"Can I just say one thing? That -- we're sort of talking -- in these kind of debates, everyone's throwing, you know -- we know this from the presidential debates -- everyone's claiming the facts are on their side. But the reality is is when you look at the numbers, when you look at the serious research, you will find that the vast majority of economists are deeply worried with this, Martine. What -- give me some example s of economists who say, ""Yeah, there's going to be millions of jobs in the future. We don't need to worry about this?"""
28,Martine Rothblatt,"You know, I'm reminded of the famous quotation from Arthur C. Clarke , who said that if you ask a lot of experts in their field whether or not something is possible, and they say no, they're almost certainly wrong. And it's the same thing about the economists. They have been wrong repeatedly throughout history. So, going to a source like e conomists -- I would look at the bare fac ts. We've got eight billion people in the world, fewer people starving than when I was growing up. Vast ly more people employed. T hose are the bare facts. And furthermore -- furthermore , let me just say one more thing. We're just at the beginning of what we can do as a human species. We've got things like electric cars from Tesla that just 10 years ago, all the economists, and the technocrats, and the bureaucrats dismissed as impossible. Now people are saying, ""Hey, soon the whole economy is going to be electric."" If you are a person who loves life, you will never run out of cool things to do."
29,Jaron Lanier,"Martine, I want you to be right. And I think you probably are, in the sense that there will be new things for people to do. All we have to admit is that people need to do them and that they could be paid for it, and then we can still have dignity. The only danger is not so much that people become obsolete. The danger is that we'll pretend they're obsolete."
30,Martine Rothblatt,"Absolutely. And already, the Europeans are leading the way to -- J aron Lanier : So, you agree --Martine Rothblatt: -- guaranteed annual income -- J aron Lanier : You know, the is screwed here."
31,Martine Rothblatt,"There will be social dividends that -- it's just like Bernie Sanders says. Medicare for all. Social Security for all. So, there will be a basic social dividend that's paid for everybody. We can afford it. Let's do it."
32,James Hughes,"Well, I do think that there's a great deal of mystification about the nature of artificial intelligence in the future. Martine has a fairly embodied notion of what artificial intelligence would be. Mine i s much more diffuse. I think that the potential space of what artificial intelligence will be in the future is , it's very difficult for us to imagine. So far we have a lot of anthropomorphic projection onto that state. Those who expect that something is going to jump out of a box is going to take over the world, the world has 10 seconds to defeat it -- I mean, that's an anthropomorphic projection of an adolescent, you know, male fantasy onto, ""Well, if I w as king of the world."" And I think, you kno w, it could be like -- a n artificial intelligence might just want to communicate with the -- with whales, or with the stock market, or with the stars. And grow like moss on the side of a mountain. I mean, we just have no idea what artificial minds are going to be like. So, yes. I think, if the project is to replicate a human mind and put human mind emulation into a machine, that's one kind of project. I f, on the other hand, self- awareness emerges out of the Internet or just through all the communications and information in the world, we have no idea what it's going to be like.John Donvan: Let --"
33,Martine Rothblatt,"I agree with James, because, you know, contrary to what Andrew said, the mass of people throughout the world are the ones who are creating our Internet. Websites were not created all by Google, and Amazon, and Apple. They we re created by literally millions of people creating the -- J aron Lanier : But then these things are appr opriated by --"
34,Andrew Keen,"All right. Let's use -- okay. Martine, let's use --"
35,Andrew Keen,"-- the example of Google. Google has created -- you know, J aron has defined artificial intelligence, I think, very intelligently, as the algorithm. Google owns the most valuable algorithm in the world. There's no secret sauce to that a lgorithm. It's not as if Larry Page and Sergey Brin at Stanford suddenly figured out, ""We're going to create this remarkably intelligent algorithm."" And --"
36,Martine Rothblatt,--
37,Andrew Keen,"Well, let me finish. No, l et me -- let me --"
38,Martine Rothblatt,You let him hold the most valuable --John Donvan: Do let him finish.
39,Martine Rothblatt,"-- operating system in the world, and they --"
40,Martine Rothblatt,-- that --
41,Martine Rothblatt,-- Google is today.
42,Andrew Keen,"So -- and this is just to reiterate what Jar on had said. That algorithm is a collection of our intelligence. Google essentially has aggregated the entire intelligence -- brilliant, brilliant maneuver. Fantastic. I'm not saying it's immoral in any way. But Google now owns our collectiv e intelligence. It's a company now that's worth -- it probably w ill be the first company that's worth a trillion dollars. Where do they pay it back to us, our intelligence, that revenue? And that's Jaron's point. When you tear back the curtain, it's n ot arti ficial intelligence. It’s us. And we're not benefiting."
43,Martine Rothblatt,"Andrew, Google does not have -- Google does not have the intelligence of one 9-year -old girl, okay? All they've got is a bunch of data that's been hoovered up, along with dozens of other companies who have hoovered up that same data. What Google thinks is magical and is special today -- 20 years from now, will be passé and unnecessary."
44,Andrew Keen,"So, why is Google such a valuable company?"
45,Martine Rothblatt,The same reason that IBM was 50 years ago. They had a point in time when they provided a valuable service to the market. IBM was more valuable relative to the economy 40 years ago than Go ogle is today. Now it's kind of irrelevant. Google will eventually become irrelevant.
46,James Hughes,I just think it's fascinating that you reiterated my point --
47,James Hughes,"-- which is that artificial intelligence is, in fact, a crystallization, a formalization of collective human intelligence. And therefore, not to trust the promise of artificial intelligence is to dismiss the promise of collective --"
48,James Hughes,-- human intelligence.
49,James Hughes,"Yes, I don't think it should be in private hands. But that's a different question. So, you know --"
50,Jaron Lanier,"So, we have the latitude to perceive agency in others or not. We have the latitude to perceive consciousness or not. We have the latitude to perceive God in the world or not. We are free to perceive different things. There's no consciousness meter that will tell you if somebody else is an automaton or not. Some of the people might feel -- seem to be so on occasions, and I -- you know, I don't know. I mean, I ca n't tell what's inside somebody else's heart. We love each other on faith. Just like we know God, we can't really know. We can only know our own consciousness. And so, you absolutely have the latitude to perceive machines that way. The question is whe ther it's useful, smart -- I mean, my argument against it can never be to challenge your faith, or your idea, or your aesthetics, as I said before. I do have a pragmatic argument on a society level, though. And the thing is, tech companies -- which I'm t o tally in be d with. They're not like some other. That's me. But the t ech companies are so powerful that we're basically like de facto governments now of the world and so what we need to do is insist, as I said before, on a church -state separa tion. What we have to do is insist that these massive powers don't adopt particular faiths about what's conscious or not because that totally screws you up. As soon as -- all of the sudden you're o wning women’s bodies because you believe that a fetus --"
51,Martine Rothblatt,So my view is that there's not a -- it's a false dichotomy between an artificial intelligence that's smarter than a human being and a human being. I think that for an artificial intelligence to be smart and intelligent it needs to be as human as we are and therefore there's a continuum of consciousness between humans and artificial intelligence. The dichotomy is false.
52,Andrew Keen,"Jaron, would you like to respond?Jaron Lanier: Yeah, I'd like to. I don't think this is new. It's happened before and the example I'd like to give you is Adam Smith's invisible hand, that markets can do things that people don't seem to be able to with planning and the thing about markets is I'm very much a Keynsian . We have to be able to use them as tools. We have to treat them as technology not as religion. As soon as we treat the market principle as religion then we actually screw up markets even, so sorry Chicago school, but that just seems to happen. And so the wise thing to do is to recognize that we can build these things. We have and yet we build them in a way that we can use them as technology, not as religions, and we can use them well, just like markets."
53,Andrew Keen,"Yeah. I mean, I'd rather -- I think Jaron should define artificial intelligence. He's probably the most suitable of everyone. He gets it more than anyone."
54,Jaron Lanier,"Well, I mean, AI is more than anything else a funding category for research. No, I mean, it's like -- -- and it incorporates a wide range of disciplines and pursuits that might or might not have been bundled together and they were bundled by historical accident in many cases. AI steps on its own foot periodically. What happens is there's a kind of a crazy wild -eyed -ness of like, ""Oh, we're about to understand how to replicate a person,"" and then the funders are like, ""Boy, you sure didn't deliver."" And then there's this thing called an AI winter that keeps on happening. And then you watch your grad students having their careers ruined. And then it finally happens again. But -- like we step on our own feet constantly with this fantasy life. And if we could only just be good engineers and scientists, we would free ourselves from this burden of just constant self-destruction."
55,Andrew Keen,"Is the -- are these AI winters getting shorter, and the summers are longer? And at some point is it going to become real? Because my experience in Silicon Valley as anentrepreneur and as a technologist, there -- it's always a questi on of timing. So Jaron's right about AI being a category for researchers. But now it's a category for entrepreneurs. You wander i nto a VR and you say, you know, ""I've got AI for this, AI for that, and I'll write you a check."" 20: 18:22"
56,Jaron Lanier,"Lately the VP will say, ""Oh, I spent all my money on VR startups."""
57,Jaron Lanier,"Well, it doesn't mean anything. There's no definition. I mean, that's the thing I'm trying to say is that we have a field that's lost its moorings to fantasy. So we don't know. I mean, I very strongly believe in research and coordinated systems and algorithms. I strongly believe t hat these things are improving the world and that they are essential. I strongly -- you know, I -- the actual work is great. But the fantasy life -- just --"
58,Martine Rothblatt,"So I think it was a great question that the gentleman from the audience just asked in terms of like, ""What is the need or the desire for AI?"" And my response is that there is nothing probably that people value more than other people. And we have families and children for that reason. What we value most about other people is probably their mind, if you want to call it their soul, their spirit, their comradery. And so there is going to be an irresistible pressure for lots of people to try to create artificial people. That's what humans do. We like houses, we make artificial houses. We like to go fast, we make artificial horses. We l o ve minds, we make artificial minds. So this is the kind of irresistible pressure I think that will end up bringing artificial intelligence forward. And as James and Jaron and Andrew have said, create a touch point for solving the ethical issues about what we do with this AI, who controls the computing substrate and the software substrate for this AI, and where do we want it to go? It's a societal issue , which is exactly why we need these type of debates and forum."
59,James Hughes,Well.
60,Martine Rothblatt,Yeah.
61,James Hughes,"Our ancestors did not par ticipate in the political process to the extent that we fantasize that they did. You know, there was a lot of backroom deals. It's fascinating to me that the Republicans are actually debating whether they should have a brokered convention and that there' s so much pushback from the leadership of the party because they realize that there would be a huge groundswell of opposition from the base. And that's because we have become a more democratic society. The smarter that we get, the more time and leisure t hat we have as a civilization, the more democracy becomes real. And what we're seeing is some of the unfortunate consequences of democracy becoming real. It's not -- it's not pretty, you know? It's not pretty in the Arab world. It's not pretty here. It's not pretty in a lot of places. But it is democracy maturing and going in the right direction."
62,Andrew Keen,"Because of the printing press, right? James Hughes:Well, I think all technologies raise a similar question. I mean, you're right that I am an accelerationist , as I do believe technologies are speeding up . I don't think it raises a fundamentally different question than previous technologies did. I mean, we could have said the same thing a bout the car, for instance. The consequences -- one of the distinctions we make in my field is between dual use technologies and single use technologies . Nuclear weapons, it's hard to defend as an ethical technology . But artificial intelligence is one w here we have to accept there are so many positive benefits that we have to take it on board and try to figure out how to mitigate the downsides."
63,Jaron Lanier,"The great danger we face is within ourselves, we've gotten good enough at technology that most of our problems are brought by our own actions now . 20:25: 25 We are rarely attacked by giant asteroids, or dinosaurs, or anything . We are in our own troubles . And so, the solution to that has to be clarity of mind. We have to be able to see clearly what we're doing to ourselves in order to do something differently . So, the thing that I keep coming back to here is to do everything possible to not fall into fantasy . And I -- it's odd, because it's a very technical sounding fantasy . And so, you think, ""Well, because it's got this technical flavor to it, it must be less fantastical than some of the other fantasies that we hear our political and social lives being drawn into all the time."" But it really isn't . I wish somehow there was a way for people to just see inside these algorithms . They're not all that fancy, honestly . I mean, they're cool, but they're not -- it's much more just the size of the data we can get these days, you know ? Years and years ago, Marv in Minsky , who I mentioned, had helped some graduate students would make a language translator over a summer project . And it didn't work for decades and decades, until we could get enough samples from people in massive quantities . And that's where we still are . And it's fantasy that we've really uncorked the core of language and we understand how language works is not so . We have statistical correlations between what real people do . But we don't have any way beyond that yet. We might , we might . But it's -- that's an unknown --"
64,Jaron Lanier,So we mustn't -- we mustn't hypnotize ourselves if we're to survive.
65,Andrew Keen,"T here's a guy at Oxford University called Nick Bostrom, who has written an important book about this . And I think his book very much influenced Musk and a number of -- Cambridge University has a Center for Existential Study . It comes ba ck to the Rumsfeld thing again . We don't know -- it's about knowing about unknowns . At the moment, I don't buy -- it's a -- as you said, it's a Hollywood scenario . The idea that we're going to wake up in the next five or 10 years, and robots will not only be smart enough, but acquire their own consciousness, and have a -- w hat Mar x might call a species being -- I think, is absurd. But we don't know . And a lot of it depends on Mo ore's law . A lot of it depends on the -- sort of the runway of computational power .And the reality is it's not impossible. But I think it's an unhealthy part of the debate, because it's so speculative and so easy for Hollywood scriptwriters to take advantage of . The real issu es are the ones that we're talking about today . The real issues are jobs, what we're going to do, who owns all this, who owns all these algorithms, and how we, as a species, benefit."
66,James Hughes,"Andrew, I just want to say --"
67,James Hughes,"-- on this we actually agree . And I think that there is a path forward in how we prepare for the possibility that -- what I consider a currently remote possibility -- of catastrophic emergence of some kind of artificial intelligence . And that would be precisely the path that we have explored around cyber theft, cyber security, having resilient information systems, being able to turn off pieces of the Internet -- that's if we need to . We have a path forward . And it's unfortunately the magical thinking, which I think you're correct about, in certain quarters, which leads people to say, ""Oh, no, no . It's going to jump out of the box and in 10 seconds it's going to take over everything,"" and then send its nanobot minions to knock down your door . That is fantasy . And that means that people don't pay attention to the political, and security, and criminal sanctions that we can put in place today to minimize that possibility."
68,Jaron Lanier,"So, I feel as if I'm arguing against a great tide of Hollywood scripts, but I just have to repeat that this question of whether the technology that might destroy the planet would be alive, or conscious, or intelligent is actually irrelevant . The only thing -- but such a technology could exist. Building a Skynet, as shown in the Terminator movies, wouldn't take a lot of code, honestly, at this point . Like, you know, I think we could do it in a week workshop or something . You know, you -- -- it's not that hard to see how you'd make a self- replicating drone at this point. I think we can print them . We can put guns on them . I mean, like, honestly, don't do it, you know? But -- -- the thing is that's the point. Like, the distinction between some smart machine that hurts you and some malfunctioning machine that you can't operate that hurts you is a nil distinction . They're just both ba dly engineered. As long as we are beholden to this mythology of the evil machine, we will not be able to see clear to design well-functioning machines that we take responsibility for and use well . And I don't know how to shake you from this hypnosis . You've seen these movies and you keep on going back into these thought patterns . Please, please, consider that this isn't a real thing . Please consider that the difference between one machine that works terribly and another machine that works terribly is not important . They just both work terribly. An important difference is between those and a machine that works well . That's what you should focus on. Can't you see that? I mean, I --"
69,Martine Rothblatt,And --
70,Jaron Lanier,"-- I love these Hollywood movies . I love them. They're great . But don't live in them. James Hughes : -- Jaron, I think you're right. I mean, it doesn't make any difference morally if a human being in human civilization or a robot does, but they're equal catastrophes. John Donvan:But when we get to the point where the debaters are agreeing with each other, we're in trouble. So, I'm going to say that concludes round two of this Intelligence Squared U.S. debate. Where our motion is Don't Trust the Promise of Artificial Intelligence. Please remember how you voted before the arguing began, because we're going to have you vote again right after this brief closing round and again it's the numbers -- it's the team whose numbers have changed the most in percentage point terms who will be declared our winner. But first round three, closing statem ents. Each debater will speak uninterrupted in turn for two minutes each. The motion is Don't Trust the Promise of Artificial Intelligence. Here to summarize his position supporting the motion not to trust, Jaron Lanier, a computer scientist and author of the book, ""Who Owns the"
71,James Hughes,"Two hundred twenty years ago the French aristocrat mathematician, Nicolas de Caritat, marquis de Condorcet , was hiding from the terror of the guillotine. He had been the revolutionary. He had been a mathematician who had come up with the theorems that argued that the crowd could be wiser than the individual kind of the bedrock of democratic argument. And he had served in the revolutionary assembly, but he was a liberal and he fell on the wrong side of the Jacobins he was hiding from them. And he decided to write a history of human progress and he got through the first chapter basically, the first book of that history. The sketch for a historical picture of progress in the human spirit, and he argued that in the future, from his perspective, we would liberate women, we would eliminate slavery, we would e liminate toil. There would be no more work. That we would eliminate disease and death. And that all of this would come about through the combined effort of the enlightenment project of democracy, equality, solidarity, and the use of human re ason through the use of science and technology, new scientific languages and techniques. We face the same challenge today. He -- by the way, he finished that book, went outside, got caught by the J acobins and was executed. But for me he was an o ptimist, sitting there under threat of death looking forward to a future which we actually have achieved and we faced that challenge today. Remembering how far we've come and having the optimism that we can muddle through and use these tools that we have developed to create a better future, and therefore I urge you to vote against this resolution. Thank you."
72,Andrew Keen,"Just ga ve me the subject to my next book title, ""AI Is not the Answer."" So we've -- Jaron I think in a very articulate way asked us not to fall into fantasy. This is a debate a conversation about supposedly the reality or the fantasy of AI. It's -- when you make your votes at the end, we're not debating AI. We're not debating its potential. We're debating its promise. We're debating the ideology of the other team. We're debating the way in which they say AI can liberate us from the things that have enslaved us, made us unhappy, or perhaps indeed define s what it means to be human. Now, I think the y’re wrong . I don't think we can trust them. I don't trust James when he celebrates the elimination of work. That's an absurdity. We can laugh at it. We can snigger. But it's utterly absurd to believe in today's world in the early part of the 21st century in political terms that any government in the world will simply have the resources, the political will, to support people who don't work. It's nonsense. Marx's ideas in the middle of the 19th century and nonsense about us being able to farm in the morning and be poets in the afternoon is very noble, very inspiring, but it's nonsense. It's fantasy. That's why you shouldn't promise it. But let me finish with Martine. She says, ""There nothing we value more than other people."" I agree with her. But why? Why do we value other people? Because of their complexity. Look at the person you've come to, to this event. Think of them, your husband, your wife, your friend, your lover, your child. We love these people because of their complexity. The idea that Martine seems to be so confident that we can replicate that co mplexity is in my mind not only a fantasy but a dangerous one. That's why we should not trust the promise of AI. John Donvan:Thank you, Andrew Keen. And that is the motion, "" Don't Trust the Promise of Artificial Intelligence."" And here to make the closing statement against the motion, Martine Rothblatt, and entrepreneur and author of, ""Virtually Human: The Promise and Peril of Digital Immortality."""
73,Martine Rothblatt,"I'd lik e to ask you to think of AI not as a science project but as an art project. If the human is the most delectable part of reality, then indeed it is the most important subject for art. And so it has been, so we have been throughout the ages in sculpture, in painting, in literature, in theater, in film, and now in AI. We are creating AI as a work of art. I believe that we should trust in the promise of AI because this work of art, this replication of a human mind will prove to be fascinating to people throughout the world and for decade after decade. We will each try to one -up ourselves to see if it can be done, ""Is this really a human mind? Have we painted a human mind yet not with co lors but with code?"" I trust in a promise of AI because already decades, maybe if we listen to our opponents, centuries away from there actually being an AI, we've taken time out of our day to gather here and to begin to debate the ethics and the rights and wrongs of, ""How do we want these AIs to be? What kind of restrictions do we want on them, taking our jobs? What kinds of rights and obligations should they have?"" We are a pretty impressive group of people to be thinking about the ethics of something which some believe, many believe, to be a century or more away. And, hence, I ask everybody to vote against the resolution and instead feel that we can trust in the promise of AI because we can trust in the promise of all of us to build this immense and beautiful work of art, the human mind, and to cast th e human minds that we create in an aura of applications of utility and ethics and practicality."
