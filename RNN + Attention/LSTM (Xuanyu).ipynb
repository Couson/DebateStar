{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1059b7bd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from point2mn import point2mn\n",
    "from point2mn import get_main_points\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found word vecs:  400000\n"
     ]
    }
   ],
   "source": [
    "embedding_index = {}\n",
    "\n",
    "f = open('glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:],dtype='float32')\n",
    "    embedding_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('found word vecs: ',len(embedding_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted([s for s in  list(embedding_index.keys()) if s[0].isalpha()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>for</th>\n",
       "      <th>against</th>\n",
       "      <th>For_Main_Points</th>\n",
       "      <th>against_Main_Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d20191112</td>\n",
       "      <td>Capitalism Is a Blessing</td>\n",
       "      <td>2019-11-12</td>\n",
       "      <td>['John Mackey', 'Katherine Mangu-Ward']</td>\n",
       "      <td>['Bhaskar Sunkara', 'Richard D. Wolff']</td>\n",
       "      <td>['By promoting market competition and rewardin...</td>\n",
       "      <td>['Capitalism serves the interests of large cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d20191029</td>\n",
       "      <td>Parenting Is Overrated</td>\n",
       "      <td>2019-10-29</td>\n",
       "      <td>['Robert Plomin', 'Nancy Segal']</td>\n",
       "      <td>['Paige Harden', 'Ann Pleshette Murphy']</td>\n",
       "      <td>[\"We're in the midst of a DNA revolution: Whil...</td>\n",
       "      <td>['While DNA is important, factors like familia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d20191022</td>\n",
       "      <td>Europe Has Declared War on American Tech Compa...</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>['Roslyn Layton', 'Berin Szóka']</td>\n",
       "      <td>['Marietje Schaake', 'Ramesh Srinivasan']</td>\n",
       "      <td>['European regulators have declared war on Ame...</td>\n",
       "      <td>['Brussels isn’t waging war on Silicon Valley....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d20190917</td>\n",
       "      <td>Replace Private Insurance with Medicare for All</td>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>['Dr. Adam Gaffney', 'Joseph Sanberg']</td>\n",
       "      <td>['Nick Gillespie', 'Sally Pipes']</td>\n",
       "      <td>['The United States government should follow t...</td>\n",
       "      <td>['Individuals should have the freedom to choos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d20190802</td>\n",
       "      <td>The Recent U.S. Policy Towards China Is Produc...</td>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>['Michael Pillsbury', 'Kori Schake']</td>\n",
       "      <td>['Graham Allison', 'Jake Sullivan']</td>\n",
       "      <td>['The prospect of China becoming an open and l...</td>\n",
       "      <td>['The United States and China are great compet...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title        date  \\\n",
       "0  d20191112                           Capitalism Is a Blessing  2019-11-12   \n",
       "1  d20191029                             Parenting Is Overrated  2019-10-29   \n",
       "2  d20191022  Europe Has Declared War on American Tech Compa...  2019-10-22   \n",
       "3  d20190917    Replace Private Insurance with Medicare for All  2019-09-17   \n",
       "4  d20190802  The Recent U.S. Policy Towards China Is Produc...  2019-08-02   \n",
       "\n",
       "                                       for  \\\n",
       "0  ['John Mackey', 'Katherine Mangu-Ward']   \n",
       "1         ['Robert Plomin', 'Nancy Segal']   \n",
       "2         ['Roslyn Layton', 'Berin Szóka']   \n",
       "3   ['Dr. Adam Gaffney', 'Joseph Sanberg']   \n",
       "4     ['Michael Pillsbury', 'Kori Schake']   \n",
       "\n",
       "                                     against  \\\n",
       "0    ['Bhaskar Sunkara', 'Richard D. Wolff']   \n",
       "1   ['Paige Harden', 'Ann Pleshette Murphy']   \n",
       "2  ['Marietje Schaake', 'Ramesh Srinivasan']   \n",
       "3          ['Nick Gillespie', 'Sally Pipes']   \n",
       "4        ['Graham Allison', 'Jake Sullivan']   \n",
       "\n",
       "                                     For_Main_Points  \\\n",
       "0  ['By promoting market competition and rewardin...   \n",
       "1  [\"We're in the midst of a DNA revolution: Whil...   \n",
       "2  ['European regulators have declared war on Ame...   \n",
       "3  ['The United States government should follow t...   \n",
       "4  ['The prospect of China becoming an open and l...   \n",
       "\n",
       "                                 against_Main_Points  \n",
       "0  ['Capitalism serves the interests of large cor...  \n",
       "1  ['While DNA is important, factors like familia...  \n",
       "2  ['Brussels isn’t waging war on Silicon Valley....  \n",
       "3  ['Individuals should have the freedom to choos...  \n",
       "4  ['The United States and China are great compet...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_points = pd.read_csv('DebateStar/Meta Data/metadata_appended_main_points.csv') \n",
    "main_points.dropna(subset = ['For_Main_Points', 'against_Main_Points'], inplace = True)\n",
    "main_points = main_points.reset_index(drop = True)\n",
    "main_points.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('DebateStar/results_data/final_online.csv') \n",
    "results = results.loc[results['winner'].apply(lambda x: x != 'undecided')]\n",
    "results['winner'] = results['winner'].apply(lambda x: 1 if x == 'for' else 0)\n",
    "id2winner = results[['id', 'winner']].set_index('id').to_dict()['winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>for</th>\n",
       "      <th>against</th>\n",
       "      <th>For_Main_Points</th>\n",
       "      <th>against_Main_Points</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d20191112</td>\n",
       "      <td>Capitalism Is a Blessing</td>\n",
       "      <td>2019-11-12</td>\n",
       "      <td>['John Mackey', 'Katherine Mangu-Ward']</td>\n",
       "      <td>['Bhaskar Sunkara', 'Richard D. Wolff']</td>\n",
       "      <td>['By promoting market competition and rewardin...</td>\n",
       "      <td>['Capitalism serves the interests of large cor...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d20191029</td>\n",
       "      <td>Parenting Is Overrated</td>\n",
       "      <td>2019-10-29</td>\n",
       "      <td>['Robert Plomin', 'Nancy Segal']</td>\n",
       "      <td>['Paige Harden', 'Ann Pleshette Murphy']</td>\n",
       "      <td>[\"We're in the midst of a DNA revolution: Whil...</td>\n",
       "      <td>['While DNA is important, factors like familia...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d20191022</td>\n",
       "      <td>Europe Has Declared War on American Tech Compa...</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>['Roslyn Layton', 'Berin Szóka']</td>\n",
       "      <td>['Marietje Schaake', 'Ramesh Srinivasan']</td>\n",
       "      <td>['European regulators have declared war on Ame...</td>\n",
       "      <td>['Brussels isn’t waging war on Silicon Valley....</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d20190917</td>\n",
       "      <td>Replace Private Insurance with Medicare for All</td>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>['Dr. Adam Gaffney', 'Joseph Sanberg']</td>\n",
       "      <td>['Nick Gillespie', 'Sally Pipes']</td>\n",
       "      <td>['The United States government should follow t...</td>\n",
       "      <td>['Individuals should have the freedom to choos...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d20190802</td>\n",
       "      <td>The Recent U.S. Policy Towards China Is Produc...</td>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>['Michael Pillsbury', 'Kori Schake']</td>\n",
       "      <td>['Graham Allison', 'Jake Sullivan']</td>\n",
       "      <td>['The prospect of China becoming an open and l...</td>\n",
       "      <td>['The United States and China are great compet...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title        date  \\\n",
       "0  d20191112                           Capitalism Is a Blessing  2019-11-12   \n",
       "1  d20191029                             Parenting Is Overrated  2019-10-29   \n",
       "2  d20191022  Europe Has Declared War on American Tech Compa...  2019-10-22   \n",
       "3  d20190917    Replace Private Insurance with Medicare for All  2019-09-17   \n",
       "4  d20190802  The Recent U.S. Policy Towards China Is Produc...  2019-08-02   \n",
       "\n",
       "                                       for  \\\n",
       "0  ['John Mackey', 'Katherine Mangu-Ward']   \n",
       "1         ['Robert Plomin', 'Nancy Segal']   \n",
       "2         ['Roslyn Layton', 'Berin Szóka']   \n",
       "3   ['Dr. Adam Gaffney', 'Joseph Sanberg']   \n",
       "4     ['Michael Pillsbury', 'Kori Schake']   \n",
       "\n",
       "                                     against  \\\n",
       "0    ['Bhaskar Sunkara', 'Richard D. Wolff']   \n",
       "1   ['Paige Harden', 'Ann Pleshette Murphy']   \n",
       "2  ['Marietje Schaake', 'Ramesh Srinivasan']   \n",
       "3          ['Nick Gillespie', 'Sally Pipes']   \n",
       "4        ['Graham Allison', 'Jake Sullivan']   \n",
       "\n",
       "                                     For_Main_Points  \\\n",
       "0  ['By promoting market competition and rewardin...   \n",
       "1  [\"We're in the midst of a DNA revolution: Whil...   \n",
       "2  ['European regulators have declared war on Ame...   \n",
       "3  ['The United States government should follow t...   \n",
       "4  ['The prospect of China becoming an open and l...   \n",
       "\n",
       "                                 against_Main_Points  label  \n",
       "0  ['Capitalism serves the interests of large cor...    0.0  \n",
       "1  ['While DNA is important, factors like familia...    1.0  \n",
       "2  ['Brussels isn’t waging war on Silicon Valley....    0.0  \n",
       "3  ['Individuals should have the freedom to choos...    0.0  \n",
       "4  ['The United States and China are great compet...    0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_points['label'] = main_points.id.apply(lambda x: id2winner[x] if x in id2winner else np.nan)\n",
    "main_points = main_points.dropna(subset = ['label']).reset_index(drop = True)\n",
    "main_points.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = main_points.id.tolist()\n",
    "labels =  main_points.label.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(inputs, labels, test_size = 0.15, random_state = 8)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.15, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(y_train)\n",
    "y_val = torch.tensor(y_val)\n",
    "y_test = torch.tensor(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    0.5\n",
       "0.0    0.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_test).value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.5\n",
       "1.0    0.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_val).value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.517647\n",
       "1.0    0.482353\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 85\n",
      "Validation: 16\n",
      "Testing: 18\n"
     ]
    }
   ],
   "source": [
    "print('Training:', len(X_train))\n",
    "print('Validation:',len(X_val))\n",
    "print('Testing:',len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Hidden state initialize differently every time running LSTM??\n",
    "\n",
    "2. init_hidden?\n",
    "\n",
    "3. Softmax?\n",
    "\n",
    "4. Use only hidden state, not cell state or output?\n",
    "\n",
    "5. Results somewhat random?\n",
    "\n",
    "6. Hidden Dimension?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tune embedding\n",
    "\n",
    "Same initial hidden states DONE\n",
    "\n",
    "Check dropout in evaluation DONE no dropout\n",
    "\n",
    "Validation set DONE\n",
    "\n",
    "Check fully connected weights \n",
    "\n",
    "Add f.c. layers DOING\n",
    "\n",
    "Mean + std of several runs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_testing(train_acc, val_acc, test_acc, how):\n",
    "    df = pd.DataFrame({'# Epoch': range(1,epochs + 1), 'training acc': train_acc,\\\n",
    "                         'validation acc': val_acc, 'testing acc': test_acc})\n",
    "    if how == 'first':\n",
    "        return df.loc[df['validation acc'] == max(df['validation acc'])].iloc[0]['testing acc']\n",
    "    elif how == 'last':\n",
    "        return df.loc[df['validation acc'] == max(df['validation acc'])].iloc[-1]['testing acc']\n",
    "    elif how == 'best':\n",
    "        return df.loc[df['validation acc'] == max(df['validation acc'])]['testing acc'].max()\n",
    "    else:\n",
    "        print('Invalid Argument for how:', how, \"Should be one of 'first', 'last', or 'best'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lstm_one_sentence(sentence, title, lstm, hidden, embedding_index):\n",
    "    inputs = point2mn(sentence, title, embedding_index)\n",
    "    tensor_input = [torch.tensor([x]) for x in inputs]\n",
    "    tensor_input = torch.cat(tensor_input).view(1, len(tensor_input), -1)\n",
    "#     hidden = (torch.randn(1, 1, HIDDEN_DIM), torch.randn(1, 1, HIDDEN_DIM)) #???????\n",
    "    tensor_output, hidden = lstm(tensor_input, hidden)\n",
    "    # should return hidden state and cell state in 'hidden' instead of output\n",
    "    return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lstm_on_fid(fid, embedding_index, lstm, hidden, combine_func = [torch.mean, torch.max]):\n",
    "    \"\"\"\n",
    "    Given fid, find main points for the debate and for each sentence, pass corresponding \n",
    "    matching vectors to lstm and get hidden state in the end. Gather the hidden states\n",
    "    in a list and do combine_func.\n",
    "    -combine_func: the funtion applied to combine lstm outputs from one side elementwisely\n",
    "    \"\"\"\n",
    "    \n",
    "    title = main_points[main_points['id'] == fid].title.iloc[0]\n",
    "    for_main_points, against_main_points = get_main_points(fid, main_points)\n",
    "    for_output_list = []\n",
    "    against_output_list = []\n",
    "    \n",
    "    for sentence in for_main_points:\n",
    "        hidden_state, cell_state = run_lstm_one_sentence(sentence, title, lstm, hidden, embedding_index)\n",
    "        for_output_list.append(hidden_state)\n",
    "        \n",
    "    for sentence in against_main_points:\n",
    "        hidden_state, cell_state = run_lstm_one_sentence(sentence, title, lstm, hidden, embedding_index)\n",
    "        against_output_list.append(hidden_state)\n",
    "    for_torchs = []\n",
    "    against_torchs = []\n",
    "    for combine_f in combine_func:\n",
    "        if combine_f == torch.mean:\n",
    "            for_torch = combine_f(torch.stack(for_output_list), dim = 0, keepdim = True)#[0]\n",
    "            against_torch = combine_f(torch.stack(against_output_list), dim = 0, keepdim = True)#[0]\n",
    "        else:\n",
    "            for_torch = combine_f(torch.stack(for_output_list), dim = 0, keepdim = True)[0]\n",
    "            against_torch = combine_f(torch.stack(against_output_list), dim = 0, keepdim = True)[0]\n",
    "        for_torchs.append(for_torch)\n",
    "        against_torchs.append(against_torch)\n",
    "    if len(for_torchs) == 2:\n",
    "        t1 = torch.cat((for_torchs[0], for_torchs[1]), dim = 2)\n",
    "        t2 = torch.cat((against_torchs[0], against_torchs[1]), dim = 2)\n",
    "        return torch.cat((t1, t2), dim = 2)\n",
    "    return torch.cat((for_torchs[0], against_torchs[0]), dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, output_size_1, output_size_2, n_layers, embedding_dim, hidden_dim, combine_funcs, hidden, drop_prob=0.5):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.output_size_1 = output_size_1\n",
    "        self.output_size_2 = output_size_2\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.combine_funcs = combine_funcs\n",
    "        self.hidden = hidden\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2 * len(self.combine_funcs), self.output_size_1)\n",
    "        self.fc2 = nn.Linear(output_size_1, self.output_size_2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, fids):\n",
    "        batch_size = len(fids)\n",
    "        lstm_out = torch.stack([run_lstm_on_fid(fid, embedding_index, self.lstm, self.hidden, \\\n",
    "                                                combine_func = self.combine_funcs) for fid in fids])\n",
    "    \n",
    "        lstm_out = lstm_out.contiguous().view(-1, len(self.combine_funcs) * 2 * self.hidden_dim)\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        out = out.view(batch_size, -1)\n",
    "        out = out[:,-1]\n",
    "        return out#, hidden\n",
    "    \n",
    "#     def init_hidden(self, batch_size):\n",
    "#         weight = next(self.parameters()).data\n",
    "#         hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "#                       weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "#         return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-2.2285e-01, -2.9363e-01,  4.1848e-02,  2.4278e-01,  9.8378e-02,\n",
       "           -5.4527e-02, -1.9896e-02,  3.5270e-01, -8.9105e-02, -1.5113e-01,\n",
       "            1.8225e-01,  2.4688e-01, -1.0039e-01, -3.1386e-01,  9.1738e-02,\n",
       "            6.7223e-02,  4.2452e-01,  2.8536e-01, -2.3161e-01,  2.1571e-02,\n",
       "            1.2818e-01, -4.5801e-01, -2.5654e-01, -2.3639e-01, -6.6850e-02,\n",
       "            1.7433e-01, -1.2748e-01, -4.6969e-02, -1.7209e-02,  4.4396e-03,\n",
       "           -3.2286e-01, -2.7042e-01, -4.6739e-02, -7.8938e-02, -3.2179e-01,\n",
       "            6.0513e-01, -2.4542e-01,  1.7760e-02, -1.6119e-01, -2.0208e-01,\n",
       "            6.9686e-02,  2.1417e-01,  1.8965e-01, -2.5910e-01, -1.4694e-01,\n",
       "            3.3707e-01, -1.6223e-01, -1.4860e-01,  6.2354e-02, -2.3028e-01],\n",
       "          [-4.1652e-02, -2.9644e-01, -7.1542e-03,  2.6875e-01,  1.3184e-02,\n",
       "           -1.1651e-01,  3.2514e-02,  4.7123e-02,  5.7037e-02, -1.0140e-01,\n",
       "            3.5391e-01,  2.6118e-01, -1.1132e-01, -1.5567e-01,  1.9504e-01,\n",
       "            1.5045e-01,  1.7227e-01,  1.4873e-01, -2.2969e-01, -1.4068e-01,\n",
       "            6.9295e-02, -2.9592e-01, -1.6414e-01, -1.9010e-01, -8.3439e-02,\n",
       "            1.8039e-01,  7.7150e-02, -7.9706e-02,  1.6390e-01,  4.2710e-02,\n",
       "           -3.9728e-01, -3.0224e-01,  4.5501e-02,  2.1168e-02, -3.4342e-01,\n",
       "            4.2663e-01, -1.6907e-01, -1.1768e-01, -1.6975e-01, -2.3920e-01,\n",
       "            6.4029e-02,  2.1210e-01,  1.1480e-01, -2.5739e-01,  7.2425e-02,\n",
       "            2.9155e-01, -9.2997e-02, -7.7973e-02, -6.2576e-02, -1.9631e-01],\n",
       "          [ 1.6903e-01, -3.5331e-01,  5.9572e-03,  2.2632e-01, -4.8642e-02,\n",
       "           -1.0482e-01,  2.3545e-02, -7.9581e-02,  1.5139e-03, -8.7705e-03,\n",
       "            3.9615e-01,  2.8648e-01, -1.7407e-01, -2.4058e-01,  2.3741e-01,\n",
       "            2.1661e-01,  2.4117e-01,  3.8861e-04, -2.9117e-01, -3.0052e-01,\n",
       "            2.1082e-02, -3.4197e-01, -1.3707e-01, -1.9231e-01,  3.2740e-02,\n",
       "            1.8016e-01,  4.7326e-02, -4.3440e-02,  2.5253e-01,  5.8179e-03,\n",
       "           -2.9528e-01, -2.8441e-01,  1.5277e-01, -9.0350e-02, -2.5777e-01,\n",
       "            5.2816e-01, -2.0504e-01, -1.1693e-01, -1.1153e-01, -1.8519e-01,\n",
       "           -2.0881e-02,  1.6999e-01,  9.8862e-03, -3.5909e-01,  1.3511e-01,\n",
       "            2.6277e-01, -1.1963e-01, -7.8054e-02, -1.5428e-01, -1.9793e-01],\n",
       "          [ 2.0485e-01, -2.8560e-01,  2.0521e-02,  3.7371e-01, -1.5770e-01,\n",
       "           -1.5005e-01,  6.1862e-02, -3.7997e-02,  6.4181e-02, -3.6186e-03,\n",
       "            2.9581e-01,  2.5540e-01, -2.6025e-01, -3.5187e-01,  2.1545e-01,\n",
       "            2.1310e-01,  1.7390e-01, -1.3749e-01, -4.2786e-01, -1.9608e-01,\n",
       "            6.1237e-02, -1.8016e-01, -9.2053e-02, -9.6038e-02,  3.3245e-02,\n",
       "            2.9525e-01, -1.8442e-01,  1.0161e-01,  1.5738e-01,  3.5939e-02,\n",
       "           -3.2665e-01, -2.5654e-01,  1.5137e-01, -1.3354e-01, -2.3528e-01,\n",
       "            4.7475e-01, -2.1673e-01, -9.8499e-02, -1.1658e-01, -1.2590e-01,\n",
       "           -2.4551e-02,  1.4418e-01, -4.3656e-02, -1.8405e-01,  1.7774e-01,\n",
       "            2.3485e-01, -4.3411e-02, -8.5878e-02, -1.4890e-01, -2.1605e-01],\n",
       "          [ 2.0615e-01, -9.0210e-02, -1.0396e-01,  4.4363e-01, -2.7989e-01,\n",
       "           -2.9384e-01,  1.0977e-01, -1.0560e-01, -1.1823e-01,  8.2818e-03,\n",
       "            2.5493e-01, -1.2772e-01, -8.1790e-02, -1.7345e-01,  1.4810e-01,\n",
       "            2.0630e-01,  8.7362e-02, -7.4242e-02, -2.0721e-01, -2.4064e-01,\n",
       "            6.7158e-02,  1.1055e-02, -1.4853e-01, -1.2035e-01, -1.5474e-01,\n",
       "            1.1055e-01, -1.3407e-01, -1.1221e-01,  3.1614e-01,  2.7436e-02,\n",
       "           -3.3060e-01, -2.4837e-01,  2.4846e-01,  2.8881e-02, -9.7137e-02,\n",
       "            4.0229e-01, -1.7574e-01,  1.8993e-03, -5.5308e-02, -1.5653e-01,\n",
       "           -1.9335e-02,  2.1125e-01, -1.6240e-01, -2.5550e-01,  2.7983e-01,\n",
       "            3.7913e-01, -1.5989e-01, -1.3514e-01, -8.7376e-02, -1.0700e-01],\n",
       "          [ 2.2784e-01, -1.6821e-02, -1.2398e-01,  3.4568e-01, -2.9821e-01,\n",
       "           -3.8698e-01,  1.2024e-01, -1.4051e-01, -2.2722e-01,  1.5127e-02,\n",
       "            2.5252e-01, -3.1454e-01, -7.0003e-02, -9.0717e-02,  1.8117e-01,\n",
       "            1.8317e-01,  7.9796e-02, -4.8995e-02, -2.0509e-01, -2.2508e-01,\n",
       "            6.9912e-02,  7.9885e-02, -1.5037e-01, -1.1345e-01, -2.1933e-01,\n",
       "            1.9705e-02, -1.5007e-01, -1.9329e-01,  3.9872e-01, -3.5933e-03,\n",
       "           -3.3404e-01, -2.7782e-01,  2.7330e-01,  9.5249e-02, -7.5717e-02,\n",
       "            3.7732e-01, -1.4479e-01,  5.5016e-02, -4.3319e-03, -1.6504e-01,\n",
       "           -1.6154e-02,  2.3912e-01, -2.1557e-01, -3.0393e-01,  2.8699e-01,\n",
       "            3.7942e-01, -1.9724e-01, -1.4484e-01,  1.0952e-01, -9.4316e-02],\n",
       "          [ 2.3653e-01,  5.8359e-03, -1.2718e-01,  2.7543e-01, -3.1151e-01,\n",
       "           -4.4649e-01,  1.1837e-01, -1.6014e-01, -2.8198e-01,  2.0410e-02,\n",
       "            2.4939e-01, -3.7960e-01, -6.1332e-02, -3.9646e-02,  1.9974e-01,\n",
       "            1.7079e-01,  8.1069e-02, -4.0120e-02, -2.0641e-01, -2.1562e-01,\n",
       "            7.1392e-02,  1.0237e-01, -1.3845e-01, -1.1103e-01, -2.3720e-01,\n",
       "           -2.1528e-02, -1.5744e-01, -2.2589e-01,  4.4006e-01, -2.3104e-02,\n",
       "           -3.4173e-01, -2.8395e-01,  2.8906e-01,  1.2712e-01, -8.2777e-02,\n",
       "            3.5878e-01, -1.1938e-01,  8.5212e-02,  1.8782e-02, -1.7549e-01,\n",
       "           -2.4727e-02,  2.5550e-01, -2.5133e-01, -3.3838e-01,  2.7954e-01,\n",
       "            3.9840e-01, -2.1157e-01, -1.4929e-01,  2.5005e-01, -9.0029e-02]]],\n",
       "        grad_fn=<TransposeBackward0>),\n",
       " (tensor([[[ 0.2365,  0.0058, -0.1272,  0.2754, -0.3115, -0.4465,  0.1184,\n",
       "            -0.1601, -0.2820,  0.0204,  0.2494, -0.3796, -0.0613, -0.0396,\n",
       "             0.1997,  0.1708,  0.0811, -0.0401, -0.2064, -0.2156,  0.0714,\n",
       "             0.1024, -0.1384, -0.1110, -0.2372, -0.0215, -0.1574, -0.2259,\n",
       "             0.4401, -0.0231, -0.3417, -0.2840,  0.2891,  0.1271, -0.0828,\n",
       "             0.3588, -0.1194,  0.0852,  0.0188, -0.1755, -0.0247,  0.2555,\n",
       "            -0.2513, -0.3384,  0.2795,  0.3984, -0.2116, -0.1493,  0.2500,\n",
       "            -0.0900]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[ 0.5457,  0.0136, -0.6190,  0.4190, -1.2675, -0.7474,  0.3593,\n",
       "            -0.5274, -0.5422,  0.1401,  1.2670, -0.8478, -0.3537, -0.0694,\n",
       "             0.4688,  0.3386,  0.1996, -0.0579, -0.6874, -0.3549,  0.1926,\n",
       "             0.2117, -0.3226, -0.1483, -0.3949, -0.0293, -0.2944, -0.3768,\n",
       "             0.6778, -0.0563, -0.8200, -1.2542,  0.4690,  0.2338, -0.1308,\n",
       "             0.7496, -0.2714,  0.1903,  0.0355, -0.5610, -0.0456,  0.3500,\n",
       "            -0.7856, -0.4544,  0.3462,  0.6172, -0.4986, -0.2519,  0.4568,\n",
       "            -0.1665]]], grad_fn=<StackBackward>)))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, batch_first=True)\n",
    "hidden = (torch.randn(1, 1, HIDDEN_DIM), torch.randn(1, 1, HIDDEN_DIM))\n",
    "run_lstm_one_sentence('It is just a test test test', 'this is a debate title', lstm, hidden, embedding_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 200\n",
    "HIDDEN_DIM = 50\n",
    "OUTPUT_SIZE_1 = 20\n",
    "COMBINE_FUNCS =[torch.mean, torch.max]\n",
    "OUTPUT_SIZE_2 = 1\n",
    "N_LAYERS = 1\n",
    "DROPOUT_PROB = 0.5\n",
    "HIDDEN_INITIAL = (torch.randn(1, 1, HIDDEN_DIM), torch.randn(1, 1, HIDDEN_DIM))\n",
    "\n",
    "# all should use the same one lstm layer\n",
    "# lstm = nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMNet(OUTPUT_SIZE_1, OUTPUT_SIZE_2, N_LAYERS, EMBEDDING_DIM, HIDDEN_DIM, \\\n",
    "                COMBINE_FUNCS, HIDDEN_INITIAL,DROPOUT_PROB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0.6956652402877808\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-25c7d82f4ef0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m#     nn.utils.clip_grad_norm_(model.parameters(), clip)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "counter = 0\n",
    "# print_every = 1000\n",
    "# clip = 5\n",
    "# valid_loss_min = np.Inf\n",
    "train_acc = []\n",
    "train_acc2 = []\n",
    "\n",
    "val_acc = []\n",
    "test_acc = []\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "#     h = model.init_hidden(batch_size)\n",
    "    \n",
    "#     for inputs, labels in train_loader:\n",
    "#         counter += 1\n",
    "#         h = tuple([e.data for e in h])\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    output = model(X_train)\n",
    "    loss = criterion(output.squeeze(), y_train.float())\n",
    "    print(loss.item())\n",
    "    loss.backward()\n",
    "#     nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "    optimizer.step()\n",
    "    model.eval()\n",
    "    outs = model(X_train)\n",
    "    train_acc.append(torch.sum((outs > 0.5) == y_train).item() / len(y_train))\n",
    "\n",
    "    outs = model(X_val)\n",
    "    val_acc.append(torch.sum((outs > 0.5) == y_val).item() / len(y_val))\n",
    "    \n",
    "    outs = model(X_test)\n",
    "    test_acc.append(torch.sum((outs > 0.5) == y_test).item() / len(y_test))\n",
    "    print(train_acc, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HIDDEN_DIM = 50, output_size_1 = 10, 2 fcs, [torch.mean, torch.max]¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0 0.717143714427948\n",
      "1 0.706023097038269\n",
      "2 0.6767569780349731\n",
      "3 0.6614444255828857\n",
      "4 0.6306944489479065\n",
      "5 0.6063251495361328\n",
      "6 0.5509687066078186\n",
      "7 0.5286946296691895\n",
      "8 0.4603004455566406\n",
      "9 0.375855416059494\n",
      "10 0.36038756370544434\n",
      "11 0.4040611684322357\n",
      "12 0.24962647259235382\n",
      "13 0.2764521837234497\n",
      "14 0.15850308537483215\n",
      "15 0.22365713119506836\n",
      "16 0.11958719044923782\n",
      "17 0.14815734326839447\n",
      "18 0.05993449687957764\n",
      "19 0.06801258772611618\n",
      "20 0.06226031482219696\n",
      "21 0.046341605484485626\n",
      "22 0.028158899396657944\n",
      "23 0.07814288139343262\n",
      "24 0.03282732516527176\n",
      "25 0.015446184203028679\n",
      "26 0.021061528474092484\n",
      "27 0.009942620992660522\n",
      "28 0.008610766381025314\n",
      "29 0.002227829536423087\n",
      "30 0.003399194683879614\n",
      "31 0.008938322775065899\n",
      "32 0.007289078552275896\n",
      "33 0.002762146992608905\n",
      "34 0.0026610377244651318\n",
      "35 0.00047819383325986564\n",
      "36 0.0061164433136582375\n",
      "37 0.0010530544677749276\n",
      "38 0.0003746900474652648\n",
      "39 0.0004252711951266974\n",
      "40 0.0010435888543725014\n",
      "41 0.0010059747146442533\n",
      "42 0.0002494642394594848\n",
      "43 0.0038332161493599415\n",
      "44 0.00031419360311701894\n",
      "45 0.0003201206272933632\n",
      "46 0.0009875368559733033\n",
      "47 0.007767997682094574\n",
      "48 0.00020853368914686143\n",
      "49 0.00015594427532050759\n",
      "50 0.0006811125203967094\n",
      "51 0.0030641404446214437\n",
      "52 4.7315530537161976e-05\n",
      "53 6.667109846603125e-05\n",
      "54 0.0001050258069881238\n",
      "55 0.00021453830413520336\n",
      "56 4.5221888285595924e-05\n",
      "57 0.00011843403626699\n",
      "58 0.00036412509507499635\n",
      "59 0.0003426648036111146\n",
      "60 0.00031726298038847744\n",
      "61 0.0005864960257895291\n",
      "62 8.100711420411244e-05\n",
      "63 0.00028216969803906977\n",
      "64 7.273496885318309e-05\n",
      "65 0.00015367782907560468\n",
      "66 5.1337879995116964e-05\n",
      "67 4.7794164856895804e-05\n",
      "68 7.022359204711393e-05\n",
      "69 6.632576696574688e-05\n",
      "70 0.00019526157120708376\n",
      "71 0.00011677473230520263\n",
      "72 5.011784378439188e-05\n",
      "73 0.00017596078396309167\n",
      "74 0.0001045564713422209\n",
      "75 0.0002649672678671777\n",
      "76 9.767618030309677e-05\n",
      "77 0.0004014303267467767\n",
      "78 4.539081055554561e-05\n",
      "79 0.00013821029278915375\n",
      "80 6.823119474574924e-05\n",
      "81 9.363376739202067e-05\n",
      "82 0.000114052279968746\n",
      "83 5.099141344544478e-05\n",
      "84 0.0001862122444435954\n",
      "85 7.639498653588817e-05\n",
      "86 5.2891347877448425e-05\n",
      "87 5.817450437461957e-05\n",
      "88 5.694583524018526e-05\n",
      "89 6.946412759134546e-05\n",
      "90 1.3910834240959957e-05\n",
      "91 4.853241262026131e-05\n",
      "92 4.562003232422285e-05\n",
      "93 3.031752203241922e-05\n",
      "94 0.00010233963985228911\n",
      "95 5.5664633691776544e-05\n",
      "96 2.4455237507936545e-05\n",
      "97 4.322930908529088e-05\n",
      "98 0.00010783845209516585\n",
      "99 3.139099135296419e-05\n",
      "1\n",
      "0 0.6963562369346619\n",
      "1 0.6826019287109375\n",
      "2 0.6860046982765198\n",
      "3 0.643207311630249\n",
      "4 0.6033353209495544\n",
      "5 0.5457524657249451\n",
      "6 0.6131473779678345\n",
      "7 0.48297134041786194\n",
      "8 0.4707370102405548\n",
      "9 0.4072122871875763\n",
      "10 0.38718727231025696\n",
      "11 0.2951704263687134\n",
      "12 0.2678264379501343\n",
      "13 0.20231890678405762\n",
      "14 0.1556824892759323\n",
      "15 0.14939306676387787\n",
      "16 0.07011335343122482\n",
      "17 0.035750675946474075\n",
      "18 0.03210039809346199\n",
      "19 0.01951899565756321\n",
      "20 0.016405265778303146\n",
      "21 0.012556788511574268\n",
      "22 0.0021326879505068064\n",
      "23 0.00708782160654664\n",
      "24 0.0017743748612701893\n",
      "25 0.000802904658485204\n",
      "26 0.0007442781352438033\n",
      "27 0.019736172631382942\n",
      "28 0.09225444495677948\n",
      "29 0.011048894375562668\n",
      "30 0.4931545555591583\n",
      "31 0.0013249071780592203\n",
      "32 0.2777339816093445\n",
      "33 0.0723472312092781\n",
      "34 0.015681277960538864\n",
      "35 0.03807024285197258\n",
      "36 0.0816071555018425\n",
      "37 0.03811657056212425\n",
      "38 0.029487259685993195\n",
      "39 0.03305409476161003\n",
      "40 0.06128627434372902\n",
      "41 0.028314899653196335\n",
      "42 0.011414751410484314\n",
      "43 0.013507272116839886\n",
      "44 0.013828297145664692\n",
      "45 0.014271175488829613\n",
      "46 0.03999505564570427\n",
      "47 0.016270821914076805\n",
      "48 0.011332846246659756\n",
      "49 0.0074775125831365585\n",
      "50 0.0066984184086322784\n",
      "51 0.009111857041716576\n",
      "52 0.0040219612419605255\n",
      "53 0.003899439936503768\n",
      "54 0.004939495585858822\n",
      "55 0.004065779037773609\n",
      "56 0.002798805246129632\n",
      "57 0.004473387263715267\n",
      "58 0.003589408239349723\n",
      "59 0.002057253150269389\n",
      "60 0.0025050374679267406\n",
      "61 0.004047374706715345\n",
      "62 0.0011857937788590789\n",
      "63 0.00973440520465374\n",
      "64 0.0011875346535816789\n",
      "65 0.0008422185201197863\n",
      "66 0.0013889744877815247\n",
      "67 0.001552516594529152\n",
      "68 0.0009550589020363986\n",
      "69 0.0006616979371756315\n",
      "70 0.0010041013592854142\n",
      "71 0.0010586720891296864\n",
      "72 0.0018389144679531455\n",
      "73 0.0005912263877689838\n",
      "74 0.0011339274933561683\n",
      "75 0.0014881901443004608\n",
      "76 0.0003952569386456162\n",
      "77 0.0007261478458531201\n",
      "78 0.0004979912773706019\n",
      "79 0.00035330356331542134\n",
      "80 0.0009768155869096518\n",
      "81 0.0007852810085751116\n",
      "82 0.0004615824145730585\n",
      "83 0.0010158723453059793\n",
      "84 0.0009695977787487209\n",
      "85 0.0008338708430528641\n",
      "86 0.000645684776827693\n",
      "87 0.0008248958620242774\n",
      "88 0.0007227452588267624\n",
      "89 0.0003117587766610086\n",
      "90 0.0010920664062723517\n",
      "91 0.00017815144383348525\n",
      "92 0.00032268938957713544\n",
      "93 0.00029005546821281314\n",
      "94 0.0002464335993863642\n",
      "95 0.00036474192165769637\n",
      "96 0.00019284503650851548\n",
      "97 0.00023299650638364255\n",
      "98 0.00012824540317524225\n",
      "99 0.00031349831260740757\n",
      "2\n",
      "0 0.6916751265525818\n",
      "1 0.6956736445426941\n",
      "2 0.6730696558952332\n",
      "3 0.6836167573928833\n",
      "4 0.6365975141525269\n",
      "5 0.6004904508590698\n",
      "6 0.5505166053771973\n",
      "7 0.5078055262565613\n",
      "8 0.45366430282592773\n",
      "9 0.4952342212200165\n",
      "10 0.49461740255355835\n",
      "11 0.3588728904724121\n",
      "12 0.38362085819244385\n",
      "13 0.3460332751274109\n",
      "14 0.27301064133644104\n",
      "15 0.3041772246360779\n",
      "16 0.17086493968963623\n",
      "17 0.1878538876771927\n",
      "18 0.13536803424358368\n",
      "19 0.09558942168951035\n",
      "20 0.11538588255643845\n",
      "21 0.05861338973045349\n",
      "22 0.09625145047903061\n",
      "23 0.025298967957496643\n",
      "24 0.0627502053976059\n",
      "25 0.021548422053456306\n",
      "26 0.023146869614720345\n",
      "27 0.028268352150917053\n",
      "28 0.009926830418407917\n",
      "29 0.004722855519503355\n",
      "30 0.006462582387030125\n",
      "31 0.008517257869243622\n",
      "32 0.004243523348122835\n",
      "33 0.001863093813881278\n",
      "34 0.0028166354168206453\n",
      "35 0.0008132963557727635\n",
      "36 0.0017218703869730234\n",
      "37 0.002747289603576064\n",
      "38 0.013236569240689278\n",
      "39 0.00022854720009490848\n",
      "40 0.0013561408268287778\n",
      "41 0.005263748578727245\n",
      "42 0.0004280540451873094\n",
      "43 0.0007149492157623172\n",
      "44 0.002675286727026105\n",
      "45 0.0005667372024618089\n",
      "46 0.0002996373805217445\n",
      "47 0.00048362064990215003\n",
      "48 0.0001389920071233064\n",
      "49 0.002396358409896493\n",
      "50 0.0001853124558692798\n",
      "51 0.000681855424772948\n",
      "52 0.00026042392710223794\n",
      "53 0.005131401587277651\n",
      "54 0.00015113376139197499\n",
      "55 0.0028389550279825926\n",
      "56 0.0001967303396668285\n",
      "57 0.00030859242542646825\n",
      "58 0.0005749932606704533\n",
      "59 0.00011209550575586036\n",
      "60 0.00046758397365920246\n",
      "61 0.00020371524442452937\n",
      "62 0.0015608149114996195\n",
      "63 8.418197103310376e-05\n",
      "64 4.919292405247688e-05\n",
      "65 0.0001129878219217062\n",
      "66 0.000150422565639019\n",
      "67 0.0003526175278238952\n",
      "68 0.0002631103852763772\n",
      "69 0.00016598351066932082\n",
      "70 7.854914292693138e-05\n",
      "71 0.00030802295077592134\n",
      "72 0.000252491794526577\n",
      "73 5.029546809964813e-05\n",
      "74 8.238524969783612e-06\n",
      "75 0.00011125793389510363\n",
      "76 7.871133857406676e-05\n",
      "77 0.0001239079429069534\n",
      "78 3.626875331974588e-05\n",
      "79 6.036915146978572e-05\n",
      "80 0.0001226177701028064\n",
      "81 1.5958021322148852e-05\n",
      "82 0.0008192112436518073\n",
      "83 1.2475742551032454e-05\n",
      "84 4.6170243876986206e-05\n",
      "85 1.1564348824322224e-05\n",
      "86 0.00013353653775993735\n",
      "87 5.642295491270488e-06\n",
      "88 0.0002067197347059846\n",
      "89 0.00012996094301342964\n",
      "90 2.5503917640889995e-05\n",
      "91 1.7311964256805368e-05\n",
      "92 0.0003341109259054065\n",
      "93 6.833310180809349e-05\n",
      "94 7.403988547594054e-06\n",
      "95 2.788638994388748e-05\n",
      "96 1.3222747838881332e-05\n",
      "97 3.8875452446518466e-05\n",
      "98 1.7313404896412976e-05\n",
      "99 2.642911385919433e-05\n",
      "3\n",
      "0 0.6996129751205444\n",
      "1 0.7004366517066956\n",
      "2 0.6787036657333374\n",
      "3 0.6597052812576294\n",
      "4 0.624618649482727\n",
      "5 0.5845910310745239\n",
      "6 0.5262323021888733\n",
      "7 0.4642714858055115\n",
      "8 0.9676598906517029\n",
      "9 0.3961777985095978\n",
      "10 0.5435163378715515\n",
      "11 0.4603942334651947\n",
      "12 0.4375828802585602\n",
      "13 0.45653465390205383\n",
      "14 0.45309731364250183\n",
      "15 0.4104762375354767\n",
      "16 0.37637996673583984\n",
      "17 0.34174466133117676\n",
      "18 0.3397330343723297\n",
      "19 0.26641950011253357\n",
      "20 0.20665939152240753\n",
      "21 0.1914622187614441\n",
      "22 0.17663520574569702\n",
      "23 0.09685014933347702\n",
      "24 0.09609530121088028\n",
      "25 0.07995468378067017\n",
      "26 0.04841466248035431\n",
      "27 0.04926137998700142\n",
      "28 0.023682456463575363\n",
      "29 0.023908309638500214\n",
      "30 0.015508792363107204\n",
      "31 0.010262470692396164\n",
      "32 0.012959311716258526\n",
      "33 0.026133155450224876\n",
      "34 0.0054707396775484085\n",
      "35 0.038349322974681854\n",
      "36 0.004238999914377928\n",
      "37 0.010060371831059456\n",
      "38 0.028034167364239693\n",
      "39 0.007296521682292223\n",
      "40 0.000986799830570817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 0.004919049795717001\n",
      "42 0.02226395532488823\n",
      "43 0.004142886493355036\n",
      "44 0.00392482103779912\n",
      "45 0.0030320847872644663\n",
      "46 0.005289600230753422\n",
      "47 0.0010685318848118186\n",
      "48 0.0012341232504695654\n",
      "49 0.0020123557187616825\n",
      "50 0.0048845550045371056\n",
      "51 0.005941338371485472\n",
      "52 0.004332779906690121\n",
      "53 0.0008416922646574676\n",
      "54 0.0006986981024965644\n",
      "55 0.000515699153766036\n",
      "56 0.0007105037220753729\n",
      "57 0.0024445513263344765\n",
      "58 0.0009256525663658977\n",
      "59 0.0001923310774145648\n",
      "60 0.001432589953765273\n",
      "61 0.0003371386555954814\n",
      "62 0.0010056642349809408\n",
      "63 0.0020551939960569143\n",
      "64 0.0002942959254141897\n",
      "65 0.00039617024594917893\n",
      "66 0.0002866090217139572\n",
      "67 0.00010203697456745431\n",
      "68 8.452918700641021e-05\n",
      "69 0.000345304433722049\n",
      "70 0.0001613888452993706\n",
      "71 0.00010912789002759382\n",
      "72 0.0001877938339021057\n",
      "73 0.00010561483213678002\n",
      "74 0.00012802916171494871\n",
      "75 0.00011460151290521026\n",
      "76 0.0002159714640583843\n",
      "77 0.0005787283880636096\n",
      "78 0.0001610374019946903\n",
      "79 0.00046687599387951195\n",
      "80 0.00021405829465948045\n",
      "81 0.0009160615154542029\n",
      "82 0.00013399576710071415\n",
      "83 0.002192042302340269\n",
      "84 0.00012254194007255137\n",
      "85 6.943949119886383e-05\n",
      "86 0.0001993233454413712\n",
      "87 0.0002387342683505267\n",
      "88 0.0004005902446806431\n",
      "89 0.0001005671510938555\n",
      "90 0.00010332917736377567\n",
      "91 0.00010667711467249319\n",
      "92 6.644543464062735e-05\n",
      "93 0.00019839125161524862\n",
      "94 6.604671943932772e-05\n",
      "95 0.00024012042558752\n",
      "96 7.69264588598162e-05\n",
      "97 0.00010896260209847242\n",
      "98 0.00030074373353272676\n",
      "99 6.897218554513529e-05\n",
      "4\n",
      "0 0.6964707970619202\n",
      "1 0.6861034631729126\n",
      "2 0.6504544615745544\n",
      "3 0.6106598973274231\n",
      "4 0.5590139031410217\n",
      "5 0.5759583115577698\n",
      "6 0.6495360732078552\n",
      "7 0.4875442385673523\n",
      "8 0.4834166467189789\n",
      "9 0.4914722740650177\n",
      "10 0.40913450717926025\n",
      "11 0.3721092641353607\n",
      "12 0.3349209725856781\n",
      "13 0.2608689069747925\n",
      "14 0.22068467736244202\n",
      "15 0.16740857064723969\n",
      "16 0.11825809627771378\n",
      "17 0.09991365671157837\n",
      "18 0.05291512981057167\n",
      "19 0.09976744651794434\n",
      "20 0.04331883788108826\n",
      "21 0.06843962520360947\n",
      "22 0.018615810200572014\n",
      "23 0.022231994196772575\n",
      "24 0.030268287286162376\n",
      "25 0.010537378489971161\n",
      "26 0.005597364157438278\n",
      "27 0.021674783900380135\n",
      "28 0.007687567733228207\n",
      "29 0.010068473406136036\n",
      "30 0.0024311961606144905\n",
      "31 0.0023876952473074198\n",
      "32 0.004143336787819862\n",
      "33 0.0030536476988345385\n",
      "34 0.006515156012028456\n",
      "35 0.0014765540836378932\n",
      "36 0.00255799968726933\n",
      "37 0.0019689565524458885\n",
      "38 0.0013033035211265087\n",
      "39 0.001221263431943953\n",
      "40 0.003579468932002783\n",
      "41 0.0008100125123746693\n",
      "42 0.0009940080344676971\n",
      "43 0.0005765834357589483\n",
      "44 0.00018439421546645463\n",
      "45 0.0006721712416037917\n",
      "46 0.0003003134625032544\n",
      "47 0.0005543277366086841\n",
      "48 0.0005845288978889585\n",
      "49 0.0017856663325801492\n",
      "50 0.0005262436461634934\n",
      "51 0.00019540659559424967\n",
      "52 0.0004235881788190454\n",
      "53 0.00045388718717731535\n",
      "54 0.0008436758653260767\n",
      "55 0.00024081391165964305\n",
      "56 0.0003522582119330764\n",
      "57 6.664838292635977e-05\n",
      "58 0.0006061175954528153\n",
      "59 0.0001785002532415092\n",
      "60 7.844129140721634e-05\n",
      "61 0.00011720901966327801\n",
      "62 0.0010842179181054235\n",
      "63 0.00020798714831471443\n",
      "64 8.16682368167676e-05\n",
      "65 4.327464193920605e-05\n",
      "66 7.344160985667259e-05\n",
      "67 2.4240192942670546e-05\n",
      "68 5.0032336730509996e-05\n",
      "69 0.00012910016812384129\n",
      "70 6.576730811502784e-05\n",
      "71 2.7484145903144963e-05\n",
      "72 0.0007559924270026386\n",
      "73 0.0004946752451360226\n",
      "74 0.0003123491769656539\n",
      "75 4.518238711170852e-05\n",
      "76 0.00012082537432434037\n",
      "77 2.2622261894866824e-05\n",
      "78 4.3133044528076425e-05\n",
      "79 5.699214307242073e-05\n",
      "80 3.3387786970706657e-05\n",
      "81 2.706311715883203e-05\n",
      "82 4.610651376424357e-05\n",
      "83 0.0001005241647362709\n",
      "84 0.00013822915207128972\n",
      "85 6.930158997420222e-05\n",
      "86 3.0963907192926854e-05\n",
      "87 4.572308171191253e-05\n",
      "88 3.7576293834717944e-05\n",
      "89 0.0001239370321854949\n",
      "90 2.0742789274663664e-05\n",
      "91 1.4744769941898994e-05\n",
      "92 8.790631545707583e-05\n",
      "93 2.730570668063592e-05\n",
      "94 8.926404916564934e-06\n",
      "95 3.372027276782319e-05\n",
      "96 2.012046388699673e-05\n",
      "97 5.8043209719471633e-05\n",
      "98 3.573650974431075e-05\n",
      "99 8.721744961803779e-06\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 200\n",
    "HIDDEN_DIM = 50\n",
    "OUTPUT_SIZE_1 = 10\n",
    "COMBINE_FUNCS =[torch.mean, torch.max]\n",
    "OUTPUT_SIZE_2 = 1\n",
    "N_LAYERS = 1\n",
    "DROPOUT_PROB = 0.5\n",
    "HIDDEN_INITIAL = (torch.randn(1, 1, HIDDEN_DIM), torch.randn(1, 1, HIDDEN_DIM))\n",
    "\n",
    "scores_first = []\n",
    "scores_last = []\n",
    "scores_best = []\n",
    "scores_ideal = []\n",
    "for i in range(5):\n",
    "    model = LSTMNet(OUTPUT_SIZE_1, OUTPUT_SIZE_2, N_LAYERS, EMBEDDING_DIM, HIDDEN_DIM, \\\n",
    "                COMBINE_FUNCS, HIDDEN_INITIAL,DROPOUT_PROB)\n",
    "    lr = 0.01\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    print(i)\n",
    "    epochs = 100\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    test_acc = []\n",
    "    model.train()\n",
    "    for j in range(epochs):\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        output = model(X_train)\n",
    "        loss = criterion(output.squeeze(), y_train.float())\n",
    "        loss.backward()\n",
    "        print(j, loss.item())\n",
    "    #     nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        model.eval()\n",
    "        outs = model(X_train)\n",
    "        train_acc.append(torch.sum((outs > 0.5) == y_train).item() / len(y_train))\n",
    "\n",
    "        outs = model(X_val)\n",
    "        val_acc.append(torch.sum((outs > 0.5) == y_val).item() / len(y_val))\n",
    "\n",
    "        outs = model(X_test)\n",
    "        test_acc.append(torch.sum((outs > 0.5) == y_test).item() / len(y_test))\n",
    "    scores_first.append(best_testing(train_acc, val_acc, test_acc, 'first'))\n",
    "    scores_last.append(best_testing(train_acc, val_acc, test_acc, 'last'))\n",
    "    scores_best.append(best_testing(train_acc, val_acc, test_acc, 'best'))\n",
    "    scores_ideal.append(max(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6666666666666666, 0.5555555555555556, 0.6111111111111112, 0.6111111111111112, 0.7222222222222222]\n",
      "[0.6666666666666666, 0.6111111111111112, 0.4444444444444444, 0.6111111111111112, 0.7222222222222222]\n",
      "[0.6666666666666666, 0.6111111111111112, 0.6111111111111112, 0.6666666666666666, 0.7222222222222222]\n"
     ]
    }
   ],
   "source": [
    "print(scores_first)\n",
    "print(scores_last)\n",
    "print(scores_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7222222222222222,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.7222222222222222]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6333333333333334\n",
      "0.611111111111111\n",
      "0.6555555555555556\n"
     ]
    }
   ],
   "source": [
    "print(np.mean([0.6666666666666666, 0.5555555555555556, 0.6111111111111112, 0.6111111111111112, 0.7222222222222222]))\n",
    "print(np.mean([0.6666666666666666, 0.6111111111111112, 0.4444444444444444, 0.6111111111111112, 0.7222222222222222]))\n",
    "print(np.mean([0.6666666666666666, 0.6111111111111112, 0.6111111111111112, 0.6666666666666666, 0.7222222222222222]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiments(OUTPUT_SIZE_1, OUTPUT_SIZE_2, N_LAYERS, EMBEDDING_DIM, HIDDEN_DIM, \\\n",
    "                COMBINE_FUNCS, HIDDEN_INITIAL,DROPOUT_PROB, epochs, iterations):\n",
    "    scores_first = []\n",
    "    scores_last = []\n",
    "    scores_best = []\n",
    "    scores_ideal = []\n",
    "    for i in range(iterations):\n",
    "        model = LSTMNet(OUTPUT_SIZE_1, OUTPUT_SIZE_2, N_LAYERS, EMBEDDING_DIM, HIDDEN_DIM, \\\n",
    "                    COMBINE_FUNCS, HIDDEN_INITIAL,DROPOUT_PROB)\n",
    "        lr = 0.01\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        print(i)\n",
    "        epochs = 100\n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "        test_acc = []\n",
    "        model.train()\n",
    "        for j in range(epochs):\n",
    "            model.train()\n",
    "            model.zero_grad()\n",
    "            output = model(X_train)\n",
    "            loss = criterion(output.squeeze(), y_train.float())\n",
    "            loss.backward()\n",
    "            print(j, loss.item())\n",
    "        #     nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "            model.eval()\n",
    "            outs = model(X_train)\n",
    "            train_acc.append(torch.sum((outs > 0.5) == y_train).item() / len(y_train))\n",
    "\n",
    "            outs = model(X_val)\n",
    "            val_acc.append(torch.sum((outs > 0.5) == y_val).item() / len(y_val))\n",
    "\n",
    "            outs = model(X_test)\n",
    "            test_acc.append(torch.sum((outs > 0.5) == y_test).item() / len(y_test))\n",
    "        scores_first.append(best_testing(train_acc, val_acc, test_acc, 'first'))\n",
    "        scores_last.append(best_testing(train_acc, val_acc, test_acc, 'last'))\n",
    "        scores_best.append(best_testing(train_acc, val_acc, test_acc, 'best'))\n",
    "        scores_ideal.append(max(test_acc))\n",
    "    return {'scores_first': scores_first, 'scores_last':scores_last, 'scores_best': scores_best,\\\n",
    "            'scores_ideal': scores_ideal}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0 0.692461371421814\n",
      "1 0.6992563009262085\n",
      "2 0.7053745985031128\n",
      "3 0.6433932185173035\n",
      "4 0.6455641388893127\n",
      "5 0.5831127166748047\n",
      "6 0.5695322155952454\n",
      "7 0.5123856663703918\n",
      "8 0.4302937984466553\n",
      "9 0.46260249614715576\n",
      "10 0.5037082433700562\n",
      "11 0.28780397772789\n",
      "12 0.3343343436717987\n",
      "13 0.23296186327934265\n",
      "14 0.1974794715642929\n",
      "15 0.18263038992881775\n",
      "16 0.12879228591918945\n",
      "17 0.10432902723550797\n",
      "18 0.09088485687971115\n",
      "19 0.03890206292271614\n",
      "20 0.08015084266662598\n",
      "21 0.03352430462837219\n",
      "22 0.011639142408967018\n",
      "23 0.009348778985440731\n",
      "24 0.013669260777533054\n",
      "25 0.011623789556324482\n",
      "26 0.0026759812608361244\n",
      "27 0.0038343940395861864\n",
      "28 0.005150455050170422\n",
      "29 0.002095646457746625\n",
      "30 0.0017128227045759559\n",
      "31 0.0017323895590379834\n",
      "32 0.0004983210819773376\n",
      "33 0.002153074834495783\n",
      "34 0.000864803500007838\n",
      "35 0.00015211457503028214\n",
      "36 0.00020961319387424737\n",
      "37 0.0010445406660437584\n",
      "38 0.0002412034955341369\n",
      "39 7.070325955282897e-05\n",
      "40 0.00010290680802427232\n",
      "41 0.003673143684864044\n",
      "42 0.0007030570995993912\n",
      "43 0.0001071984734153375\n",
      "44 0.0006327225710265338\n",
      "45 0.0007868743850849569\n",
      "46 0.0033369313459843397\n",
      "47 9.966169454855844e-05\n",
      "48 0.00023814624000806361\n",
      "49 5.2624829550040886e-05\n",
      "50 0.00034378402051515877\n",
      "51 0.001968494150787592\n",
      "52 3.404431481612846e-05\n",
      "53 0.00021505399490706623\n",
      "54 0.0004211647028569132\n",
      "55 5.559475175687112e-05\n",
      "56 2.8865055355709046e-05\n",
      "57 2.4812128685880452e-05\n",
      "58 0.001093873055651784\n",
      "59 8.022669135243632e-06\n",
      "60 0.0007006576634012163\n",
      "61 1.595993308001198e-05\n",
      "62 0.0002640568127389997\n",
      "63 8.56118494994007e-05\n",
      "64 0.00013403045886661857\n",
      "65 0.0006941698957234621\n",
      "66 5.314617374096997e-05\n",
      "67 9.079019218916073e-05\n",
      "68 1.9029776012757793e-05\n",
      "69 5.190504089114256e-05\n",
      "70 0.000428418890805915\n",
      "71 1.7608384951017797e-05\n",
      "72 1.6453270291094668e-05\n",
      "73 0.00010825799108715728\n",
      "74 6.702368409605697e-05\n",
      "75 2.1226637727522757e-06\n",
      "76 1.8368342352914624e-05\n",
      "77 1.0294122603227152e-06\n",
      "78 3.458616447460372e-06\n",
      "79 5.9718513512052596e-05\n",
      "80 7.187655137386173e-05\n",
      "81 6.400734037015354e-06\n",
      "82 2.671048378033447e-06\n",
      "83 4.024484951514751e-05\n",
      "84 2.0303481505834498e-05\n",
      "85 0.0008377841440960765\n",
      "86 8.669709495734423e-05\n",
      "87 5.9685691667255014e-05\n",
      "88 1.4601751900045201e-05\n",
      "89 1.1275897122686729e-06\n",
      "90 1.8449817389409873e-06\n",
      "91 4.30605468864087e-05\n",
      "92 4.9832751756184734e-06\n",
      "93 2.579209194664145e-06\n",
      "94 2.1170731088204775e-06\n",
      "95 1.2597187378560193e-05\n",
      "96 6.746373401256278e-05\n",
      "97 1.4304426258604508e-05\n",
      "98 4.291674940759549e-06\n",
      "99 7.03911209711805e-05\n",
      "1\n",
      "0 0.6905900239944458\n",
      "1 0.6875119805335999\n",
      "2 0.6826069355010986\n",
      "3 0.6279881000518799\n",
      "4 0.5844740271568298\n",
      "5 0.5658332109451294\n",
      "6 0.49232012033462524\n",
      "7 0.3856073319911957\n",
      "8 0.33354878425598145\n",
      "9 0.47641804814338684\n",
      "10 0.3932267725467682\n",
      "11 0.273441344499588\n",
      "12 0.23489819467067719\n",
      "13 0.19232337176799774\n",
      "14 0.157307431101799\n",
      "15 0.1354653686285019\n",
      "16 0.16800522804260254\n",
      "17 0.054517026990652084\n",
      "18 0.07605195790529251\n",
      "19 0.0713815838098526\n",
      "20 0.027892649173736572\n",
      "21 0.01938563585281372\n",
      "22 0.013492079451680183\n",
      "23 0.022646810859441757\n",
      "24 0.011298890225589275\n",
      "25 0.010310808196663857\n",
      "26 0.004773316439241171\n",
      "27 0.00719187268987298\n",
      "28 0.005714875645935535\n",
      "29 0.007253346033394337\n",
      "30 0.0018429787596687675\n",
      "31 0.0008680617320351303\n",
      "32 0.00016095027967821807\n",
      "33 0.0003584949881769717\n",
      "34 0.00042686419328674674\n",
      "35 0.0014106121379882097\n",
      "36 0.0006488566286861897\n",
      "37 0.0011801245855167508\n",
      "38 0.0002236127038486302\n",
      "39 0.0002744423400145024\n",
      "40 0.0004726612532977015\n",
      "41 0.00012236752081662416\n",
      "42 0.0001916922628879547\n",
      "43 0.0002443433040753007\n",
      "44 0.0001991044555325061\n",
      "45 0.0005191840464249253\n",
      "46 0.001024065539240837\n",
      "47 9.298937948187813e-05\n",
      "48 7.951314182719216e-05\n",
      "49 0.00021514343097805977\n",
      "50 0.0002667151275090873\n",
      "51 2.3907025024527684e-05\n",
      "52 3.118082895525731e-05\n",
      "53 0.00026728486409410834\n",
      "54 0.001298457384109497\n",
      "55 5.5096836149459705e-05\n",
      "56 2.8311937057878822e-05\n",
      "57 0.00013697364192921668\n",
      "58 0.00010987590212607756\n",
      "59 5.929831331741298e-06\n",
      "60 1.7158490663859993e-05\n",
      "61 0.0002615865378174931\n",
      "62 9.41278904065257e-06\n",
      "63 7.206533337011933e-05\n",
      "64 0.00015227719268295914\n",
      "65 1.6548065104871057e-05\n",
      "66 1.39648736876552e-05\n",
      "67 6.52272065053694e-05\n",
      "68 1.7527439922560006e-05\n",
      "69 4.8401238018414006e-05\n",
      "70 2.8893580747535452e-05\n",
      "71 9.874195529846475e-05\n",
      "72 5.217327270656824e-06\n",
      "73 1.3339891665964387e-05\n",
      "74 2.55006889346987e-05\n",
      "75 7.787629328959156e-06\n",
      "76 6.169067637529224e-05\n",
      "77 5.158334533916786e-05\n",
      "78 1.3814871635986492e-05\n",
      "79 0.0001254130620509386\n",
      "80 6.0684371419483796e-05\n",
      "81 3.218121491954662e-05\n",
      "82 5.244001840765122e-06\n",
      "83 0.0002996772527694702\n",
      "84 2.6921632525045425e-05\n",
      "85 3.838745760731399e-05\n",
      "86 1.9237544620409608e-05\n",
      "87 3.040804404008668e-05\n",
      "88 7.504815584979951e-05\n",
      "89 1.215054089698242e-05\n",
      "90 6.492416559922276e-06\n",
      "91 3.193498969267239e-06\n",
      "92 1.6175477867363952e-05\n",
      "93 6.0266535001574084e-05\n",
      "94 1.69802297023125e-05\n",
      "95 3.312148692202754e-05\n",
      "96 1.1591830116230994e-05\n",
      "97 1.2488419088185765e-05\n",
      "98 0.00023550748301204294\n",
      "99 0.0002689858083613217\n",
      "2\n",
      "0 0.6906633973121643\n",
      "1 0.726360023021698\n",
      "2 0.7099995017051697\n",
      "3 0.6631326079368591\n",
      "4 0.6508861780166626\n",
      "5 0.6401939392089844\n",
      "6 0.6129682660102844\n",
      "7 0.5684284567832947\n",
      "8 0.519451916217804\n",
      "9 0.459286093711853\n",
      "10 0.44466522336006165\n",
      "11 0.36599135398864746\n",
      "12 0.27610960602760315\n",
      "13 0.274478018283844\n",
      "14 0.22107332944869995\n",
      "15 0.15469008684158325\n",
      "16 0.095574289560318\n",
      "17 0.06614235043525696\n",
      "18 0.05358976870775223\n",
      "19 0.054970428347587585\n",
      "20 0.04486935958266258\n",
      "21 0.07862146943807602\n",
      "22 0.04502885043621063\n",
      "23 0.08756622672080994\n",
      "24 0.02410736121237278\n",
      "25 0.13280126452445984\n",
      "26 0.006646287627518177\n",
      "27 0.23021641373634338\n",
      "28 0.01142464205622673\n",
      "29 0.016239620745182037\n",
      "30 0.036795470863580704\n",
      "31 0.09892648458480835\n",
      "32 0.015807271003723145\n",
      "33 0.00602211058139801\n",
      "34 0.06395526975393295\n",
      "35 0.025288470089435577\n",
      "36 0.005990861915051937\n",
      "37 0.01322250533849001\n",
      "38 0.02384488470852375\n",
      "39 0.008971156552433968\n",
      "40 0.03912004828453064\n",
      "41 0.005525860004127026\n",
      "42 0.004457300994545221\n",
      "43 0.005690703634172678\n",
      "44 0.0010026659583672881\n",
      "45 0.0011533118085935712\n",
      "46 0.004401779733598232\n",
      "47 0.009615354239940643\n",
      "48 0.017614157870411873\n",
      "49 0.002098476979881525\n",
      "50 0.002427434315904975\n",
      "51 0.001955057494342327\n",
      "52 0.005623806733638048\n",
      "53 0.0009337261435575783\n",
      "54 0.0005767153925262392\n",
      "55 0.0003832440706901252\n",
      "56 0.001524473656900227\n",
      "57 0.0015948349609971046\n",
      "58 0.00055859045824036\n",
      "59 0.018973100930452347\n",
      "60 0.0007127677672542632\n",
      "61 0.0034796325489878654\n",
      "62 0.0004565610724966973\n",
      "63 0.00039621529867872596\n",
      "64 0.0005855484050698578\n",
      "65 0.0010664367582648993\n",
      "66 0.0015320791862905025\n",
      "67 0.0016798418946564198\n",
      "68 0.0005308078834787011\n",
      "69 0.0008031624020077288\n",
      "70 0.00025430769892409444\n",
      "71 0.0004444693913683295\n",
      "72 0.00012799208343494684\n",
      "73 0.0005935192457400262\n",
      "74 0.0006825589225627482\n",
      "75 0.0005831611342728138\n",
      "76 0.001400423003360629\n",
      "77 0.00016706905444152653\n",
      "78 0.0009456280386075377\n",
      "79 0.00018835210357792675\n",
      "80 0.0018118689768016338\n",
      "81 0.00022325848112814128\n",
      "82 0.0004433566064108163\n",
      "83 0.0009938279399648309\n",
      "84 0.0002713798894546926\n",
      "85 0.0008827924611978233\n",
      "86 0.001178809441626072\n",
      "87 0.0008081269334070385\n",
      "88 0.0008050736505538225\n",
      "89 0.00014617727720178664\n",
      "90 8.192912355298176e-05\n",
      "91 8.716979209566489e-05\n",
      "92 0.00019125714607071131\n",
      "93 0.00022043405624572188\n",
      "94 0.0006132069975137711\n",
      "95 0.00013263271830510348\n",
      "96 0.0003509212692733854\n",
      "97 8.206023630918935e-05\n",
      "98 0.00015163041825871915\n",
      "99 4.70951636089012e-05\n",
      "3\n",
      "0 0.6977810263633728\n",
      "1 0.7313553094863892\n",
      "2 0.6919086575508118\n",
      "3 0.6826561689376831\n",
      "4 0.6462830305099487\n",
      "5 0.6354137063026428\n",
      "6 0.5811532139778137\n",
      "7 0.5521939396858215\n",
      "8 0.4883635938167572\n",
      "9 0.45172348618507385\n",
      "10 0.3780333697795868\n",
      "11 0.32736697793006897\n",
      "12 0.6278128027915955\n",
      "13 0.22510674595832825\n",
      "14 0.38498377799987793\n",
      "15 0.24790483713150024\n",
      "16 0.1834232062101364\n",
      "17 0.20960962772369385\n",
      "18 0.2010478526353836\n",
      "19 0.15127936005592346\n",
      "20 0.10020901262760162\n",
      "21 0.09125244617462158\n",
      "22 0.0902625322341919\n",
      "23 0.05808668211102486\n",
      "24 0.059410739690065384\n",
      "25 0.02814783714711666\n",
      "26 0.019830232486128807\n",
      "27 0.013334679417312145\n",
      "28 0.03155501186847687\n",
      "29 0.007342166267335415\n",
      "30 0.009422936476767063\n",
      "31 0.008760392665863037\n",
      "32 0.003125404706224799\n",
      "33 0.0026304172351956367\n",
      "34 0.009211741387844086\n",
      "35 0.0023883734829723835\n",
      "36 0.0018323074327781796\n",
      "37 0.0007051524589769542\n",
      "38 0.001008097780868411\n",
      "39 0.0027259045746177435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 0.00439026253297925\n",
      "41 0.0017909924499690533\n",
      "42 0.0002958676777780056\n",
      "43 0.003625099081546068\n",
      "44 0.0004250875790603459\n",
      "45 0.0005669035599566996\n",
      "46 0.0003442463930696249\n",
      "47 0.000421640754211694\n",
      "48 0.0014660283923149109\n",
      "49 5.894234709558077e-05\n",
      "50 0.00016095150203909725\n",
      "51 0.0001521232770755887\n",
      "52 0.00036158348666504025\n",
      "53 0.0001563687255838886\n",
      "54 6.47132474114187e-05\n",
      "55 0.00015076583076734096\n",
      "56 7.052700675558299e-05\n",
      "57 0.00018036054098047316\n",
      "58 0.0003520035825204104\n",
      "59 0.000538146123290062\n",
      "60 0.0010035440791398287\n",
      "61 0.00024292523448821157\n",
      "62 7.560364610981196e-05\n",
      "63 5.339087874745019e-05\n",
      "64 0.00021208969701547176\n",
      "65 0.0007186196162365377\n",
      "66 0.00020314678840804845\n",
      "67 6.187775579746813e-05\n",
      "68 4.7353758418466896e-05\n",
      "69 0.000153830973431468\n",
      "70 0.00016228716413024813\n",
      "71 0.0005045332363806665\n",
      "72 0.00017113178910221905\n",
      "73 0.0006377322133630514\n",
      "74 7.073706365190446e-05\n",
      "75 7.397789158858359e-05\n",
      "76 0.00027394830249249935\n",
      "77 0.00017807501717470586\n",
      "78 0.0007404926000162959\n",
      "79 0.00012300204252824187\n",
      "80 3.547864980646409e-05\n",
      "81 3.417912739678286e-05\n",
      "82 0.00011434278712840751\n",
      "83 3.6751422157976776e-05\n",
      "84 3.949779784306884e-05\n",
      "85 5.193598190089688e-05\n",
      "86 2.4429968107142486e-05\n",
      "87 0.0001395871804561466\n",
      "88 1.8078580978908576e-05\n",
      "89 1.5561374311801046e-05\n",
      "90 4.2691903217928484e-05\n",
      "91 3.257428033975884e-05\n",
      "92 1.9580866137403063e-05\n",
      "93 1.2094292287656572e-05\n",
      "94 0.0002239621098851785\n",
      "95 3.3808668376877904e-05\n",
      "96 1.9120889191981405e-05\n",
      "97 2.633307667565532e-05\n",
      "98 4.311891461838968e-05\n",
      "99 1.3499252418114338e-05\n",
      "4\n",
      "0 0.6988069415092468\n",
      "1 0.654883623123169\n",
      "2 0.6716131567955017\n",
      "3 0.6472628712654114\n",
      "4 0.5975777506828308\n",
      "5 0.5121920108795166\n",
      "6 0.46872249245643616\n",
      "7 0.6461350321769714\n",
      "8 0.4099769592285156\n",
      "9 0.44577160477638245\n",
      "10 0.34738558530807495\n",
      "11 0.3441002666950226\n",
      "12 0.3153352439403534\n",
      "13 0.22629858553409576\n",
      "14 0.2502855956554413\n",
      "15 0.1659008115530014\n",
      "16 0.11110568046569824\n",
      "17 0.14103727042675018\n",
      "18 0.07717710733413696\n",
      "19 0.04910163953900337\n",
      "20 0.0564422607421875\n",
      "21 0.03331441804766655\n",
      "22 0.01716112717986107\n",
      "23 0.016893377527594566\n",
      "24 0.019114922732114792\n",
      "25 0.010893885046243668\n",
      "26 0.0030440811533480883\n",
      "27 0.003099879715591669\n",
      "28 0.005313300993293524\n",
      "29 0.005811923183500767\n",
      "30 0.0018601400079205632\n",
      "31 0.0012828540056943893\n",
      "32 0.0022310398053377867\n",
      "33 0.0008475288632325828\n",
      "34 0.0003241347149014473\n",
      "35 0.00027408936875872314\n",
      "36 0.00040923862252384424\n",
      "37 0.0015181070193648338\n",
      "38 0.0011247663060203195\n",
      "39 0.00011308694229228422\n",
      "40 0.0009052992681972682\n",
      "41 0.0001997019280679524\n",
      "42 0.00043781186104752123\n",
      "43 8.145144965965301e-05\n",
      "44 0.00014478119555860758\n",
      "45 5.247112858342007e-05\n",
      "46 0.0013825332280248404\n",
      "47 0.00023244567273650318\n",
      "48 0.0009011240326799452\n",
      "49 0.00010204540740232915\n",
      "50 0.00115300714969635\n",
      "51 7.238020043587312e-05\n",
      "52 0.00027796579524874687\n",
      "53 3.0011311537236907e-05\n",
      "54 0.00013794547703582793\n",
      "55 0.0017244386253878474\n",
      "56 3.560242475941777e-05\n",
      "57 7.596146315336227e-05\n",
      "58 0.0007888272521086037\n",
      "59 1.0519546776777133e-05\n",
      "60 0.00013653207861352712\n",
      "61 2.423552723485045e-05\n",
      "62 6.46973930997774e-05\n",
      "63 7.744785762042738e-06\n",
      "64 2.1000731067033485e-05\n",
      "65 0.00011614679533522576\n",
      "66 0.00021842619753442705\n",
      "67 6.362759449984878e-05\n",
      "68 0.00012891214282717556\n",
      "69 2.0444404071895406e-05\n",
      "70 5.392183447838761e-05\n",
      "71 2.6750165488920175e-05\n",
      "72 2.4613211280666292e-05\n",
      "73 6.702063728880603e-06\n",
      "74 0.00010082224616780877\n",
      "75 2.352930277993437e-05\n",
      "76 7.641113370482344e-06\n",
      "77 4.355692908575293e-06\n",
      "78 1.3294798009155784e-05\n",
      "79 0.00012134400458307937\n",
      "80 5.709783727070317e-05\n",
      "81 2.2048250684747472e-05\n",
      "82 0.00017189413483720273\n",
      "83 9.754475286172237e-06\n",
      "84 8.154448551067617e-06\n",
      "85 3.1802271678316174e-06\n",
      "86 3.5011682484764606e-05\n",
      "87 0.00010087408736580983\n",
      "88 3.727240709849866e-06\n",
      "89 2.661245616764063e-06\n",
      "90 2.8863216812169412e-06\n",
      "91 8.25751521915663e-06\n",
      "92 3.0799478736298624e-06\n",
      "93 9.761190540302778e-07\n",
      "94 1.4670025620944216e-06\n",
      "95 2.0960133042535745e-06\n",
      "96 3.4698456147452816e-05\n",
      "97 6.887976724101463e-06\n",
      "98 2.077126737276558e-05\n",
      "99 1.3309543192008277e-06\n",
      "[0.5555555555555556, 0.6111111111111112, 0.5555555555555556, 0.6111111111111112, 0.6666666666666666]\n",
      "[0.5555555555555556, 0.5, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666]\n",
      "[0.5555555555555556, 0.6111111111111112, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666]\n",
      "[0.6666666666666666, 0.6666666666666666, 0.8333333333333334, 0.7222222222222222, 0.7222222222222222]\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 200\n",
    "HIDDEN_DIM = 50\n",
    "OUTPUT_SIZE_1 = 20\n",
    "COMBINE_FUNCS =[torch.mean, torch.max]\n",
    "OUTPUT_SIZE_2 = 1\n",
    "N_LAYERS = 1\n",
    "DROPOUT_PROB = 0.5\n",
    "HIDDEN_INITIAL = (torch.randn(1, 1, HIDDEN_DIM), torch.randn(1, 1, HIDDEN_DIM))\n",
    "\n",
    "scores_first = []\n",
    "scores_last = []\n",
    "scores_best = []\n",
    "scores_ideal = []\n",
    "for i in range(5):\n",
    "    model = LSTMNet(OUTPUT_SIZE_1, OUTPUT_SIZE_2, N_LAYERS, EMBEDDING_DIM, HIDDEN_DIM, \\\n",
    "                COMBINE_FUNCS, HIDDEN_INITIAL, DROPOUT_PROB)\n",
    "    lr = 0.01\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    print(i)\n",
    "    epochs = 100\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    test_acc = []\n",
    "    model.train()\n",
    "    for j in range(epochs):\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        output = model(X_train)\n",
    "        loss = criterion(output.squeeze(), y_train.float())\n",
    "        loss.backward()\n",
    "        print(j, loss.item())\n",
    "    #     nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        model.eval()\n",
    "        outs = model(X_train)\n",
    "        train_acc.append(torch.sum((outs > 0.5) == y_train).item() / len(y_train))\n",
    "\n",
    "        outs = model(X_val)\n",
    "        val_acc.append(torch.sum((outs > 0.5) == y_val).item() / len(y_val))\n",
    "\n",
    "        outs = model(X_test)\n",
    "        test_acc.append(torch.sum((outs > 0.5) == y_test).item() / len(y_test))\n",
    "    scores_first.append(best_testing(train_acc, val_acc, test_acc, 'first'))\n",
    "    scores_last.append(best_testing(train_acc, val_acc, test_acc, 'last'))\n",
    "    scores_best.append(best_testing(train_acc, val_acc, test_acc, 'best'))\n",
    "    scores_ideal.append(max(test_acc))\n",
    "print(scores_first)\n",
    "print(scores_last)\n",
    "print(scores_best)\n",
    "print(scores_ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Iteration</th>\n",
       "      <th>scores_first</th>\n",
       "      <th>scores_last</th>\n",
       "      <th>scores_best</th>\n",
       "      <th>scores_ideal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  # Iteration  scores_first  scores_last  scores_best  scores_ideal\n",
       "0           1      0.555556     0.555556     0.555556      0.666667\n",
       "1           2      0.611111     0.500000     0.611111      0.666667\n",
       "2           3      0.555556     0.666667     0.666667      0.833333\n",
       "3           4      0.611111     0.666667     0.666667      0.722222\n",
       "4           5      0.666667     0.666667     0.666667      0.722222\n",
       "5        mean      0.600000     0.611111     0.633333      0.722222"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterations = 5\n",
    "df = pd.DataFrame({'# Iteration': list(range(1,iterations + 1)) + ['mean'], \\\n",
    "                   'scores_first': scores_first + [np.mean(scores_first)],\\\n",
    "                         'scores_last': scores_last + [np.mean(scores_last)], \\\n",
    "                   'scores_best': scores_best + [np.mean(scores_best)], \\\n",
    "                   'scores_ideal': scores_ideal + [np.mean(scores_ideal)]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HIDDEN_DIM = 30, output_size_1 = 10, 2 fcs, [torch.mean, torch.max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0 0.7209392786026001\n",
      "1 0.6991881132125854\n",
      "2 0.6680363416671753\n",
      "3 0.6521626710891724\n",
      "4 0.6394084095954895\n",
      "5 0.6030824780464172\n",
      "6 0.5655356049537659\n",
      "7 0.5466874241828918\n",
      "8 0.45585665106773376\n",
      "9 0.43434277176856995\n",
      "10 0.3985781967639923\n",
      "11 0.3104100525379181\n",
      "12 0.2596261501312256\n",
      "13 0.2660207450389862\n",
      "14 0.16194190084934235\n",
      "15 0.18888992071151733\n",
      "16 0.10979588329792023\n",
      "17 0.15166625380516052\n",
      "18 0.08165708929300308\n",
      "19 0.07200481742620468\n",
      "20 0.017080184072256088\n",
      "21 0.04558799788355827\n",
      "22 0.02976216934621334\n",
      "23 0.03545723855495453\n",
      "24 0.006710705813020468\n",
      "25 0.021947519853711128\n",
      "26 0.014621886424720287\n",
      "27 0.016545668244361877\n",
      "28 0.010586890392005444\n",
      "29 0.004534859210252762\n",
      "30 0.007739148568361998\n",
      "31 0.01846708543598652\n",
      "32 0.010698042809963226\n",
      "33 0.003819498233497143\n",
      "34 0.0007363728946074843\n",
      "35 0.010628625750541687\n",
      "36 0.0018541236640885472\n",
      "37 0.0008499554242007434\n",
      "38 0.0007881139754317701\n",
      "39 0.0010979649377986789\n",
      "40 0.004891460761427879\n",
      "41 0.000523023831192404\n",
      "42 0.01968265138566494\n",
      "43 0.00045333345769904554\n",
      "44 0.0010751835070550442\n",
      "45 0.00400423351675272\n",
      "46 0.00016247159510385245\n",
      "47 0.0005751848220825195\n",
      "48 0.0073306867852807045\n",
      "49 0.0021614201832562685\n",
      "50 0.0037419027648866177\n",
      "51 0.006730254273861647\n",
      "52 0.0003926310164388269\n",
      "53 0.0006311578908935189\n",
      "54 0.00041607514140196145\n",
      "55 0.000799065048340708\n",
      "56 0.00275069079361856\n",
      "57 0.003027882194146514\n",
      "58 0.0004013282305095345\n",
      "59 0.00037402287125587463\n",
      "60 0.0017576906830072403\n",
      "61 0.0010174488415941596\n",
      "62 0.0013808354269713163\n",
      "63 0.00019273308862466365\n",
      "64 5.3949548600940034e-05\n",
      "65 0.00027908087940886617\n",
      "66 4.708062260760926e-05\n",
      "67 0.0008933499339036644\n",
      "68 0.00016045015945564955\n",
      "69 0.00020609244529623538\n",
      "70 8.161787263816223e-05\n",
      "71 0.0002701596822589636\n",
      "72 5.226982830208726e-05\n",
      "73 9.479455911787227e-05\n",
      "74 0.0013499038759618998\n",
      "75 5.4709420510334894e-05\n",
      "76 3.8746424252167344e-05\n",
      "77 0.00015691012958995998\n",
      "78 5.2759089157916605e-05\n",
      "79 0.0006480003939941525\n",
      "80 0.000231125857681036\n",
      "81 0.00011799334606621414\n",
      "82 5.07927434227895e-05\n",
      "83 0.0002953740186057985\n",
      "84 0.003266708692535758\n",
      "85 0.00012483535101637244\n",
      "86 0.00028573337476700544\n",
      "87 7.055499736452475e-05\n",
      "88 0.00011013619223376736\n",
      "89 0.0009243465610779822\n",
      "90 0.0012578285532072186\n",
      "91 4.728920612251386e-05\n",
      "92 4.045799869345501e-05\n",
      "93 0.00011205401824554428\n",
      "94 0.00024181941989809275\n",
      "95 0.0007937219925224781\n",
      "96 3.775210279854946e-05\n",
      "97 2.5936809834092855e-05\n",
      "98 2.953052353404928e-05\n",
      "99 5.378155765356496e-05\n",
      "1\n",
      "0 0.7001862525939941\n",
      "1 0.6813115477561951\n",
      "2 0.6682769656181335\n",
      "3 0.6576080322265625\n",
      "4 0.6491676568984985\n",
      "5 0.598015308380127\n",
      "6 0.5525511503219604\n",
      "7 0.5004662275314331\n",
      "8 0.5501402616500854\n",
      "9 0.4057314395904541\n",
      "10 0.4247877597808838\n",
      "11 0.35766953229904175\n",
      "12 0.37809738516807556\n",
      "13 0.2693968713283539\n",
      "14 0.2759770452976227\n",
      "15 0.202321395277977\n",
      "16 0.1706480085849762\n",
      "17 0.15063324570655823\n",
      "18 0.11251677572727203\n",
      "19 0.12815573811531067\n",
      "20 0.07295070588588715\n",
      "21 0.07371383905410767\n",
      "22 0.03798888623714447\n",
      "23 0.03046276420354843\n",
      "24 0.062281932681798935\n",
      "25 0.01513840164989233\n",
      "26 0.07499443739652634\n",
      "27 0.01862623356282711\n",
      "28 0.03032526932656765\n",
      "29 0.012431949377059937\n",
      "30 0.02146795019507408\n",
      "31 0.01082683727145195\n",
      "32 0.0020221674349159002\n",
      "33 0.013145136646926403\n",
      "34 0.010026661679148674\n",
      "35 0.013933475129306316\n",
      "36 0.002505654003471136\n",
      "37 0.001479544909670949\n",
      "38 0.003686256008222699\n",
      "39 0.011254564858973026\n",
      "40 0.002712371526286006\n",
      "41 0.0018126433715224266\n",
      "42 0.0007533903699368238\n",
      "43 0.0007748646894469857\n",
      "44 0.002285863971337676\n",
      "45 0.0019784141331911087\n",
      "46 0.001613972126506269\n",
      "47 0.011470976285636425\n",
      "48 0.001209459500387311\n",
      "49 0.002632626798003912\n",
      "50 0.0017307598609477282\n",
      "51 0.004444749094545841\n",
      "52 0.01702149212360382\n",
      "53 0.0004145733255427331\n",
      "54 0.001599247450940311\n",
      "55 0.009349972940981388\n",
      "56 0.028278501704335213\n",
      "57 0.0019922207575291395\n",
      "58 0.0014528213068842888\n",
      "59 0.0008539636619389057\n",
      "60 0.0021412901114672422\n",
      "61 0.004247377626597881\n",
      "62 0.0028158710338175297\n",
      "63 0.0071075791493058205\n",
      "64 0.000196415203390643\n",
      "65 0.000581109372433275\n",
      "66 0.0002373096940573305\n",
      "67 0.0010655815713107586\n",
      "68 0.0023828649427741766\n",
      "69 0.0012071698438376188\n",
      "70 0.021131977438926697\n",
      "71 0.000591773132327944\n",
      "72 0.0009704597759991884\n",
      "73 0.0009095346904359758\n",
      "74 0.0579872764647007\n",
      "75 0.0005052209598943591\n",
      "76 0.00018385014845989645\n",
      "77 0.00966761913150549\n",
      "78 0.032267600297927856\n",
      "79 0.0005059739341959357\n",
      "80 0.001411035074852407\n",
      "81 0.00028751222998835146\n",
      "82 0.0035944448318332434\n",
      "83 0.0028787266928702593\n",
      "84 0.00800425186753273\n",
      "85 0.003578414674848318\n",
      "86 0.009665502235293388\n",
      "87 0.0021223260555416346\n",
      "88 0.001792093738913536\n",
      "89 0.009743775241076946\n",
      "90 0.0013319951249286532\n",
      "91 0.0162269975990057\n",
      "92 0.0024242247454822063\n",
      "93 0.0006898235296830535\n",
      "94 0.0009976450819522142\n",
      "95 0.0005824911640956998\n",
      "96 0.0005844880361109972\n",
      "97 0.0026159221306443214\n",
      "98 0.007102132774889469\n",
      "99 0.0008349657291546464\n",
      "2\n",
      "0 0.6853551864624023\n",
      "1 0.684984028339386\n",
      "2 0.6822997331619263\n",
      "3 0.6731706261634827\n",
      "4 0.6333485841751099\n",
      "5 0.5823485255241394\n",
      "6 0.5332282185554504\n",
      "7 0.5032258629798889\n",
      "8 0.5289725661277771\n",
      "9 0.3971232771873474\n",
      "10 0.4169943928718567\n",
      "11 0.33336517214775085\n",
      "12 0.3326263725757599\n",
      "13 0.23943963646888733\n",
      "14 0.20279614627361298\n",
      "15 0.20760305225849152\n",
      "16 0.13428142666816711\n",
      "17 0.12819041311740875\n",
      "18 0.06338763236999512\n",
      "19 0.09133225679397583\n",
      "20 0.027233634144067764\n",
      "21 0.06337793916463852\n",
      "22 0.020551081746816635\n",
      "23 0.022708861157298088\n",
      "24 0.014205093495547771\n",
      "25 0.014644586481153965\n",
      "26 0.007005464285612106\n",
      "27 0.006422404199838638\n",
      "28 0.019163629040122032\n",
      "29 0.004314651247113943\n",
      "30 0.006728199776262045\n",
      "31 0.0019888621754944324\n",
      "32 0.0035923849791288376\n",
      "33 0.0003465912595856935\n",
      "34 0.0006563455099239945\n",
      "35 0.0005570719949901104\n",
      "36 0.004072113428264856\n",
      "37 0.0011626621708273888\n",
      "38 0.005810974631458521\n",
      "39 0.00043812490184791386\n",
      "40 0.0007494424353353679\n",
      "41 0.03781523555517197\n",
      "42 0.0004598235827870667\n",
      "43 0.2769046127796173\n",
      "44 0.0008471455657854676\n",
      "45 0.10565928369760513\n",
      "46 0.07185565680265427\n",
      "47 0.003087940625846386\n",
      "48 0.029796341434121132\n",
      "49 0.10367517918348312\n",
      "50 0.009196248836815357\n",
      "51 0.008824600838124752\n",
      "52 0.026928812265396118\n",
      "53 0.022008847445249557\n",
      "54 0.01758056879043579\n",
      "55 0.006306731607764959\n",
      "56 0.007028923835605383\n",
      "57 0.009080120362341404\n",
      "58 0.004821782931685448\n",
      "59 0.0034584493841975927\n",
      "60 0.03139717876911163\n",
      "61 0.01947806030511856\n",
      "62 0.006758687552064657\n",
      "63 0.008669238537549973\n",
      "64 0.005057911854237318\n",
      "65 0.005109704099595547\n",
      "66 0.01674560271203518\n",
      "67 0.005203776992857456\n",
      "68 0.01201743632555008\n",
      "69 0.0029102880507707596\n",
      "70 0.00911141000688076\n",
      "71 0.003273164853453636\n",
      "72 0.002445436781272292\n",
      "73 0.005668396595865488\n",
      "74 0.0032328187953680754\n",
      "75 0.0027995717246085405\n",
      "76 0.003069784725084901\n",
      "77 0.0044518690556287766\n",
      "78 0.004398259334266186\n",
      "79 0.0039715939201414585\n",
      "80 0.0006248581339605153\n",
      "81 0.0010323005262762308\n",
      "82 0.0005830806330777705\n",
      "83 0.00041676228283904493\n",
      "84 0.0006684465915895998\n",
      "85 0.0005085082375444472\n",
      "86 0.0007462960784323514\n",
      "87 0.0014888388104736805\n",
      "88 0.00034001070889644325\n",
      "89 0.0030363111291080713\n",
      "90 0.0008169125067070127\n",
      "91 0.0012735987547785044\n",
      "92 0.000501033675391227\n",
      "93 0.0011443129042163491\n",
      "94 0.0013290215283632278\n",
      "95 0.0008826815173961222\n",
      "96 0.00028243198175914586\n",
      "97 0.0009514502016827464\n",
      "98 0.00013842896441929042\n",
      "99 0.0001339477312285453\n",
      "3\n",
      "0 0.6944065093994141\n",
      "1 0.6836562156677246\n",
      "2 0.6657297015190125\n",
      "3 0.6274651288986206\n",
      "4 0.5850589871406555\n",
      "5 0.6148789525032043\n",
      "6 0.5202484726905823\n",
      "7 0.4856511652469635\n",
      "8 0.4088989794254303\n",
      "9 0.3930836021900177\n",
      "10 0.3137397766113281\n",
      "11 0.2751137316226959\n",
      "12 0.24217826128005981\n",
      "13 0.19953812658786774\n",
      "14 0.21538196504116058\n",
      "15 0.0885356217622757\n",
      "16 0.17768119275569916\n",
      "17 0.056316666305065155\n",
      "18 0.1004529520869255\n",
      "19 0.031675420701503754\n",
      "20 0.04418732970952988\n",
      "21 0.05162905901670456\n",
      "22 0.017168497666716576\n",
      "23 0.04957224801182747\n",
      "24 0.03552898392081261\n",
      "25 0.0044597662054002285\n",
      "26 0.015245690010488033\n",
      "27 0.015167671255767345\n",
      "28 0.008705515414476395\n",
      "29 0.0013244424480944872\n",
      "30 0.005529785994440317\n",
      "31 0.0076715461909770966\n",
      "32 0.0016932336147874594\n",
      "33 0.0007894914597272873\n",
      "34 0.007596688345074654\n",
      "35 0.0019048659596592188\n",
      "36 0.0008906283765099943\n",
      "37 0.0032709960360080004\n",
      "38 0.001139795407652855\n",
      "39 0.00031187274726107717\n",
      "40 0.00033184810308739543\n",
      "41 0.004971466492861509\n",
      "42 0.00021936610573902726\n",
      "43 0.0003671801823657006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 0.0006129975081421435\n",
      "45 0.0007232955540530384\n",
      "46 0.0037225179839879274\n",
      "47 0.00011051290493924171\n",
      "48 0.000278386112768203\n",
      "49 0.0019310573115944862\n",
      "50 0.0006982499035075307\n",
      "51 0.0006398421246558428\n",
      "52 0.00015833514044061303\n",
      "53 6.532363477163017e-05\n",
      "54 0.00133828679099679\n",
      "55 6.685681728413329e-05\n",
      "56 3.307902443339117e-05\n",
      "57 7.685791206313297e-05\n",
      "58 1.5120596799533814e-05\n",
      "59 6.839688285253942e-05\n",
      "60 7.24118945072405e-05\n",
      "61 5.897176743019372e-05\n",
      "62 0.0003897732531186193\n",
      "63 4.200945113552734e-05\n",
      "64 8.500077819917351e-05\n",
      "65 4.8548521590419114e-05\n",
      "66 1.3505799870472401e-05\n",
      "67 8.93446704139933e-05\n",
      "68 0.0001344435877399519\n",
      "69 2.7077181584900245e-05\n",
      "70 3.336006557219662e-05\n",
      "71 1.8740067389444448e-05\n",
      "72 3.682380338432267e-05\n",
      "73 3.250363442930393e-05\n",
      "74 0.00010588821896817535\n",
      "75 1.736564445309341e-05\n",
      "76 2.9610966521431692e-05\n",
      "77 0.00012443590094335377\n",
      "78 0.00015381211414933205\n",
      "79 4.195485234959051e-05\n",
      "80 0.00017757950990926474\n",
      "81 0.00029330619145184755\n",
      "82 0.00020530539040919393\n",
      "83 1.7073822164093144e-05\n",
      "84 6.0005859268130735e-05\n",
      "85 1.2653011253860313e-05\n",
      "86 9.030547516886145e-06\n",
      "87 3.5409193515079096e-05\n",
      "88 1.5888901543803513e-05\n",
      "89 3.9495580494985916e-06\n",
      "90 1.3973232853459194e-05\n",
      "91 1.9301696738693863e-05\n",
      "92 2.444697565806564e-05\n",
      "93 1.0135967386304401e-05\n",
      "94 1.3504815797205083e-05\n",
      "95 2.954849878733512e-05\n",
      "96 4.637229358195327e-05\n",
      "97 5.209063601796515e-05\n",
      "98 1.1617705240496434e-05\n",
      "99 0.00010853615822270513\n",
      "4\n",
      "0 0.6943170428276062\n",
      "1 0.6882156729698181\n",
      "2 0.6767176985740662\n",
      "3 0.6464113593101501\n",
      "4 0.6196135878562927\n",
      "5 0.5878661274909973\n",
      "6 0.5413405299186707\n",
      "7 0.5133657455444336\n",
      "8 0.4695207178592682\n",
      "9 0.3712078928947449\n",
      "10 0.3627973794937134\n",
      "11 0.33041396737098694\n",
      "12 0.31231561303138733\n",
      "13 0.18373681604862213\n",
      "14 0.17885687947273254\n",
      "15 0.1590631902217865\n",
      "16 0.10922788828611374\n",
      "17 0.08941115438938141\n",
      "18 0.0745265781879425\n",
      "19 0.048623982816934586\n",
      "20 0.041307155042886734\n",
      "21 0.0233562383800745\n",
      "22 0.04703044891357422\n",
      "23 0.008318132720887661\n",
      "24 0.02561984397470951\n",
      "25 0.006872630212455988\n",
      "26 0.003944856114685535\n",
      "27 0.008044501766562462\n",
      "28 0.021275000646710396\n",
      "29 0.0012017633998766541\n",
      "30 0.0032372779678553343\n",
      "31 0.04889458045363426\n",
      "32 0.0011243794579058886\n",
      "33 0.09486927837133408\n",
      "34 0.000726620783098042\n",
      "35 0.008030597120523453\n",
      "36 0.014702985994517803\n",
      "37 0.006971664261072874\n",
      "38 0.022707846015691757\n",
      "39 0.0004192613123450428\n",
      "40 0.001793178729712963\n",
      "41 0.01233331486582756\n",
      "42 0.012617746368050575\n",
      "43 0.010597599670290947\n",
      "44 0.002108780900016427\n",
      "45 0.000314820499625057\n",
      "46 0.0012892714003100991\n",
      "47 0.009432214312255383\n",
      "48 0.011686421930789948\n",
      "49 0.0036105660255998373\n",
      "50 0.0003969336685258895\n",
      "51 0.0020078555680811405\n",
      "52 0.0010700607672333717\n",
      "53 0.002190283965319395\n",
      "54 0.0010299106361344457\n",
      "55 0.018240895122289658\n",
      "56 0.0019332156516611576\n",
      "57 0.0005288946558721364\n",
      "58 0.005058444570749998\n",
      "59 0.0006191374850459397\n",
      "60 0.002471852581948042\n",
      "61 0.004895735997706652\n",
      "62 0.0030354512855410576\n",
      "63 0.008418173529207706\n",
      "64 0.00032929654116742313\n",
      "65 0.00041473537567071617\n",
      "66 0.0005640932940877974\n",
      "67 0.0003515108546707779\n",
      "68 0.005840193014591932\n",
      "69 0.004794062115252018\n",
      "70 0.0011010218877345324\n",
      "71 0.00035313761327415705\n",
      "72 0.005331214517354965\n",
      "73 3.167256363667548e-05\n",
      "74 0.00030199522734619677\n",
      "75 0.0008674615528434515\n",
      "76 0.00023938559752423316\n",
      "77 0.0005113485385663807\n",
      "78 0.004366541281342506\n",
      "79 0.007031550630927086\n",
      "80 0.0007124910480342805\n",
      "81 0.0005474539357237518\n",
      "82 0.001995059894397855\n",
      "83 0.0004609744646586478\n",
      "84 2.5625033231335692e-05\n",
      "85 3.612340151448734e-05\n",
      "86 0.0002188203070545569\n",
      "87 0.001503653242252767\n",
      "88 0.0002170802472392097\n",
      "89 0.0013851713156327605\n",
      "90 0.001826165127567947\n",
      "91 0.00041954213520511985\n",
      "92 0.00017302304331678897\n",
      "93 0.001057440647855401\n",
      "94 6.237348861759529e-05\n",
      "95 2.3981048798304982e-05\n",
      "96 0.00034610426519066095\n",
      "97 2.5946474124793895e-05\n",
      "98 8.019572305784095e-06\n",
      "99 6.4248611124639865e-06\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 200\n",
    "HIDDEN_DIM = 30\n",
    "OUTPUT_SIZE_1 = 10\n",
    "COMBINE_FUNCS =[torch.mean, torch.max]\n",
    "OUTPUT_SIZE_2 = 1\n",
    "N_LAYERS = 1\n",
    "DROPOUT_PROB = 0.5\n",
    "HIDDEN_INITIAL = (torch.randn(1, 1, HIDDEN_DIM), torch.randn(1, 1, HIDDEN_DIM))\n",
    "results = experiments(OUTPUT_SIZE_1, OUTPUT_SIZE_2, N_LAYERS, EMBEDDING_DIM, HIDDEN_DIM, \\\n",
    "                COMBINE_FUNCS, HIDDEN_INITIAL,DROPOUT_PROB, epochs, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Iteration</th>\n",
       "      <th>scores_first</th>\n",
       "      <th>scores_last</th>\n",
       "      <th>scores_best</th>\n",
       "      <th>scores_ideal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.744444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>std</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.073703</td>\n",
       "      <td>0.049690</td>\n",
       "      <td>0.027217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  # Iteration  scores_first  scores_last  scores_best  scores_ideal\n",
       "0           1      0.611111     0.611111     0.611111      0.722222\n",
       "1           2      0.611111     0.722222     0.722222      0.777778\n",
       "2           3      0.611111     0.611111     0.611111      0.777778\n",
       "3           4      0.722222     0.555556     0.722222      0.722222\n",
       "4           5      0.666667     0.500000     0.666667      0.722222\n",
       "5        mean      0.644444     0.600000     0.666667      0.744444\n",
       "6         std      0.044444     0.073703     0.049690      0.027217"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'# Iteration': list(range(1,iterations + 1)) + ['mean', 'std'], \\\n",
    "    'scores_first': results['scores_first'] + [np.mean(results['scores_first']), np.std(results['scores_first'])],\\\n",
    "     'scores_last': results['scores_last'] + [np.mean(results['scores_last']), np.std(results['scores_last'])], \\\n",
    "     'scores_best': results['scores_best'] + [np.mean(results['scores_best']), np.std(results['scores_best'])], \\\n",
    "    'scores_ideal': results['scores_ideal'] + [np.mean(results['scores_ideal']), np.std(results['scores_ideal'])]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HIDDEN_DIM = 50, 1 fc, [torch.mean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0 0.6917464137077332\n",
      "1 0.6984074711799622\n",
      "2 0.6921167969703674\n",
      "3 0.6424497961997986\n",
      "4 0.6421229839324951\n",
      "5 0.6335413455963135\n",
      "6 0.6136420965194702\n",
      "7 0.607666015625\n",
      "8 0.5730096697807312\n",
      "9 0.5423061847686768\n",
      "10 0.48941242694854736\n",
      "11 0.4433946907520294\n",
      "12 0.490826815366745\n",
      "13 0.4872857928276062\n",
      "14 0.358762264251709\n",
      "15 0.42498236894607544\n",
      "16 0.3426423966884613\n",
      "17 0.3412606120109558\n",
      "18 0.32328230142593384\n",
      "19 0.28157785534858704\n",
      "20 0.26916033029556274\n",
      "21 0.22325706481933594\n",
      "22 0.181879922747612\n",
      "23 0.17620690166950226\n",
      "24 0.11562053114175797\n",
      "25 0.12123742699623108\n",
      "26 0.21593032777309418\n",
      "27 0.24342581629753113\n",
      "28 0.10030799359083176\n",
      "29 0.22849006950855255\n",
      "30 0.10007015615701675\n",
      "31 0.09306840598583221\n",
      "32 0.1320171058177948\n",
      "33 0.07486504316329956\n",
      "34 0.07699944078922272\n",
      "35 0.11206527054309845\n",
      "36 0.048772312700748444\n",
      "37 0.04315643385052681\n",
      "38 0.056020401418209076\n",
      "39 0.044992025941610336\n",
      "40 0.025481002405285835\n",
      "41 0.019321560859680176\n",
      "42 0.034956835210323334\n",
      "43 0.03182835876941681\n",
      "44 0.013980516232550144\n",
      "45 0.01137456577271223\n",
      "46 0.010510598309338093\n",
      "47 0.016153184697031975\n",
      "48 0.014730585739016533\n",
      "49 0.012632542289793491\n",
      "50 0.007441765628755093\n",
      "51 0.00334290717728436\n",
      "52 0.0039449152536690235\n",
      "53 0.008151253685355186\n",
      "54 0.008019833825528622\n",
      "55 0.003660209011286497\n",
      "56 0.002826804993674159\n",
      "57 0.0024637982714921236\n",
      "58 0.002501451876014471\n",
      "59 0.0008073515491560102\n",
      "60 0.002609865041449666\n",
      "61 0.0018547152867540717\n",
      "62 0.0018245161045342684\n",
      "63 0.0015743895201012492\n",
      "64 0.0016114379977807403\n",
      "65 0.0009616498718969524\n",
      "66 0.0006522588664665818\n",
      "67 0.0010985564440488815\n",
      "68 0.0009085391648113728\n",
      "69 0.0006420935387723148\n",
      "70 0.0004984987899661064\n",
      "71 0.0014224068727344275\n",
      "72 0.0005266870139166713\n",
      "73 0.0006066125934012234\n",
      "74 0.0008500355761498213\n",
      "75 0.0006892856326885521\n",
      "76 0.0006488813669420779\n",
      "77 0.0006981751066632569\n",
      "78 0.0008123061852529645\n",
      "79 0.000562092405743897\n",
      "80 0.0003751857439056039\n",
      "81 0.0005516107194125652\n",
      "82 0.0005567818880081177\n",
      "83 0.00043372262734919786\n",
      "84 0.00040435625123791397\n",
      "85 0.000296179874567315\n",
      "86 0.0004214578657411039\n",
      "87 0.000500241294503212\n",
      "88 0.0006008591153658926\n",
      "89 0.0005135585088282824\n",
      "90 0.0005853004986420274\n",
      "91 0.00039855955401435494\n",
      "92 0.0003387283650226891\n",
      "93 0.0003920409653801471\n",
      "94 0.0002823639952111989\n",
      "95 0.0003613411099649966\n",
      "96 0.0002647454966790974\n",
      "97 0.00035547008155845106\n",
      "98 0.0002692807465791702\n",
      "99 0.0004456235619727522\n",
      "1\n",
      "0 0.7006625533103943\n",
      "1 0.6786432862281799\n",
      "2 0.6577062010765076\n",
      "3 0.6096538305282593\n",
      "4 0.588149905204773\n",
      "5 0.563873291015625\n",
      "6 0.545233428478241\n",
      "7 0.5035083293914795\n",
      "8 0.4842776954174042\n",
      "9 0.49513378739356995\n",
      "10 0.5170029401779175\n",
      "11 0.4074863791465759\n",
      "12 0.4016016721725464\n",
      "13 0.3989657163619995\n",
      "14 0.3498276174068451\n",
      "15 0.34510427713394165\n",
      "16 0.30009427666664124\n",
      "17 0.2875165343284607\n",
      "18 0.22566379606723785\n",
      "19 0.2104072868824005\n",
      "20 0.14969384670257568\n",
      "21 0.21674294769763947\n",
      "22 0.1481357365846634\n",
      "23 0.12223702669143677\n",
      "24 0.09841342270374298\n",
      "25 0.11540945619344711\n",
      "26 0.05494406819343567\n",
      "27 0.0544515885412693\n",
      "28 0.05889226123690605\n",
      "29 0.03166865557432175\n",
      "30 0.03660844638943672\n",
      "31 0.009777352213859558\n",
      "32 0.04346977546811104\n",
      "33 0.011378651484847069\n",
      "34 0.06067952513694763\n",
      "35 0.0094517907127738\n",
      "36 0.023513808846473694\n",
      "37 0.01743401400744915\n",
      "38 0.010897008702158928\n",
      "39 0.011632991954684258\n",
      "40 0.01990797184407711\n",
      "41 0.004320225678384304\n",
      "42 0.013152931816875935\n",
      "43 0.04132341593503952\n",
      "44 0.004881841130554676\n",
      "45 0.003134450875222683\n",
      "46 0.0087519446387887\n",
      "47 0.013447041623294353\n",
      "48 0.012010680511593819\n",
      "49 0.008155581541359425\n",
      "50 0.003026987425982952\n",
      "51 0.002679775469005108\n",
      "52 0.004006013739854097\n",
      "53 0.0042973970994353294\n",
      "54 0.002454636851325631\n",
      "55 0.0029998014215379953\n",
      "56 0.0024960143491625786\n",
      "57 0.000720999320037663\n",
      "58 0.0011706522200256586\n",
      "59 0.001551835099235177\n",
      "60 0.001913075102493167\n",
      "61 0.003381266025826335\n",
      "62 0.0018242504447698593\n",
      "63 0.0012364080175757408\n",
      "64 0.0008045505965128541\n",
      "65 0.0007770364754833281\n",
      "66 0.0012489567743614316\n",
      "67 0.00036499614361673594\n",
      "68 0.0015169561374932528\n",
      "69 0.000268959382083267\n",
      "70 0.00046240462688729167\n",
      "71 0.0003462435561232269\n",
      "72 0.000296697486191988\n",
      "73 0.0008849853766150773\n",
      "74 0.0009529522503726184\n",
      "75 0.0005261782789602876\n",
      "76 0.000290474621579051\n",
      "77 0.00020133254292886704\n",
      "78 0.0002196067216573283\n",
      "79 0.000319198559736833\n",
      "80 0.00024328457948286086\n",
      "81 0.00012955264537595212\n",
      "82 0.00037376643740572035\n",
      "83 0.0002943981089629233\n",
      "84 0.0001675254461588338\n",
      "85 0.00019617365614976734\n",
      "86 0.0002478783717378974\n",
      "87 0.0002194913395214826\n",
      "88 0.00030575337586924434\n",
      "89 0.00018165571964345872\n",
      "90 0.00017018070502672344\n",
      "91 0.00014904358249623328\n",
      "92 0.0001408939715474844\n",
      "93 0.0002352224983042106\n",
      "94 0.00031807704363018274\n",
      "95 0.0001759999431669712\n",
      "96 9.403355943504721e-05\n",
      "97 0.00012556122965179384\n",
      "98 8.334916492458433e-05\n",
      "99 0.00011024243576684967\n",
      "2\n",
      "0 0.700893223285675\n",
      "1 0.6970314383506775\n",
      "2 0.667243242263794\n",
      "3 0.6363750696182251\n",
      "4 0.624001145362854\n",
      "5 0.622952938079834\n",
      "6 0.5815410614013672\n",
      "7 0.5312138795852661\n",
      "8 0.4993549585342407\n",
      "9 0.5288602709770203\n",
      "10 0.5635979771614075\n",
      "11 0.40336981415748596\n",
      "12 0.47581732273101807\n",
      "13 0.4409845769405365\n",
      "14 0.382567822933197\n",
      "15 0.38657665252685547\n",
      "16 0.3463682234287262\n",
      "17 0.31304308772087097\n",
      "18 0.325194776058197\n",
      "19 0.2543942332267761\n",
      "20 0.24278524518013\n",
      "21 0.2105131447315216\n",
      "22 0.17732024192810059\n",
      "23 0.13982653617858887\n",
      "24 0.12648232281208038\n",
      "25 0.09056475758552551\n",
      "26 0.06556292623281479\n",
      "27 0.11679454892873764\n",
      "28 0.18404537439346313\n",
      "29 0.1426243782043457\n",
      "30 0.09203773736953735\n",
      "31 0.05061303824186325\n",
      "32 0.09221859276294708\n",
      "33 0.09078885614871979\n",
      "34 0.04379795491695404\n",
      "35 0.050316181033849716\n",
      "36 0.058678094297647476\n",
      "37 0.04549231380224228\n",
      "38 0.02668987214565277\n",
      "39 0.021439876407384872\n",
      "40 0.028983144089579582\n",
      "41 0.015317863784730434\n",
      "42 0.016234304755926132\n",
      "43 0.009012814611196518\n",
      "44 0.009227498434484005\n",
      "45 0.007622868288308382\n",
      "46 0.010293573141098022\n",
      "47 0.008811631239950657\n",
      "48 0.0049604736268520355\n",
      "49 0.0030229035764932632\n",
      "50 0.0036832550540566444\n",
      "51 0.0026102960109710693\n",
      "52 0.003319905837997794\n",
      "53 0.0018935924163088202\n",
      "54 0.001892182743176818\n",
      "55 0.0027061181608587503\n",
      "56 0.003087106626480818\n",
      "57 0.001224852865561843\n",
      "58 0.0008403672836720943\n",
      "59 0.0009769914904609323\n",
      "60 0.0008714308496564627\n",
      "61 0.0007314165122807026\n",
      "62 0.0008387196576222777\n",
      "63 0.0009349045576527715\n",
      "64 0.0013352740788832307\n",
      "65 0.0012904626782983541\n",
      "66 0.0008180880104191601\n",
      "67 0.0012325650313869119\n",
      "68 0.0006073066033422947\n",
      "69 0.000851286924444139\n",
      "70 0.0009976666187867522\n",
      "71 0.0007081573712639511\n",
      "72 0.0008933658245950937\n",
      "73 0.0006034466787241399\n",
      "74 0.0006631904398091137\n",
      "75 0.00024411598860751837\n",
      "76 0.0003126483061350882\n",
      "77 0.0005899346433579922\n",
      "78 0.0004017770697828382\n",
      "79 0.000622333085630089\n",
      "80 0.00044234859524294734\n",
      "81 0.0003151452401652932\n",
      "82 0.0006649989518336952\n",
      "83 0.0005324623780325055\n",
      "84 0.00027833826607093215\n",
      "85 0.0002459471288602799\n",
      "86 0.00029251017258502543\n",
      "87 0.0003181078936904669\n",
      "88 0.00025217243819497526\n",
      "89 0.00021052060765214264\n",
      "90 0.00036915368400514126\n",
      "91 0.00039574046968482435\n",
      "92 0.00038014838355593383\n",
      "93 0.00027069810312241316\n",
      "94 0.00030653891735710204\n",
      "95 0.00020042048709001392\n",
      "96 0.00017774809384718537\n",
      "97 0.00017564590962138027\n",
      "98 0.0004827155207749456\n",
      "99 0.000251617340836674\n",
      "3\n",
      "0 0.7025733590126038\n",
      "1 0.6674582958221436\n",
      "2 0.660129189491272\n",
      "3 0.6354494690895081\n",
      "4 0.6242587566375732\n",
      "5 0.5865370035171509\n",
      "6 0.5932042002677917\n",
      "7 0.5456618666648865\n",
      "8 0.4840482473373413\n",
      "9 0.49205949902534485\n",
      "10 0.5079039335250854\n",
      "11 0.4276449382305145\n",
      "12 0.3721845746040344\n",
      "13 0.35354864597320557\n",
      "14 0.30053335428237915\n",
      "15 0.24857065081596375\n",
      "16 0.23588521778583527\n",
      "17 0.8028503656387329\n",
      "18 0.20640981197357178\n",
      "19 0.39491334557533264\n",
      "20 0.23219653964042664\n",
      "21 0.28200235962867737\n",
      "22 0.3396206498146057\n",
      "23 0.23797160387039185\n",
      "24 0.20016328990459442\n",
      "25 0.22278554737567902\n",
      "26 0.1925436407327652\n",
      "27 0.16575366258621216\n",
      "28 0.14931635558605194\n",
      "29 0.1028643250465393\n",
      "30 0.08741874247789383\n",
      "31 0.08705965429544449\n",
      "32 0.07308922708034515\n",
      "33 0.048703383654356\n",
      "34 0.030139917507767677\n",
      "35 0.024581903591752052\n",
      "36 0.017816348001360893\n",
      "37 0.011502678506076336\n",
      "38 0.011055397801101208\n",
      "39 0.010109521448612213\n",
      "40 0.00583939952775836\n",
      "41 0.008987993001937866\n",
      "42 0.0043952856212854385\n",
      "43 0.00831158459186554\n",
      "44 0.005012952722609043\n",
      "45 0.003167981281876564\n",
      "46 0.002754269866272807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 0.0019700515549629927\n",
      "48 0.003989158198237419\n",
      "49 0.0020789902191609144\n",
      "50 0.0012155472068116069\n",
      "51 0.0016836341237649322\n",
      "52 0.001320175244472921\n",
      "53 0.0011562724830582738\n",
      "54 0.0011598257115110755\n",
      "55 0.0012710748706012964\n",
      "56 0.0010385116329416633\n",
      "57 0.0015247728442773223\n",
      "58 0.000772516883444041\n",
      "59 0.000760897877626121\n",
      "60 0.0008881559479050338\n",
      "61 0.0008014923660084605\n",
      "62 0.00047970449668355286\n",
      "63 0.00033587307552807033\n",
      "64 0.00035551132168620825\n",
      "65 0.0006341732223518193\n",
      "66 0.0005060440744273365\n",
      "67 0.0003190208226442337\n",
      "68 0.00040816402179189026\n",
      "69 0.00042667187517508864\n",
      "70 0.00036553724203258753\n",
      "71 0.00029603857547044754\n",
      "72 0.0004606864822562784\n",
      "73 0.0003319754614494741\n",
      "74 0.0003418217529542744\n",
      "75 0.00022458832245320082\n",
      "76 0.0006119210738688707\n",
      "77 0.0002907472662627697\n",
      "78 0.00025715981610119343\n",
      "79 0.0003364496515132487\n",
      "80 0.00024925655452534556\n",
      "81 0.00018848941545002162\n",
      "82 0.00021933167590759695\n",
      "83 0.00022413836268242449\n",
      "84 0.00015108825755305588\n",
      "85 0.00015611988783348352\n",
      "86 0.0001977378997253254\n",
      "87 0.0001933635212481022\n",
      "88 0.00012554253044072539\n",
      "89 0.00019324262393638492\n",
      "90 0.0002755492168944329\n",
      "91 0.00014384982932824641\n",
      "92 0.00016455474542453885\n",
      "93 0.00011016569624189287\n",
      "94 0.00018656501197256148\n",
      "95 0.0001206829838338308\n",
      "96 9.409982158103958e-05\n",
      "97 0.00019104899547528476\n",
      "98 0.00018569293024484068\n",
      "99 0.00014479021774604917\n",
      "4\n",
      "0 0.6976358294487\n",
      "1 0.6900334358215332\n",
      "2 0.6650311946868896\n",
      "3 0.6531787514686584\n",
      "4 0.6531354188919067\n",
      "5 0.5985698699951172\n",
      "6 0.5915518403053284\n",
      "7 0.5437084436416626\n",
      "8 0.49451568722724915\n",
      "9 0.5367361903190613\n",
      "10 0.7153491973876953\n",
      "11 0.4452018141746521\n",
      "12 0.5686444640159607\n",
      "13 0.5743988156318665\n",
      "14 0.5201524496078491\n",
      "15 0.5236712098121643\n",
      "16 0.5117149353027344\n",
      "17 0.4682129919528961\n",
      "18 0.4359172284603119\n",
      "19 0.43603575229644775\n",
      "20 0.43597128987312317\n",
      "21 0.37601736187934875\n",
      "22 0.35217082500457764\n",
      "23 0.33146798610687256\n",
      "24 0.275553822517395\n",
      "25 0.26485884189605713\n",
      "26 0.25737959146499634\n",
      "27 0.2137472778558731\n",
      "28 0.18621140718460083\n",
      "29 0.1534591168165207\n",
      "30 0.1311403214931488\n",
      "31 0.11205579340457916\n",
      "32 0.1218680888414383\n",
      "33 0.1750589907169342\n",
      "34 0.07500817626714706\n",
      "35 0.0835692435503006\n",
      "36 0.047392334789037704\n",
      "37 0.05661742389202118\n",
      "38 0.05476664379239082\n",
      "39 0.0287786815315485\n",
      "40 0.025865523144602776\n",
      "41 0.031170962378382683\n",
      "42 0.016592029482126236\n",
      "43 0.017001738771796227\n",
      "44 0.012775670737028122\n",
      "45 0.013892680406570435\n",
      "46 0.006677979603409767\n",
      "47 0.0035895260516554117\n",
      "48 0.005125752184540033\n",
      "49 0.003772125579416752\n",
      "50 0.003854260081425309\n",
      "51 0.0012444342719390988\n",
      "52 0.002382059581577778\n",
      "53 0.012548794038593769\n",
      "54 0.0023723759222775698\n",
      "55 0.04230361431837082\n",
      "56 0.001337893889285624\n",
      "57 0.10138905793428421\n",
      "58 0.3059881329536438\n",
      "59 0.01036957185715437\n",
      "60 0.033997368067502975\n",
      "61 0.13136906921863556\n",
      "62 0.10528837889432907\n",
      "63 0.0698753371834755\n",
      "64 0.050610095262527466\n",
      "65 0.05738203972578049\n",
      "66 0.09834884107112885\n",
      "67 0.06750373542308807\n",
      "68 0.052600763738155365\n",
      "69 0.038338467478752136\n",
      "70 0.03264349326491356\n",
      "71 0.03219131752848625\n",
      "72 0.03167491406202316\n",
      "73 0.035366035997867584\n",
      "74 0.026524772867560387\n",
      "75 0.02007467858493328\n",
      "76 0.0219221543520689\n",
      "77 0.015061561949551105\n",
      "78 0.01618870534002781\n",
      "79 0.021067598834633827\n",
      "80 0.01666048914194107\n",
      "81 0.012580358423292637\n",
      "82 0.016384514048695564\n",
      "83 0.009098850190639496\n",
      "84 0.006925268564373255\n",
      "85 0.009100732393562794\n",
      "86 0.0074999332427978516\n",
      "87 0.005453627090901136\n",
      "88 0.00540452403947711\n",
      "89 0.006885285954922438\n",
      "90 0.009073707275092602\n",
      "91 0.005746985320001841\n",
      "92 0.004479472991079092\n",
      "93 0.0032016397453844547\n",
      "94 0.0036058169789612293\n",
      "95 0.0018296490889042616\n",
      "96 0.0020724923815578222\n",
      "97 0.0018298464128747582\n",
      "98 0.0026591827627271414\n",
      "99 0.0025966353714466095\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 200\n",
    "HIDDEN_DIM = 50\n",
    "OUTPUT_SIZE_1 = 1\n",
    "COMBINE_FUNCS =[torch.mean]\n",
    "OUTPUT_SIZE_2 = 1\n",
    "N_LAYERS = 1\n",
    "DROPOUT_PROB = 0.5\n",
    "HIDDEN_INITIAL = (torch.randn(1, 1, HIDDEN_DIM), torch.randn(1, 1, HIDDEN_DIM))\n",
    "results = experiments(OUTPUT_SIZE_1, OUTPUT_SIZE_2, N_LAYERS, EMBEDDING_DIM, HIDDEN_DIM, \\\n",
    "                COMBINE_FUNCS, HIDDEN_INITIAL,DROPOUT_PROB, epochs, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Iteration</th>\n",
       "      <th>scores_first</th>\n",
       "      <th>scores_last</th>\n",
       "      <th>scores_best</th>\n",
       "      <th>scores_ideal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.711111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  # Iteration  scores_first  scores_last  scores_best  scores_ideal\n",
       "0           1      0.555556     0.555556     0.555556      0.722222\n",
       "1           2      0.555556     0.555556     0.555556      0.722222\n",
       "2           3      0.666667     0.611111     0.666667      0.722222\n",
       "3           4      0.500000     0.388889     0.500000      0.666667\n",
       "4           5      0.611111     0.666667     0.666667      0.722222\n",
       "5        mean      0.577778     0.555556     0.588889      0.711111"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'# Iteration': list(range(1,iterations + 1)) + ['mean'], \\\n",
    "                   'scores_first': results['scores_first'] + [np.mean(results['scores_first'])],\\\n",
    "                         'scores_last': results['scores_last'] + [np.mean(results['scores_last'])], \\\n",
    "                   'scores_best': results['scores_best'] + [np.mean(results['scores_best'])], \\\n",
    "                   'scores_ideal': results['scores_ideal'] + [np.mean(results['scores_ideal'])]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HIDDEN_DIM = 50, output_size_1 = 20, 2 fcs, [torch.mean, torch.max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0 0.7045242786407471\n",
      "1 0.7154113054275513\n",
      "2 0.7108703851699829\n",
      "3 0.665443480014801\n",
      "4 0.6484684348106384\n",
      "5 0.6370669007301331\n",
      "6 0.6088412404060364\n",
      "7 0.5580205321311951\n",
      "8 0.5120642781257629\n",
      "9 0.4456539750099182\n",
      "10 0.34897199273109436\n",
      "11 0.39847105741500854\n",
      "12 0.7809348702430725\n",
      "13 0.21073146164417267\n",
      "14 0.4467383027076721\n",
      "15 0.365533709526062\n",
      "16 0.22151866555213928\n",
      "17 0.24302572011947632\n",
      "18 0.2557424306869507\n",
      "19 0.24726556241512299\n",
      "20 0.17857974767684937\n",
      "21 0.12845654785633087\n",
      "22 0.1254992038011551\n",
      "23 0.12065384536981583\n",
      "24 0.09062220901250839\n",
      "25 0.06133587658405304\n",
      "26 0.03803260624408722\n",
      "27 0.02782885544002056\n",
      "28 0.017187386751174927\n",
      "29 0.014478539116680622\n",
      "30 0.007680822163820267\n",
      "31 0.024162663146853447\n",
      "32 0.007301937323063612\n",
      "33 0.006052274722605944\n",
      "34 0.02777852676808834\n",
      "35 0.01605812832713127\n",
      "36 0.0021910264622420073\n",
      "37 0.0014310150872915983\n",
      "38 0.0019032306736335158\n",
      "39 0.0016822745092213154\n",
      "40 0.000491370155941695\n",
      "41 0.0005104023148305714\n",
      "42 0.0020333316642791033\n",
      "43 0.0014897296205163002\n",
      "44 0.011068793013691902\n",
      "45 0.02154749631881714\n",
      "46 0.00020509347086772323\n",
      "47 0.0002849492593668401\n",
      "48 0.0014200265286490321\n",
      "49 0.00034495320869609714\n",
      "50 0.004004860762506723\n",
      "51 0.0010304825846105814\n",
      "52 0.003765074536204338\n",
      "53 0.00012805084406863898\n",
      "54 0.0009880869183689356\n",
      "55 0.0014166522305458784\n",
      "56 0.0005976551328785717\n",
      "57 0.0008491899934597313\n",
      "58 0.0001301839220104739\n",
      "59 0.0004477701731957495\n",
      "60 0.0013223574496805668\n",
      "61 0.0002412412577541545\n",
      "62 0.0001615460787434131\n",
      "63 0.00029797322349622846\n",
      "64 0.0001934198517119512\n",
      "65 0.0007240705890581012\n",
      "66 0.00014626038318965584\n",
      "67 0.00019535569299478084\n",
      "68 0.0001138416919275187\n",
      "69 0.0004830361867789179\n",
      "70 0.002145529957488179\n",
      "71 0.00023870516452006996\n",
      "72 5.115499152452685e-05\n",
      "73 4.386872751638293e-05\n",
      "74 0.00010234297951683402\n",
      "75 4.0180730138672516e-05\n",
      "76 0.0004098385979887098\n",
      "77 0.00025991350412368774\n",
      "78 0.00016979131032712758\n",
      "79 5.2385184972081333e-05\n",
      "80 3.946919969166629e-05\n",
      "81 0.0007851782720535994\n",
      "82 0.0011645568301901221\n",
      "83 0.00029132477357052267\n",
      "84 0.00012023400631733239\n",
      "85 0.0005250254762358963\n",
      "86 7.35570938559249e-05\n",
      "87 0.00010487235704204068\n",
      "88 8.813328167889267e-05\n",
      "89 6.908292562002316e-05\n",
      "90 4.308289862819947e-05\n",
      "91 5.625715493806638e-05\n",
      "92 1.8852862922358327e-05\n",
      "93 0.00011331043788231909\n",
      "94 0.00015088741201907396\n",
      "95 0.00011707225348800421\n",
      "96 0.006836771033704281\n",
      "97 9.122804476646706e-05\n",
      "98 3.18585334753152e-05\n",
      "99 0.00027400176622904837\n",
      "1\n",
      "0 0.7096365690231323\n",
      "1 0.7252528667449951\n",
      "2 0.6720362901687622\n",
      "3 0.6900979280471802\n",
      "4 0.6677530407905579\n",
      "5 0.6462120413780212\n",
      "6 0.5896808505058289\n",
      "7 0.5871161818504333\n",
      "8 0.5052909255027771\n",
      "9 0.5102726817131042\n",
      "10 0.4829745888710022\n",
      "11 0.3337372839450836\n",
      "12 0.3450709581375122\n",
      "13 0.26313406229019165\n",
      "14 0.2089252769947052\n",
      "15 0.13692136108875275\n",
      "16 0.1266704648733139\n",
      "17 0.06430205702781677\n",
      "18 0.043215371668338776\n",
      "19 0.044834356755018234\n",
      "20 0.01767403818666935\n",
      "21 0.009532078169286251\n",
      "22 0.00980367697775364\n",
      "23 0.031280018389225006\n",
      "24 0.0817919671535492\n",
      "25 0.007506251335144043\n",
      "26 0.023796919733285904\n",
      "27 0.010435594245791435\n",
      "28 0.0046840994618833065\n",
      "29 0.01324445940554142\n",
      "30 0.037354230880737305\n",
      "31 0.02944176271557808\n",
      "32 0.007906394079327583\n",
      "33 0.028666267171502113\n",
      "34 0.022533902898430824\n",
      "35 0.025354614481329918\n",
      "36 0.0010352313984185457\n",
      "37 0.0019028221722692251\n",
      "38 0.0029763441998511553\n",
      "39 0.00845393631607294\n",
      "40 0.0063050976023077965\n",
      "41 0.03484726324677467\n",
      "42 0.0030121824238449335\n",
      "43 0.0009874764364212751\n",
      "44 0.006243961863219738\n",
      "45 0.00032419158378615975\n",
      "46 0.000571153243072331\n",
      "47 0.0030222730711102486\n",
      "48 0.0023853920865803957\n",
      "49 0.0005223147454671562\n",
      "50 0.0022257105447351933\n",
      "51 0.0006292342441156507\n",
      "52 0.00020024213881697506\n",
      "53 0.00011617541167652234\n",
      "54 0.0005547183100134134\n",
      "55 0.0002558597188908607\n",
      "56 0.017538079991936684\n",
      "57 0.001286551938392222\n",
      "58 0.0012840342242270708\n",
      "59 0.0007347523933276534\n",
      "60 0.021030843257904053\n",
      "61 5.161215449334122e-05\n",
      "62 0.014153181575238705\n",
      "63 0.0016917797038331628\n",
      "64 0.001032046740874648\n",
      "65 0.009770774282515049\n",
      "66 0.001089639961719513\n",
      "67 0.000476126471767202\n",
      "68 0.0016136262565851212\n",
      "69 0.01775163970887661\n",
      "70 0.001672504236921668\n",
      "71 0.001277824048884213\n",
      "72 0.00018021503638010472\n",
      "73 0.0005351689760573208\n",
      "74 0.00019314500968903303\n",
      "75 0.014318527653813362\n",
      "76 0.0043998705223202705\n",
      "77 0.00043075764551758766\n",
      "78 0.00011748921679100022\n",
      "79 0.0007142163813114166\n",
      "80 0.00028609426226466894\n",
      "81 0.000311710056848824\n",
      "82 0.04803062975406647\n",
      "83 0.0004870416014455259\n",
      "84 0.0314846895635128\n",
      "85 0.0004919819766655564\n",
      "86 0.000655456620734185\n",
      "87 0.00016581178351771086\n",
      "88 0.00031230723834596574\n",
      "89 9.887165651889518e-05\n",
      "90 0.002708504907786846\n",
      "91 0.0011591785587370396\n",
      "92 0.0010601951507851481\n",
      "93 0.003375186352059245\n",
      "94 0.0025698107201606035\n",
      "95 0.0003505510976538062\n",
      "96 0.001650146208703518\n",
      "97 0.019231395795941353\n",
      "98 0.00042333980672992766\n",
      "99 0.002977378899231553\n",
      "2\n",
      "0 0.692005455493927\n",
      "1 0.6856057643890381\n",
      "2 0.7021520733833313\n",
      "3 0.6356695294380188\n",
      "4 0.6561551094055176\n",
      "5 0.6173954010009766\n",
      "6 0.541473388671875\n",
      "7 0.5109627842903137\n",
      "8 0.4572506248950958\n",
      "9 0.4016173779964447\n",
      "10 0.3280452489852905\n",
      "11 0.26394975185394287\n",
      "12 0.2358788400888443\n",
      "13 0.20397648215293884\n",
      "14 0.111514151096344\n",
      "15 0.08786080777645111\n",
      "16 0.067415252327919\n",
      "17 0.05482366681098938\n",
      "18 0.021212764084339142\n",
      "19 0.03889082372188568\n",
      "20 0.040909893810749054\n",
      "21 0.01712130941450596\n",
      "22 0.005455156788229942\n",
      "23 0.004942032042890787\n",
      "24 0.0179347675293684\n",
      "25 0.002194655127823353\n",
      "26 0.005139018874615431\n",
      "27 0.0022550374269485474\n",
      "28 0.0030554928816854954\n",
      "29 0.001234030001796782\n",
      "30 0.0010633546626195312\n",
      "31 0.007122595328837633\n",
      "32 0.0004349831724539399\n",
      "33 0.0011254752753302455\n",
      "34 0.0007004172657616436\n",
      "35 0.029327835887670517\n",
      "36 0.000543622940313071\n",
      "37 0.0031138178892433643\n",
      "38 0.007087474223226309\n",
      "39 0.0031846470665186644\n",
      "40 0.0036498988047242165\n",
      "41 0.0006072857649996877\n",
      "42 0.00042578656575642526\n",
      "43 0.000888751819729805\n",
      "44 0.029807107523083687\n",
      "45 0.0007982798269949853\n",
      "46 0.0005844216793775558\n",
      "47 0.0033623743802309036\n",
      "48 0.0017179690767079592\n",
      "49 0.0012569426326081157\n",
      "50 0.05455680191516876\n",
      "51 0.0002518733963370323\n",
      "52 0.013213252648711205\n",
      "53 0.0033953520469367504\n",
      "54 0.018772024661302567\n",
      "55 0.004182445351034403\n",
      "56 0.014915541745722294\n",
      "57 0.0006153392023406923\n",
      "58 0.008125809952616692\n",
      "59 0.007536422461271286\n",
      "60 0.009113644249737263\n",
      "61 0.0012685853289440274\n",
      "62 0.009322297759354115\n",
      "63 0.0016822954639792442\n",
      "64 0.003468795446678996\n",
      "65 0.02243788354098797\n",
      "66 0.0004576051142066717\n",
      "67 0.0006964621716178954\n",
      "68 0.011590523645281792\n",
      "69 0.024915063753724098\n",
      "70 0.0004408923559822142\n",
      "71 0.0002830307639669627\n",
      "72 0.001594243454746902\n",
      "73 0.0027225457597523928\n",
      "74 0.023860959336161613\n",
      "75 0.006744170095771551\n",
      "76 0.00216580624692142\n",
      "77 0.01405367162078619\n",
      "78 8.63761015352793e-05\n",
      "79 0.0006620755302719772\n",
      "80 0.0003619352064561099\n",
      "81 0.0020320978946983814\n",
      "82 0.00029798378818668425\n",
      "83 0.00018847019237000495\n",
      "84 0.0050413645803928375\n",
      "85 0.0011317861499264836\n",
      "86 0.0005159538122825325\n",
      "87 0.00039251105044968426\n",
      "88 0.001046406920067966\n",
      "89 0.0009518286096863449\n",
      "90 0.001461563864722848\n",
      "91 0.00023525334836449474\n",
      "92 0.00029140192782506347\n",
      "93 0.000636418757494539\n",
      "94 6.986693188082427e-05\n",
      "95 0.0014346634270623326\n",
      "96 0.003480189712718129\n",
      "97 0.0014888374134898186\n",
      "98 0.0013398283626884222\n",
      "99 0.00015586611698381603\n",
      "3\n",
      "0 0.7040396928787231\n",
      "1 0.7010296583175659\n",
      "2 0.6948328614234924\n",
      "3 0.654032289981842\n",
      "4 0.6241687536239624\n",
      "5 0.5978578329086304\n",
      "6 0.5629716515541077\n",
      "7 0.45693400502204895\n",
      "8 0.4066387712955475\n",
      "9 0.3926944136619568\n",
      "10 0.6096654534339905\n",
      "11 0.26821741461753845\n",
      "12 0.3643404245376587\n",
      "13 0.2717760503292084\n",
      "14 0.2102186381816864\n",
      "15 0.2727806866168976\n",
      "16 0.21175578236579895\n",
      "17 0.1305740922689438\n",
      "18 0.1399073451757431\n",
      "19 0.12183967232704163\n",
      "20 0.0656033381819725\n",
      "21 0.06682676076889038\n",
      "22 0.028497029095888138\n",
      "23 0.030088413506746292\n",
      "24 0.020896095782518387\n",
      "25 0.01723639853298664\n",
      "26 0.0028895442374050617\n",
      "27 0.00915338471531868\n",
      "28 0.013161404058337212\n",
      "29 0.005837482400238514\n",
      "30 0.003910607658326626\n",
      "31 0.0038794190622866154\n",
      "32 0.015100833959877491\n",
      "33 0.002390926470980048\n",
      "34 0.03281911462545395\n",
      "35 0.002578424522653222\n",
      "36 0.0013185319257900119\n",
      "37 0.0006393244257196784\n",
      "38 0.0027784535195678473\n",
      "39 0.019688595086336136\n",
      "40 0.00030237887403927743\n",
      "41 0.0008378452039323747\n",
      "42 0.0009274429176002741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 0.000628416077233851\n",
      "44 0.0001810549001675099\n",
      "45 0.0017202625749632716\n",
      "46 0.000623039435595274\n",
      "47 0.0003799257392529398\n",
      "48 0.0028795134276151657\n",
      "49 0.00437328452244401\n",
      "50 0.00025651275063864887\n",
      "51 0.00040713942144066095\n",
      "52 0.00029229180654510856\n",
      "53 0.0017371461726725101\n",
      "54 0.001023960066959262\n",
      "55 0.0003258329234085977\n",
      "56 0.0023298312444239855\n",
      "57 0.00021790560276713222\n",
      "58 0.000845497299451381\n",
      "59 0.00015100630116648972\n",
      "60 9.433188097318634e-05\n",
      "61 0.00022908720711711794\n",
      "62 0.0003221928491257131\n",
      "63 0.00028459238819777966\n",
      "64 0.003101208945736289\n",
      "65 0.0029959450475871563\n",
      "66 0.0035998562816530466\n",
      "67 0.0005392826860770583\n",
      "68 0.00011578160774661228\n",
      "69 0.0016244299476966262\n",
      "70 0.0005260410835035145\n",
      "71 0.0006465267506428063\n",
      "72 0.003769532311707735\n",
      "73 0.0023318829480558634\n",
      "74 0.000972720212303102\n",
      "75 0.00019358292047400028\n",
      "76 0.0002549319760873914\n",
      "77 4.130154411541298e-05\n",
      "78 0.00035655396641232073\n",
      "79 7.363262557191774e-05\n",
      "80 0.0015475312247872353\n",
      "81 0.00031678020604886115\n",
      "82 0.0006652050069533288\n",
      "83 0.0005319072515703738\n",
      "84 0.0001205738662974909\n",
      "85 0.00041540159145370126\n",
      "86 2.7956299163633958e-05\n",
      "87 0.00022891948174219579\n",
      "88 0.0002644653432071209\n",
      "89 2.7393743948778138e-05\n",
      "90 0.00034865413908846676\n",
      "91 2.2467464077635668e-05\n",
      "92 8.199738658731803e-05\n",
      "93 9.490883530816063e-05\n",
      "94 9.744631097419187e-05\n",
      "95 3.0113806133158505e-05\n",
      "96 6.0166112234583125e-05\n",
      "97 0.00016969420539680868\n",
      "98 2.440338175802026e-05\n",
      "99 0.00012156165757915005\n",
      "4\n",
      "0 0.6933923363685608\n",
      "1 0.6813675165176392\n",
      "2 0.6329568028450012\n",
      "3 0.5824501514434814\n",
      "4 0.550163984298706\n",
      "5 0.5024001002311707\n",
      "6 1.158793330192566\n",
      "7 0.44071367383003235\n",
      "8 0.6807809472084045\n",
      "9 0.5490478277206421\n",
      "10 0.4490116834640503\n",
      "11 0.45832231640815735\n",
      "12 0.47361844778060913\n",
      "13 0.4248164892196655\n",
      "14 0.4046166241168976\n",
      "15 0.3908734917640686\n",
      "16 0.32671022415161133\n",
      "17 0.293908029794693\n",
      "18 0.254223108291626\n",
      "19 0.236497163772583\n",
      "20 0.1920221596956253\n",
      "21 0.15344876050949097\n",
      "22 0.12414759397506714\n",
      "23 0.09080477803945541\n",
      "24 0.11347762495279312\n",
      "25 0.06726745516061783\n",
      "26 0.06884371489286423\n",
      "27 0.03983496502041817\n",
      "28 0.029495373368263245\n",
      "29 0.03442367911338806\n",
      "30 0.02062883786857128\n",
      "31 0.016344022005796432\n",
      "32 0.01460359338670969\n",
      "33 0.014512067660689354\n",
      "34 0.009802538901567459\n",
      "35 0.020869512110948563\n",
      "36 0.00270637683570385\n",
      "37 0.010121242143213749\n",
      "38 0.0027115419507026672\n",
      "39 0.007912348955869675\n",
      "40 0.002650552662089467\n",
      "41 0.0018225768581032753\n",
      "42 0.0045026009902358055\n",
      "43 0.0014328038087114692\n",
      "44 0.0009815043304115534\n",
      "45 0.001160604297183454\n",
      "46 0.0029503032565116882\n",
      "47 0.008527225814759731\n",
      "48 0.0007345872581936419\n",
      "49 0.00038756983121857047\n",
      "50 0.0009043797035701573\n",
      "51 0.00046616760664619505\n",
      "52 0.0008718359167687595\n",
      "53 0.0009711154270917177\n",
      "54 0.00034637973294593394\n",
      "55 0.0004767117206938565\n",
      "56 0.0013529442949220538\n",
      "57 0.0009276841301470995\n",
      "58 0.00048241359763778746\n",
      "59 0.00037195865297690034\n",
      "60 0.00011345785605954006\n",
      "61 0.00017087123706005514\n",
      "62 0.000549027812667191\n",
      "63 0.0008233909029513597\n",
      "64 0.0009398687398061156\n",
      "65 0.00028775687678717077\n",
      "66 0.00023700135352555662\n",
      "67 0.0003756448277272284\n",
      "68 0.0002333402808289975\n",
      "69 0.0003465294430498034\n",
      "70 0.00013284316810313612\n",
      "71 0.0005464982823468745\n",
      "72 0.00027073267847299576\n",
      "73 0.0005300766206346452\n",
      "74 0.0002689083048608154\n",
      "75 0.00011448042641859502\n",
      "76 0.0001626567100174725\n",
      "77 0.00010541766096139327\n",
      "78 6.605060480069369e-05\n",
      "79 0.0002386875858064741\n",
      "80 8.212630928028375e-05\n",
      "81 0.00012702768435701728\n",
      "82 0.0001117512583732605\n",
      "83 6.546545046148822e-05\n",
      "84 0.00023334009165409952\n",
      "85 0.0002948802721221\n",
      "86 0.0002407300053164363\n",
      "87 4.327334318077192e-05\n",
      "88 0.00017853881581686437\n",
      "89 0.00022002986224833876\n",
      "90 8.043284469749779e-05\n",
      "91 0.0004058265476487577\n",
      "92 0.00016410114767495543\n",
      "93 0.0002208161458838731\n",
      "94 0.000552130164578557\n",
      "95 0.0006909137591719627\n",
      "96 0.00045929441694170237\n",
      "97 7.727111369604245e-05\n",
      "98 7.725592149654403e-05\n",
      "99 0.00017815626051742584\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 200\n",
    "HIDDEN_DIM = 50\n",
    "OUTPUT_SIZE_1 = 20\n",
    "COMBINE_FUNCS =[torch.mean, torch.max]\n",
    "OUTPUT_SIZE_2 = 1\n",
    "N_LAYERS = 1\n",
    "DROPOUT_PROB = 0.5\n",
    "epochs = 100\n",
    "iterations = 5\n",
    "HIDDEN_INITIAL = (torch.randn(1, 1, HIDDEN_DIM), torch.randn(1, 1, HIDDEN_DIM))\n",
    "results = experiments(OUTPUT_SIZE_1, OUTPUT_SIZE_2, N_LAYERS, EMBEDDING_DIM, HIDDEN_DIM, \\\n",
    "                COMBINE_FUNCS, HIDDEN_INITIAL,DROPOUT_PROB, epochs, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Iteration</th>\n",
       "      <th>scores_first</th>\n",
       "      <th>scores_last</th>\n",
       "      <th>scores_best</th>\n",
       "      <th>scores_ideal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.755556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  # Iteration  scores_first  scores_last  scores_best  scores_ideal\n",
       "0           1      0.666667     0.666667     0.666667      0.722222\n",
       "1           2      0.611111     0.611111     0.611111      0.777778\n",
       "2           3      0.666667     0.611111     0.666667      0.722222\n",
       "3           4      0.611111     0.666667     0.666667      0.777778\n",
       "4           5      0.611111     0.611111     0.611111      0.777778\n",
       "5        mean      0.633333     0.633333     0.644444      0.755556"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'# Iteration': list(range(1,iterations + 1)) + ['mean'], \\\n",
    "                   'scores_first': results['scores_first'] + [np.mean(results['scores_first'])],\\\n",
    "                         'scores_last': results['scores_last'] + [np.mean(results['scores_last'])], \\\n",
    "                   'scores_best': results['scores_best'] + [np.mean(results['scores_best'])], \\\n",
    "                   'scores_ideal': results['scores_ideal'] + [np.mean(results['scores_ideal'])]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
