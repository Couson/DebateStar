{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1248e2b70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from point2mn import point2mn\n",
    "from point2mn import get_main_points\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found word vecs:  400000\n"
     ]
    }
   ],
   "source": [
    "embedding_index = {}\n",
    "\n",
    "f = open('glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:],dtype='float32')\n",
    "    embedding_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('found word vecs: ',len(embedding_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted([s for s in  list(embedding_index.keys()) if s[0].isalpha()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>for</th>\n",
       "      <th>against</th>\n",
       "      <th>For_Main_Points</th>\n",
       "      <th>against_Main_Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d20191112</td>\n",
       "      <td>Capitalism Is a Blessing</td>\n",
       "      <td>2019-11-12</td>\n",
       "      <td>['John Mackey', 'Katherine Mangu-Ward']</td>\n",
       "      <td>['Bhaskar Sunkara', 'Richard D. Wolff']</td>\n",
       "      <td>['By promoting market competition and rewardin...</td>\n",
       "      <td>['Capitalism serves the interests of large cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d20191029</td>\n",
       "      <td>Parenting Is Overrated</td>\n",
       "      <td>2019-10-29</td>\n",
       "      <td>['Robert Plomin', 'Nancy Segal']</td>\n",
       "      <td>['Paige Harden', 'Ann Pleshette Murphy']</td>\n",
       "      <td>[\"We're in the midst of a DNA revolution: Whil...</td>\n",
       "      <td>['While DNA is important, factors like familia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d20191022</td>\n",
       "      <td>Europe Has Declared War on American Tech Compa...</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>['Roslyn Layton', 'Berin Szóka']</td>\n",
       "      <td>['Marietje Schaake', 'Ramesh Srinivasan']</td>\n",
       "      <td>['European regulators have declared war on Ame...</td>\n",
       "      <td>['Brussels isn’t waging war on Silicon Valley....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d20190917</td>\n",
       "      <td>Replace Private Insurance with Medicare for All</td>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>['Dr. Adam Gaffney', 'Joseph Sanberg']</td>\n",
       "      <td>['Nick Gillespie', 'Sally Pipes']</td>\n",
       "      <td>['The United States government should follow t...</td>\n",
       "      <td>['Individuals should have the freedom to choos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d20190802</td>\n",
       "      <td>The Recent U.S. Policy Towards China Is Produc...</td>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>['Michael Pillsbury', 'Kori Schake']</td>\n",
       "      <td>['Graham Allison', 'Jake Sullivan']</td>\n",
       "      <td>['The prospect of China becoming an open and l...</td>\n",
       "      <td>['The United States and China are great compet...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title        date  \\\n",
       "0  d20191112                           Capitalism Is a Blessing  2019-11-12   \n",
       "1  d20191029                             Parenting Is Overrated  2019-10-29   \n",
       "2  d20191022  Europe Has Declared War on American Tech Compa...  2019-10-22   \n",
       "3  d20190917    Replace Private Insurance with Medicare for All  2019-09-17   \n",
       "4  d20190802  The Recent U.S. Policy Towards China Is Produc...  2019-08-02   \n",
       "\n",
       "                                       for  \\\n",
       "0  ['John Mackey', 'Katherine Mangu-Ward']   \n",
       "1         ['Robert Plomin', 'Nancy Segal']   \n",
       "2         ['Roslyn Layton', 'Berin Szóka']   \n",
       "3   ['Dr. Adam Gaffney', 'Joseph Sanberg']   \n",
       "4     ['Michael Pillsbury', 'Kori Schake']   \n",
       "\n",
       "                                     against  \\\n",
       "0    ['Bhaskar Sunkara', 'Richard D. Wolff']   \n",
       "1   ['Paige Harden', 'Ann Pleshette Murphy']   \n",
       "2  ['Marietje Schaake', 'Ramesh Srinivasan']   \n",
       "3          ['Nick Gillespie', 'Sally Pipes']   \n",
       "4        ['Graham Allison', 'Jake Sullivan']   \n",
       "\n",
       "                                     For_Main_Points  \\\n",
       "0  ['By promoting market competition and rewardin...   \n",
       "1  [\"We're in the midst of a DNA revolution: Whil...   \n",
       "2  ['European regulators have declared war on Ame...   \n",
       "3  ['The United States government should follow t...   \n",
       "4  ['The prospect of China becoming an open and l...   \n",
       "\n",
       "                                 against_Main_Points  \n",
       "0  ['Capitalism serves the interests of large cor...  \n",
       "1  ['While DNA is important, factors like familia...  \n",
       "2  ['Brussels isn’t waging war on Silicon Valley....  \n",
       "3  ['Individuals should have the freedom to choos...  \n",
       "4  ['The United States and China are great compet...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_points = pd.read_csv('DebateStar/Meta Data/metadata_appended_main_points.csv') \n",
    "main_points.dropna(subset = ['For_Main_Points', 'against_Main_Points'], inplace = True)\n",
    "main_points = main_points.reset_index(drop = True)\n",
    "main_points.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('DebateStar/results_data/final_online.csv') \n",
    "results = results.loc[results['winner'].apply(lambda x: x != 'undecided')]\n",
    "results['winner'] = results['winner'].apply(lambda x: 1 if x == 'for' else 0)\n",
    "id2winner = results[['id', 'winner']].set_index('id').to_dict()['winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>for</th>\n",
       "      <th>against</th>\n",
       "      <th>For_Main_Points</th>\n",
       "      <th>against_Main_Points</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d20191112</td>\n",
       "      <td>Capitalism Is a Blessing</td>\n",
       "      <td>2019-11-12</td>\n",
       "      <td>['John Mackey', 'Katherine Mangu-Ward']</td>\n",
       "      <td>['Bhaskar Sunkara', 'Richard D. Wolff']</td>\n",
       "      <td>['By promoting market competition and rewardin...</td>\n",
       "      <td>['Capitalism serves the interests of large cor...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d20191029</td>\n",
       "      <td>Parenting Is Overrated</td>\n",
       "      <td>2019-10-29</td>\n",
       "      <td>['Robert Plomin', 'Nancy Segal']</td>\n",
       "      <td>['Paige Harden', 'Ann Pleshette Murphy']</td>\n",
       "      <td>[\"We're in the midst of a DNA revolution: Whil...</td>\n",
       "      <td>['While DNA is important, factors like familia...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d20191022</td>\n",
       "      <td>Europe Has Declared War on American Tech Compa...</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>['Roslyn Layton', 'Berin Szóka']</td>\n",
       "      <td>['Marietje Schaake', 'Ramesh Srinivasan']</td>\n",
       "      <td>['European regulators have declared war on Ame...</td>\n",
       "      <td>['Brussels isn’t waging war on Silicon Valley....</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d20190917</td>\n",
       "      <td>Replace Private Insurance with Medicare for All</td>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>['Dr. Adam Gaffney', 'Joseph Sanberg']</td>\n",
       "      <td>['Nick Gillespie', 'Sally Pipes']</td>\n",
       "      <td>['The United States government should follow t...</td>\n",
       "      <td>['Individuals should have the freedom to choos...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d20190802</td>\n",
       "      <td>The Recent U.S. Policy Towards China Is Produc...</td>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>['Michael Pillsbury', 'Kori Schake']</td>\n",
       "      <td>['Graham Allison', 'Jake Sullivan']</td>\n",
       "      <td>['The prospect of China becoming an open and l...</td>\n",
       "      <td>['The United States and China are great compet...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title        date  \\\n",
       "0  d20191112                           Capitalism Is a Blessing  2019-11-12   \n",
       "1  d20191029                             Parenting Is Overrated  2019-10-29   \n",
       "2  d20191022  Europe Has Declared War on American Tech Compa...  2019-10-22   \n",
       "3  d20190917    Replace Private Insurance with Medicare for All  2019-09-17   \n",
       "4  d20190802  The Recent U.S. Policy Towards China Is Produc...  2019-08-02   \n",
       "\n",
       "                                       for  \\\n",
       "0  ['John Mackey', 'Katherine Mangu-Ward']   \n",
       "1         ['Robert Plomin', 'Nancy Segal']   \n",
       "2         ['Roslyn Layton', 'Berin Szóka']   \n",
       "3   ['Dr. Adam Gaffney', 'Joseph Sanberg']   \n",
       "4     ['Michael Pillsbury', 'Kori Schake']   \n",
       "\n",
       "                                     against  \\\n",
       "0    ['Bhaskar Sunkara', 'Richard D. Wolff']   \n",
       "1   ['Paige Harden', 'Ann Pleshette Murphy']   \n",
       "2  ['Marietje Schaake', 'Ramesh Srinivasan']   \n",
       "3          ['Nick Gillespie', 'Sally Pipes']   \n",
       "4        ['Graham Allison', 'Jake Sullivan']   \n",
       "\n",
       "                                     For_Main_Points  \\\n",
       "0  ['By promoting market competition and rewardin...   \n",
       "1  [\"We're in the midst of a DNA revolution: Whil...   \n",
       "2  ['European regulators have declared war on Ame...   \n",
       "3  ['The United States government should follow t...   \n",
       "4  ['The prospect of China becoming an open and l...   \n",
       "\n",
       "                                 against_Main_Points  label  \n",
       "0  ['Capitalism serves the interests of large cor...    0.0  \n",
       "1  ['While DNA is important, factors like familia...    1.0  \n",
       "2  ['Brussels isn’t waging war on Silicon Valley....    0.0  \n",
       "3  ['Individuals should have the freedom to choos...    0.0  \n",
       "4  ['The United States and China are great compet...    0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_points['label'] = main_points.id.apply(lambda x: id2winner[x] if x in id2winner else np.nan)\n",
    "main_points = main_points.dropna(subset = ['label']).reset_index(drop = True)\n",
    "main_points.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = main_points.id.tolist()\n",
    "labels =  main_points.label.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(inputs, labels, test_size = 0.2, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(y_train)\n",
    "y_val = torch.tensor(y_val)\n",
    "y_test = torch.tensor(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.5\n",
       "1.0    0.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_test).value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    0.5\n",
       "0.0    0.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_val).value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.517647\n",
       "1.0    0.482353\n",
       "dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Hidden state initialize differently every time running LSTM??\n",
    "\n",
    "2. init_hidden?\n",
    "\n",
    "3. Softmax?\n",
    "\n",
    "4. Use only hidden state, not cell state or output?\n",
    "\n",
    "5. Results somewhat random?\n",
    "\n",
    "6. Hidden Dimension?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tune embedding\n",
    "\n",
    "Same initial hidden states DONE\n",
    "\n",
    "Check dropout in evaluation DONE no dropout\n",
    "\n",
    "Validation set DONE\n",
    "\n",
    "Check fully connected weights \n",
    "\n",
    "Add f.c. layers DOING\n",
    "\n",
    "Mean + std of several runs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lstm_one_sentence(sentence, title, lstm, hidden, embedding_index):\n",
    "    inputs = point2mn(sentence, title, embedding_index)\n",
    "    tensor_input = [torch.tensor([x]) for x in inputs]\n",
    "    tensor_input = torch.cat(tensor_input).view(1, len(tensor_input), -1)\n",
    "#     hidden = (torch.randn(1, 1, HIDDEN_DIM), torch.randn(1, 1, HIDDEN_DIM)) #???????\n",
    "    tensor_output, hidden = lstm(tensor_input, hidden)\n",
    "    # should return hidden state and cell state in 'hidden' instead of output\n",
    "    return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_lstm_on_fid(fid, embedding_index, lstm, hidden, combine_func = [torch.mean, torch.max]):\n",
    "    \"\"\"\n",
    "    Given fid, find main points for the debate and for each sentence, pass corresponding \n",
    "    matching vectors to lstm and get hidden state in the end. Gather the hidden states\n",
    "    in a list and do combine_func.\n",
    "    -combine_func: the funtion applied to combine lstm outputs from one side elementwisely\n",
    "    \"\"\"\n",
    "    \n",
    "    title = main_points[main_points['id'] == fid].title.iloc[0]\n",
    "    for_main_points, against_main_points = get_main_points(fid, main_points)\n",
    "    for_output_list = []\n",
    "    against_output_list = []\n",
    "    \n",
    "    for sentence in for_main_points:\n",
    "        hidden_state, cell_state = run_lstm_one_sentence(sentence, title, lstm, hidden, embedding_index)\n",
    "        for_output_list.append(hidden_state)\n",
    "        \n",
    "    for sentence in against_main_points:\n",
    "        hidden_state, cell_state = run_lstm_one_sentence(sentence, title, lstm, hidden, embedding_index)\n",
    "        against_output_list.append(hidden_state)\n",
    "    for_torchs = []\n",
    "    against_torchs = []\n",
    "    for combine_f in combine_func:\n",
    "        if combine_f == torch.mean:\n",
    "            for_torch = combine_f(torch.stack(for_output_list), dim = 0, keepdim = True)#[0]\n",
    "            against_torch = combine_f(torch.stack(against_output_list), dim = 0, keepdim = True)#[0]\n",
    "        else:\n",
    "            for_torch = combine_f(torch.stack(for_output_list), dim = 0, keepdim = True)[0]\n",
    "            against_torch = combine_f(torch.stack(against_output_list), dim = 0, keepdim = True)[0]\n",
    "        for_torchs.append(for_torch)\n",
    "        against_torchs.append(against_torch)\n",
    "    if len(for_torchs) == 2:\n",
    "        t1 = torch.cat((for_torchs[0], for_torchs[1]), dim = 2)\n",
    "        t2 = torch.cat((against_torchs[0], against_torchs[1]), dim = 2)\n",
    "        return torch.cat((t1, t2), dim = 2)\n",
    "    return torch.cat((for_torchs[0], against_torchs[0]), dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, output_size_1, output_size_2, n_layers, embedding_dim, hidden_dim, combine_funcs, hidden, drop_prob=0.5):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.output_size_1 = output_size_1\n",
    "        self.output_size_2 = output_size_2\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.combine_funcs = combine_funcs\n",
    "        self.hidden = hidden\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2 * len(self.combine_funcs), self.output_size_1)\n",
    "        self.fc2 = nn.Linear(output_size_1, self.output_size_2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, fids):\n",
    "        batch_size = len(fids)\n",
    "        lstm_out = torch.stack([run_lstm_on_fid(fid, embedding_index, self.lstm, self.hidden, \\\n",
    "                                                combine_func = self.combine_funcs) for fid in fids])\n",
    "    \n",
    "        lstm_out = lstm_out.contiguous().view(-1, len(self.combine_funcs) * 2 * self.hidden_dim)\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        out = out.view(batch_size, -1)\n",
    "        out = out[:,-1]\n",
    "        return out#, hidden\n",
    "    \n",
    "#     def init_hidden(self, batch_size):\n",
    "#         weight = next(self.parameters()).data\n",
    "#         hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "#                       weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "#         return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 200\n",
    "HIDDEN_DIM = 50\n",
    "OUTPUT_SIZE_1 = 20\n",
    "COMBINE_FUNCS =[torch.mean, torch.max]\n",
    "OUTPUT_SIZE_2 = 1\n",
    "N_LAYERS = 1\n",
    "DROPOUT_PROB = 0.5\n",
    "HIDDEN_INITIAL = (torch.randn(1, 1, HIDDEN_DIM), torch.randn(1, 1, HIDDEN_DIM))\n",
    "# all should use the same one lstm layer\n",
    "# lstm = nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMNet(OUTPUT_SIZE_1, OUTPUT_SIZE_2, N_LAYERS, EMBEDDING_DIM, HIDDEN_DIM, COMBINE_FUNCS, HIDDEN_INITIAL,DROPOUT_PROB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.005\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6946223974227905\n",
      "0.6832095980644226\n",
      "0.6761366128921509\n",
      "0.6420382857322693\n",
      "0.6203120350837708\n",
      "0.5813390016555786\n",
      "0.5190531611442566\n",
      "0.4666883945465088\n",
      "0.4329531192779541\n",
      "0.3752633035182953\n",
      "0.30831459164619446\n",
      "0.23986196517944336\n",
      "0.24928957223892212\n",
      "0.39366015791893005\n",
      "0.1403120756149292\n",
      "0.2522309720516205\n",
      "0.12413179874420166\n",
      "0.1029122844338417\n",
      "0.16996270418167114\n",
      "0.08095245808362961\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "counter = 0\n",
    "# print_every = 1000\n",
    "# clip = 5\n",
    "# valid_loss_min = np.Inf\n",
    "train_acc = []\n",
    "train_acc2 = []\n",
    "\n",
    "val_acc = []\n",
    "test_acc = []\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "#     h = model.init_hidden(batch_size)\n",
    "    \n",
    "#     for inputs, labels in train_loader:\n",
    "#         counter += 1\n",
    "#         h = tuple([e.data for e in h])\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    output = model(X_train)\n",
    "    loss = criterion(output.squeeze(), y_train.float())\n",
    "    print(loss.item())\n",
    "    loss.backward()\n",
    "#     nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "    optimizer.step()\n",
    "    model.eval()\n",
    "    outs = model(X_train)\n",
    "    train_acc.append(torch.sum((outs > 0.5) == y_train).item() / len(y_train))\n",
    "\n",
    "    outs = model(X_val)\n",
    "    val_acc.append(torch.sum((outs > 0.5) == y_val).item() / len(y_val))\n",
    "    \n",
    "    outs = model(X_test)\n",
    "    test_acc.append(torch.sum((outs > 0.5) == y_test).item() / len(y_test))\n",
    "\n",
    "    \n",
    "    \n",
    "#         if counter%print_every == 0:\n",
    "#             val_h = model.init_hidden(batch_size)\n",
    "#             val_losses = []\n",
    "#             model.eval()\n",
    "#             for inp, lab in val_loader:\n",
    "#                 val_h = tuple([each.data for each in val_h])\n",
    "#                 inp, lab = inp.to(device), lab.to(device)\n",
    "#                 out, val_h = model(inp, val_h)\n",
    "#                 val_loss = criterion(out.squeeze(), lab.float())\n",
    "#                 val_losses.append(val_loss.item())\n",
    "                \n",
    "#             model.train()\n",
    "#             print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
    "#                   \"Step: {}...\".format(counter),\n",
    "#                   \"Loss: {:.6f}...\".format(loss.item()),\n",
    "#                   \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "#             if np.mean(val_losses) <= valid_loss_min:\n",
    "#                 torch.save(model.state_dict(), './state_dict.pt')\n",
    "#                 print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,np.mean(val_losses)))\n",
    "#                 valid_loss_min = np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_results(outputsize, N_LAYERS, embedding_dim, hidden_dim, combine_funcs, drop_prob, lr, epochs):\n",
    "    print('output size = ', outputsize, 'n_layers =', N_LAYERS, 'embedding_dim = ', embedding_dim, \\\n",
    "         'hidden_dim = ', hidden_dim, 'combine_funcs = ', str(combine_funcs), 'drop_prob = ', drop_prob, \\\n",
    "          'lr = ', lr, 'epochs = ', epochs)\n",
    "    return pd.DataFrame({'# Epoch': range(1,epochs + 1), 'training acc': train_acc,\\\n",
    "                         'validation acc': val_acc, 'testing acc': test_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size =  1 n_layers = 1 embedding_dim =  200 hidden_dim =  50 combine_funcs =  [<built-in method mean of type object at 0x116f7deb0>, <built-in method max of type object at 0x116f7deb0>] drop_prob =  0.5 lr =  0.005 epochs =  20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Epoch</th>\n",
       "      <th>training acc</th>\n",
       "      <th>validation acc</th>\n",
       "      <th>testing acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.894118</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    # Epoch  training acc  validation acc  testing acc\n",
       "0         1      0.647059             0.4     0.583333\n",
       "1         2      0.788235             0.5     0.666667\n",
       "2         3      0.623529             0.5     0.500000\n",
       "3         4      0.658824             0.6     0.500000\n",
       "4         5      0.894118             0.7     0.583333\n",
       "5         6      0.870588             0.6     0.500000\n",
       "6         7      0.776471             0.6     0.583333\n",
       "7         8      0.811765             0.5     0.458333\n",
       "8         9      0.800000             0.7     0.541667\n",
       "9        10      0.858824             0.6     0.458333\n",
       "10       11      0.952941             0.6     0.583333\n",
       "11       12      0.929412             0.5     0.583333\n",
       "12       13      0.788235             0.5     0.541667\n",
       "13       14      0.988235             0.6     0.625000\n",
       "14       15      0.870588             0.6     0.541667\n",
       "15       16      0.988235             0.5     0.666667\n",
       "16       17      0.952941             0.5     0.625000\n",
       "17       18      0.941176             0.6     0.500000\n",
       "18       19      1.000000             0.6     0.666667\n",
       "19       20      1.000000             0.6     0.666667"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_results(OUTPUT_SIZE, N_LAYERS, EMBEDDING_DIM, HIDDEN_DIM, [torch.mean, torch.max], DROPOUT_PROB, lr, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size =  1 n_layers = 1 embedding_dim =  200 hidden_dim =  50 combine_funcs =  [<built-in method mean of type object at 0x116f7deb0>, <built-in method max of type object at 0x116f7deb0>] drop_prob =  0.5 lr =  0.005 epochs =  20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Epoch</th>\n",
       "      <th>training acc</th>\n",
       "      <th>validation acc</th>\n",
       "      <th>testing acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    # Epoch  training acc  validation acc  testing acc\n",
       "0         1      0.658824             0.6     0.541667\n",
       "1         2      0.705882             0.6     0.583333\n",
       "2         3      0.835294             0.8     0.625000\n",
       "3         4      0.729412             0.5     0.500000\n",
       "4         5      0.788235             0.5     0.625000\n",
       "5         6      0.870588             0.6     0.625000\n",
       "6         7      0.882353             0.8     0.625000\n",
       "7         8      0.870588             0.9     0.625000\n",
       "8         9      0.811765             0.6     0.541667\n",
       "9        10      0.764706             0.8     0.541667\n",
       "10       11      0.752941             0.5     0.583333\n",
       "11       12      0.870588             0.8     0.541667\n",
       "12       13      0.811765             0.7     0.583333\n",
       "13       14      0.905882             0.5     0.541667\n",
       "14       15      0.929412             0.5     0.541667\n",
       "15       16      0.882353             0.8     0.500000\n",
       "16       17      1.000000             0.9     0.583333\n",
       "17       18      0.964706             0.5     0.583333\n",
       "18       19      1.000000             0.7     0.583333\n",
       "19       20      0.988235             0.6     0.583333"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_results(OUTPUT_SIZE, N_LAYERS, EMBEDDING_DIM, HIDDEN_DIM, [torch.mean, torch.max], DROPOUT_PROB, lr, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size =  1 n_layers = 1 embedding_dim =  200 hidden_dim =  30 combine_funcs =  [<built-in method mean of type object at 0x116f7deb0>, <built-in method max of type object at 0x116f7deb0>] drop_prob =  0.6 lr =  0.01 epochs =  20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Epoch</th>\n",
       "      <th>training acc</th>\n",
       "      <th>validation acc</th>\n",
       "      <th>testing acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    # Epoch  training acc  validation acc  testing acc\n",
       "0         1      0.529412             0.6     0.500000\n",
       "1         2      0.764706             0.8     0.666667\n",
       "2         3      0.835294             0.7     0.541667\n",
       "3         4      0.823529             0.7     0.583333\n",
       "4         5      0.823529             0.6     0.625000\n",
       "5         6      0.835294             0.7     0.583333\n",
       "6         7      0.870588             0.7     0.666667\n",
       "7         8      0.823529             0.7     0.541667\n",
       "8         9      0.776471             0.5     0.583333\n",
       "9        10      0.882353             0.7     0.541667\n",
       "10       11      0.800000             0.8     0.541667\n",
       "11       12      0.988235             0.9     0.666667\n",
       "12       13      0.882353             0.6     0.625000\n",
       "13       14      0.882353             0.6     0.625000\n",
       "14       15      0.988235             0.8     0.750000\n",
       "15       16      0.976471             0.6     0.541667\n",
       "16       17      0.976471             0.6     0.541667\n",
       "17       18      1.000000             0.7     0.625000\n",
       "18       19      1.000000             0.6     0.666667\n",
       "19       20      0.976471             0.5     0.625000"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_results(OUTPUT_SIZE, N_LAYERS, EMBEDDING_DIM, HIDDEN_DIM, [torch.mean, torch.max], DROPOUT_PROB, lr, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size =  1 n_layers = 1 embedding_dim =  200 hidden_dim =  50 combine_funcs =  [<built-in method mean of type object at 0x116f7deb0>, <built-in method max of type object at 0x116f7deb0>] drop_prob =  0.6 lr =  0.01 epochs =  20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Epoch</th>\n",
       "      <th>training acc</th>\n",
       "      <th>validation acc</th>\n",
       "      <th>testing acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    # Epoch  training acc  validation acc  testing acc\n",
       "0         1      0.717647             0.7     0.625000\n",
       "1         2      0.541176             0.5     0.458333\n",
       "2         3      0.564706             0.5     0.541667\n",
       "3         4      0.682353             0.5     0.500000\n",
       "4         5      0.917647             0.6     0.666667\n",
       "5         6      0.800000             0.7     0.541667\n",
       "6         7      0.647059             0.5     0.500000\n",
       "7         8      0.905882             0.6     0.625000\n",
       "8         9      0.705882             0.6     0.541667\n",
       "9        10      0.964706             0.6     0.583333\n",
       "10       11      0.917647             0.5     0.500000\n",
       "11       12      0.952941             0.5     0.541667\n",
       "12       13      1.000000             0.6     0.500000\n",
       "13       14      0.917647             0.7     0.583333\n",
       "14       15      0.964706             0.6     0.583333\n",
       "15       16      1.000000             0.6     0.500000\n",
       "16       17      0.976471             0.5     0.625000\n",
       "17       18      1.000000             0.6     0.500000\n",
       "18       19      1.000000             0.6     0.625000\n",
       "19       20      1.000000             0.6     0.583333"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_results(OUTPUT_SIZE, N_LAYERS, EMBEDDING_DIM, HIDDEN_DIM, [torch.mean, torch.max], DROPOUT_PROB, lr, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size =  1 n_layers = 1 embedding_dim =  200 hidden_dim =  50 combine_funcs =  [<built-in method mean of type object at 0x116f7deb0>, <built-in method max of type object at 0x116f7deb0>] drop_prob =  0.6 lr =  0.01 epochs =  20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Epoch</th>\n",
       "      <th>training acc</th>\n",
       "      <th>validation acc</th>\n",
       "      <th>testing acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.894118</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    # Epoch  training acc  validation acc  testing acc\n",
       "0         1      0.517647             0.5     0.500000\n",
       "1         2      0.494118             0.5     0.500000\n",
       "2         3      0.670588             0.5     0.541667\n",
       "3         4      0.588235             0.5     0.500000\n",
       "4         5      0.647059             0.5     0.500000\n",
       "5         6      0.882353             0.6     0.583333\n",
       "6         7      0.858824             0.6     0.583333\n",
       "7         8      0.847059             0.7     0.583333\n",
       "8         9      0.776471             0.8     0.541667\n",
       "9        10      0.776471             0.6     0.500000\n",
       "10       11      0.894118             0.5     0.500000\n",
       "11       12      0.835294             0.7     0.541667\n",
       "12       13      0.964706             0.6     0.541667\n",
       "13       14      0.952941             0.6     0.625000\n",
       "14       15      1.000000             0.9     0.541667\n",
       "15       16      0.988235             0.9     0.541667\n",
       "16       17      1.000000             0.6     0.583333\n",
       "17       18      0.976471             0.6     0.625000\n",
       "18       19      1.000000             0.7     0.666667\n",
       "19       20      1.000000             0.7     0.625000"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_results(OUTPUT_SIZE, N_LAYERS, EMBEDDING_DIM, HIDDEN_DIM, [torch.mean, torch.max], DROPOUT_PROB, lr, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size =  1 n_layers = 1 embedding_dim =  200 hidden_dim =  100 combine_funcs =  [<built-in method mean of type object at 0x115fcceb0>, <built-in method max of type object at 0x115fcceb0>] drop_prob =  0.7 lr =  0.001 epochs =  20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Epoch</th>\n",
       "      <th>training acc</th>\n",
       "      <th>testing acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.547368</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.568421</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.610526</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.694737</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.831579</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.863158</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.873684</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.873684</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.873684</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.863158</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.852632</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.863158</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    # Epoch  training acc  testing acc\n",
       "0         1      0.547368     0.500000\n",
       "1         2      0.568421     0.500000\n",
       "2         3      0.610526     0.500000\n",
       "3         4      0.631579     0.500000\n",
       "4         5      0.694737     0.500000\n",
       "5         6      0.736842     0.500000\n",
       "6         7      0.789474     0.541667\n",
       "7         8      0.800000     0.416667\n",
       "8         9      0.831579     0.458333\n",
       "9        10      0.863158     0.541667\n",
       "10       11      0.873684     0.541667\n",
       "11       12      0.894737     0.583333\n",
       "12       13      0.873684     0.583333\n",
       "13       14      0.873684     0.583333\n",
       "14       15      0.863158     0.541667\n",
       "15       16      0.852632     0.541667\n",
       "16       17      0.842105     0.583333\n",
       "17       18      0.863158     0.541667\n",
       "18       19      0.905263     0.500000\n",
       "19       20      0.905263     0.541667"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_results(OUTPUT_SIZE, N_LAYERS, EMBEDDING_DIM, HIDDEN_DIM, [torch.mean, torch.max], DROPOUT_PROB, lr, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size =  1 n_layers = 1 embedding_dim =  200 hidden_dim =  100 combine_funcs =  [<built-in method mean of type object at 0x115fcceb0>, <built-in method max of type object at 0x115fcceb0>] drop_prob =  0.4 lr =  0.001 epochs =  20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Epoch</th>\n",
       "      <th>training acc</th>\n",
       "      <th>testing acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.536842</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.705263</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.726316</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.778947</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.768421</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.831579</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.831579</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.852632</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.831579</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.831579</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.810526</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    # Epoch  training acc  testing acc\n",
       "0         1      0.536842     0.500000\n",
       "1         2      0.631579     0.458333\n",
       "2         3      0.705263     0.416667\n",
       "3         4      0.726316     0.458333\n",
       "4         5      0.778947     0.458333\n",
       "5         6      0.789474     0.458333\n",
       "6         7      0.789474     0.458333\n",
       "7         8      0.789474     0.500000\n",
       "8         9      0.789474     0.500000\n",
       "9        10      0.768421     0.458333\n",
       "10       11      0.831579     0.500000\n",
       "11       12      0.831579     0.541667\n",
       "12       13      0.852632     0.500000\n",
       "13       14      0.842105     0.541667\n",
       "14       15      0.831579     0.541667\n",
       "15       16      0.842105     0.541667\n",
       "16       17      0.831579     0.500000\n",
       "17       18      0.821053     0.500000\n",
       "18       19      0.810526     0.500000\n",
       "19       20      0.821053     0.500000"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_results(OUTPUT_SIZE, N_LAYERS, EMBEDDING_DIM, HIDDEN_DIM, [torch.mean, torch.max], 0.4, lr, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size =  1 n_layers = 1 embedding_dim =  200 hidden_dim =  100 combine_funcs =  [<built-in method mean of type object at 0x115fcceb0>, <built-in method max of type object at 0x115fcceb0>] drop_prob =  0.4 lr =  0.001 epochs =  20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Epoch</th>\n",
       "      <th>training acc</th>\n",
       "      <th>testing acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.547368</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.652632</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.673684</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.747368</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.757895</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.778947</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.873684</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.884211</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.884211</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.884211</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.863158</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.863158</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.852632</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.863158</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    # Epoch  training acc  testing acc\n",
       "0         1      0.547368     0.625000\n",
       "1         2      0.652632     0.541667\n",
       "2         3      0.673684     0.583333\n",
       "3         4      0.747368     0.583333\n",
       "4         5      0.757895     0.583333\n",
       "5         6      0.778947     0.625000\n",
       "6         7      0.789474     0.666667\n",
       "7         8      0.821053     0.666667\n",
       "8         9      0.873684     0.666667\n",
       "9        10      0.884211     0.666667\n",
       "10       11      0.884211     0.666667\n",
       "11       12      0.894737     0.666667\n",
       "12       13      0.884211     0.666667\n",
       "13       14      0.863158     0.625000\n",
       "14       15      0.863158     0.583333\n",
       "15       16      0.852632     0.583333\n",
       "16       17      0.842105     0.583333\n",
       "17       18      0.842105     0.625000\n",
       "18       19      0.842105     0.625000\n",
       "19       20      0.863158     0.625000"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_results(OUTPUT_SIZE, N_LAYERS, EMBEDDING_DIM, HIDDEN_DIM, [torch.mean, torch.max], 0.4, lr, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size =  1 n_layers = 1 embedding_dim =  200 hidden_dim =  50 combine_funcs =  [<built-in method mean of type object at 0x115fcceb0>, <built-in method max of type object at 0x115fcceb0>] drop_prob =  0.4 lr =  0.001 epochs =  20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Epoch</th>\n",
       "      <th>training acc</th>\n",
       "      <th>testing acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.505263</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.568421</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.747368</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.810526</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.831579</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.831579</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.810526</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    # Epoch  training acc  testing acc\n",
       "0         1      0.505263     0.500000\n",
       "1         2      0.568421     0.500000\n",
       "2         3      0.631579     0.458333\n",
       "3         4      0.747368     0.541667\n",
       "4         5      0.810526     0.500000\n",
       "5         6      0.800000     0.500000\n",
       "6         7      0.831579     0.458333\n",
       "7         8      0.821053     0.500000\n",
       "8         9      0.831579     0.541667\n",
       "9        10      0.810526     0.541667\n",
       "10       11      0.789474     0.458333\n",
       "11       12      0.800000     0.458333\n",
       "12       13      0.800000     0.458333\n",
       "13       14      0.821053     0.500000\n",
       "14       15      0.800000     0.458333\n",
       "15       16      0.821053     0.500000\n",
       "16       17      0.821053     0.500000\n",
       "17       18      0.842105     0.500000\n",
       "18       19      0.842105     0.500000\n",
       "19       20      0.842105     0.458333"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_results(OUTPUT_SIZE, N_LAYERS, EMBEDDING_DIM, HIDDEN_DIM, [torch.mean, torch.max], 0.4, lr, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size =  1 n_layers = 1 embedding_dim =  200 hidden_dim =  50 combine_funcs =  [<built-in method mean of type object at 0x115fcceb0>, <built-in method max of type object at 0x115fcceb0>] drop_prob =  0.4 lr =  0.001 epochs =  20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Epoch</th>\n",
       "      <th>training acc</th>\n",
       "      <th>testing acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.547368</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.568421</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.652632</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.663158</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.747368</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.757895</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.852632</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.852632</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.852632</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.810526</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.810526</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    # Epoch  training acc  testing acc\n",
       "0         1      0.547368     0.583333\n",
       "1         2      0.568421     0.500000\n",
       "2         3      0.652632     0.541667\n",
       "3         4      0.663158     0.625000\n",
       "4         5      0.747368     0.666667\n",
       "5         6      0.757895     0.708333\n",
       "6         7      0.800000     0.708333\n",
       "7         8      0.821053     0.708333\n",
       "8         9      0.821053     0.708333\n",
       "9        10      0.842105     0.708333\n",
       "10       11      0.852632     0.708333\n",
       "11       12      0.852632     0.750000\n",
       "12       13      0.852632     0.750000\n",
       "13       14      0.842105     0.750000\n",
       "14       15      0.842105     0.791667\n",
       "15       16      0.842105     0.666667\n",
       "16       17      0.821053     0.708333\n",
       "17       18      0.810526     0.708333\n",
       "18       19      0.810526     0.708333\n",
       "19       20      0.821053     0.708333"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_results(OUTPUT_SIZE, N_LAYERS, EMBEDDING_DIM, HIDDEN_DIM, [torch.mean, torch.max], 0.4, lr, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size =  1 n_layers = 1 embedding_dim =  200 hidden_dim =  50 combine_funcs =  [<built-in method mean of type object at 0x115fcceb0>, <built-in method max of type object at 0x115fcceb0>] drop_prob =  0.4 lr =  0.001 epochs =  20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Epoch</th>\n",
       "      <th>training acc</th>\n",
       "      <th>testing acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.873684</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.873684</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.873684</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.884211</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.884211</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    # Epoch  training acc  testing acc\n",
       "0         1      0.873684     0.583333\n",
       "1         2      0.873684     0.625000\n",
       "2         3      0.873684     0.625000\n",
       "3         4      0.884211     0.541667\n",
       "4         5      0.884211     0.541667\n",
       "5         6      0.894737     0.541667\n",
       "6         7      0.905263     0.583333\n",
       "7         8      0.915789     0.541667\n",
       "8         9      0.905263     0.583333\n",
       "9        10      0.905263     0.625000\n",
       "10       11      0.915789     0.625000\n",
       "11       12      0.915789     0.666667\n",
       "12       13      0.915789     0.666667\n",
       "13       14      0.915789     0.666667\n",
       "14       15      0.915789     0.666667\n",
       "15       16      0.915789     0.666667\n",
       "16       17      0.915789     0.625000\n",
       "17       18      0.915789     0.666667\n",
       "18       19      0.905263     0.625000\n",
       "19       20      0.894737     0.583333"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_results(OUTPUT_SIZE, N_LAYERS, EMBEDDING_DIM, HIDDEN_DIM, [torch.mean, torch.max], 0.4, lr, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size =  1 n_layers = 1 embedding_dim =  200 hidden_dim =  50 combine_funcs =  [<built-in method mean of type object at 0x115fcceb0>, <built-in method max of type object at 0x115fcceb0>] drop_prob =  0.7 lr =  0.01 epochs =  20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Epoch</th>\n",
       "      <th>training acc</th>\n",
       "      <th>testing acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.515789</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.726316</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.778947</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.747368</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.757895</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.778947</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.757895</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.884211</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.905263</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.936842</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.936842</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.884211</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.715789</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.757895</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.989474</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.747368</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    # Epoch  training acc  testing acc\n",
       "0         1      0.515789     0.500000\n",
       "1         2      0.726316     0.583333\n",
       "2         3      0.778947     0.583333\n",
       "3         4      0.747368     0.458333\n",
       "4         5      0.757895     0.583333\n",
       "5         6      0.778947     0.500000\n",
       "6         7      0.800000     0.541667\n",
       "7         8      0.684211     0.541667\n",
       "8         9      0.757895     0.583333\n",
       "9        10      0.884211     0.541667\n",
       "10       11      0.905263     0.541667\n",
       "11       12      0.915789     0.541667\n",
       "12       13      0.936842     0.583333\n",
       "13       14      0.915789     0.583333\n",
       "14       15      0.936842     0.625000\n",
       "15       16      0.884211     0.500000\n",
       "16       17      0.715789     0.541667\n",
       "17       18      0.757895     0.541667\n",
       "18       19      0.989474     0.625000\n",
       "19       20      0.747368     0.625000"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_results(OUTPUT_SIZE, N_LAYERS, EMBEDDING_DIM, HIDDEN_DIM, [torch.mean, torch.max], DROPOUT_PROB, lr, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_results(OUTPUT_SIZE, N_LAYERS, EMBEDDING_DIM, HIDDEN_DIM, [torch.mean, torch.max], DROPOUT_PROB, lr, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([95, 800])\n",
      "tensor(0.6929, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "torch.Size([95, 800])\n",
      "torch.Size([24, 800])\n",
      "torch.Size([95, 800])\n",
      "tensor(0.6958, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "torch.Size([95, 800])\n",
      "torch.Size([24, 800])\n",
      "torch.Size([95, 800])\n",
      "tensor(0.6592, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "torch.Size([95, 800])\n",
      "torch.Size([24, 800])\n",
      "torch.Size([95, 800])\n",
      "tensor(0.6423, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "torch.Size([95, 800])\n",
      "torch.Size([24, 800])\n",
      "torch.Size([95, 800])\n",
      "tensor(0.6292, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "torch.Size([95, 800])\n",
      "torch.Size([24, 800])\n",
      "torch.Size([95, 800])\n",
      "tensor(0.5868, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "torch.Size([95, 800])\n",
      "torch.Size([24, 800])\n",
      "torch.Size([95, 800])\n",
      "tensor(0.5452, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "torch.Size([95, 800])\n",
      "torch.Size([24, 800])\n",
      "torch.Size([95, 800])\n",
      "tensor(0.4975, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "torch.Size([95, 800])\n",
      "torch.Size([24, 800])\n",
      "torch.Size([95, 800])\n",
      "tensor(0.6022, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "torch.Size([95, 800])\n",
      "torch.Size([24, 800])\n",
      "torch.Size([95, 800])\n",
      "tensor(0.4290, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "torch.Size([95, 800])\n",
      "torch.Size([24, 800])\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "counter = 0\n",
    "print_every = 1000\n",
    "# clip = 5\n",
    "valid_loss_min = np.Inf\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "#     h = model.init_hidden(batch_size)\n",
    "    \n",
    "#     for inputs, labels in train_loader:\n",
    "#         counter += 1\n",
    "#         h = tuple([e.data for e in h])\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "    model.zero_grad()\n",
    "    output = model(X_train)\n",
    "    loss = criterion(output.squeeze(), y_train.float())\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "#     nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "    optimizer.step()\n",
    "    outs = model(X_train)\n",
    "    train_acc.append(torch.sum((outs > 0.5) == y_train).item() / len(y_train))\n",
    "    outs = model(X_test)\n",
    "    test_acc.append(torch.sum((outs > 0.5) == y_test).item() / len(y_test))\n",
    "    \n",
    "    \n",
    "#         if counter%print_every == 0:\n",
    "#             val_h = model.init_hidden(batch_size)\n",
    "#             val_losses = []\n",
    "#             model.eval()\n",
    "#             for inp, lab in val_loader:\n",
    "#                 val_h = tuple([each.data for each in val_h])\n",
    "#                 inp, lab = inp.to(device), lab.to(device)\n",
    "#                 out, val_h = model(inp, val_h)\n",
    "#                 val_loss = criterion(out.squeeze(), lab.float())\n",
    "#                 val_losses.append(val_loss.item())\n",
    "                \n",
    "#             model.train()\n",
    "#             print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
    "#                   \"Step: {}...\".format(counter),\n",
    "#                   \"Loss: {:.6f}...\".format(loss.item()),\n",
    "#                   \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "#             if np.mean(val_losses) <= valid_loss_min:\n",
    "#                 torch.save(model.state_dict(), './state_dict.pt')\n",
    "#                 print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,np.mean(val_losses)))\n",
    "#                 valid_loss_min = np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5157894736842106,\n",
       " 0.5263157894736842,\n",
       " 0.6210526315789474,\n",
       " 0.7052631578947368,\n",
       " 0.7052631578947368,\n",
       " 0.8842105263157894,\n",
       " 0.7578947368421053,\n",
       " 0.6,\n",
       " 0.8105263157894737,\n",
       " 0.7263157894736842]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5,\n",
       " 0.5416666666666666,\n",
       " 0.5833333333333334,\n",
       " 0.5,\n",
       " 0.625,\n",
       " 0.6666666666666666,\n",
       " 0.5,\n",
       " 0.5833333333333334,\n",
       " 0.5833333333333334,\n",
       " 0.5]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outs = model(X_train)\n",
    "# torch.sum((outs > 0.5) == y_train).item() / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5020, 0.3077, 0.3503, 0.5805, 0.4688, 0.5605, 0.1735, 0.3698, 0.3980,\n",
       "        0.5669, 0.5357, 0.4020, 0.3885, 0.4056, 0.3149, 0.6157, 0.5548, 0.5643,\n",
       "        0.3511, 0.5886, 0.3619, 0.5594, 0.4987, 0.6190],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FullyNet(nn.Module):\n",
    "#     def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "#         super(FullyNet, self).__init__()\n",
    "#         self.output_size = output_size\n",
    "#         self.n_layers = n_layers\n",
    "#         self.hidden_dim = hidden_dim\n",
    "        \n",
    "#         #self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "#         self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "#         self.dropout = nn.Dropout(drop_prob)\n",
    "#         self.fc = nn.Linear(hidden_dim, output_size)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "#     def forward(self, x, hidden):\n",
    "#         batch_size = x.size(0)\n",
    "#         x = x.long()\n",
    "#         #embeds = self.embedding(x)\n",
    "#         lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "#         lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "#         out = self.dropout(lstm_out)\n",
    "#         out = self.fc(out)\n",
    "#         out = self.sigmoid(out)\n",
    "        \n",
    "#         out = out.view(batch_size, -1)\n",
    "#         out = out[:,-1]\n",
    "#         return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
