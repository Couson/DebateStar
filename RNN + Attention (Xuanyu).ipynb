{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob \n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stopwords?\n",
    "Combine all for points?\n",
    "What if word not exist?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Word Embeddings, Attention Vectors, and Matching Vectors using GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found word vecs:  400000\n"
     ]
    }
   ],
   "source": [
    "embedding_index = {}\n",
    "\n",
    "f = open('glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:],dtype='float32')\n",
    "    embedding_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('found word vecs: ',len(embedding_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>for</th>\n",
       "      <th>against</th>\n",
       "      <th>For_Main_Points</th>\n",
       "      <th>against_Main_Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d20191112</td>\n",
       "      <td>Capitalism Is a Blessing</td>\n",
       "      <td>2019-11-12</td>\n",
       "      <td>['John Mackey', 'Katherine Mangu-Ward']</td>\n",
       "      <td>['Bhaskar Sunkara', 'Richard D. Wolff']</td>\n",
       "      <td>['By promoting market competition and rewardin...</td>\n",
       "      <td>['Capitalism serves the interests of large cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d20191029</td>\n",
       "      <td>Parenting Is Overrated</td>\n",
       "      <td>2019-10-29</td>\n",
       "      <td>['Robert Plomin', 'Nancy Segal']</td>\n",
       "      <td>['Paige Harden', 'Ann Pleshette Murphy']</td>\n",
       "      <td>[\"We're in the midst of a DNA revolution: Whil...</td>\n",
       "      <td>['While DNA is important, factors like familia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d20191022</td>\n",
       "      <td>Europe Has Declared War on American Tech Compa...</td>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>['Roslyn Layton', 'Berin Szóka']</td>\n",
       "      <td>['Marietje Schaake', 'Ramesh Srinivasan']</td>\n",
       "      <td>['European regulators have declared war on Ame...</td>\n",
       "      <td>['Brussels isn’t waging war on Silicon Valley....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d20190917</td>\n",
       "      <td>Replace Private Insurance with Medicare for All</td>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>['Dr. Adam Gaffney', 'Joseph Sanberg']</td>\n",
       "      <td>['Nick Gillespie', 'Sally Pipes']</td>\n",
       "      <td>['The United States government should follow t...</td>\n",
       "      <td>['Individuals should have the freedom to choos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d20190912</td>\n",
       "      <td>Unresolved: Shifting Power in the Middle East</td>\n",
       "      <td>2019-09-12</td>\n",
       "      <td>['Michael Doran', 'Reuel Marc Gerecht', 'Berna...</td>\n",
       "      <td>['Brett McGurk', 'Barbara Slavin']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title        date  \\\n",
       "0  d20191112                           Capitalism Is a Blessing  2019-11-12   \n",
       "1  d20191029                             Parenting Is Overrated  2019-10-29   \n",
       "2  d20191022  Europe Has Declared War on American Tech Compa...  2019-10-22   \n",
       "3  d20190917    Replace Private Insurance with Medicare for All  2019-09-17   \n",
       "4  d20190912      Unresolved: Shifting Power in the Middle East  2019-09-12   \n",
       "\n",
       "                                                 for  \\\n",
       "0            ['John Mackey', 'Katherine Mangu-Ward']   \n",
       "1                   ['Robert Plomin', 'Nancy Segal']   \n",
       "2                   ['Roslyn Layton', 'Berin Szóka']   \n",
       "3             ['Dr. Adam Gaffney', 'Joseph Sanberg']   \n",
       "4  ['Michael Doran', 'Reuel Marc Gerecht', 'Berna...   \n",
       "\n",
       "                                     against  \\\n",
       "0    ['Bhaskar Sunkara', 'Richard D. Wolff']   \n",
       "1   ['Paige Harden', 'Ann Pleshette Murphy']   \n",
       "2  ['Marietje Schaake', 'Ramesh Srinivasan']   \n",
       "3          ['Nick Gillespie', 'Sally Pipes']   \n",
       "4         ['Brett McGurk', 'Barbara Slavin']   \n",
       "\n",
       "                                     For_Main_Points  \\\n",
       "0  ['By promoting market competition and rewardin...   \n",
       "1  [\"We're in the midst of a DNA revolution: Whil...   \n",
       "2  ['European regulators have declared war on Ame...   \n",
       "3  ['The United States government should follow t...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                 against_Main_Points  \n",
       "0  ['Capitalism serves the interests of large cor...  \n",
       "1  ['While DNA is important, factors like familia...  \n",
       "2  ['Brussels isn’t waging war on Silicon Valley....  \n",
       "3  ['Individuals should have the freedom to choos...  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_points =pd.read_csv('DebateStar/Meta Data/metadata_appended_main_points.csv') \n",
    "main_points.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_points(fid, main_points):\n",
    "    \"\"\"\n",
    "    Returns main points for both sides given fid and main_points table\n",
    "    \"\"\"\n",
    "    for_points = main_points.loc[main_points['id'] == fid]['For_Main_Points'].item()\n",
    "    for_points = ast.literal_eval(for_points)\n",
    "    against_points = main_points.loc[main_points['id'] == fid]['against_Main_Points'].item()\n",
    "    against_points = ast.literal_eval(against_points)\n",
    "    return for_points, against_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = string.punctuation\n",
    "def tokenize_point(point):\n",
    "    \"\"\"\n",
    "    Returns a list of lowercased tokens, without punctuations\n",
    "    \"\"\"\n",
    "    tokens = [t for t in word_tokenize(point.lower()) if t not in punctuations]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2glove(word, embedding_index):\n",
    "    \"\"\"\n",
    "    Returns GloVe embedding given a word, and zeros if word does not exist in the dictionary\n",
    "    \"\"\"\n",
    "    word = word.lower()\n",
    "    try:\n",
    "        word_vec = embedding_index[word]\n",
    "    except:\n",
    "        word_vec = np.zeros(embedding_index['the'].shape)\n",
    "    return word_vec\n",
    "\n",
    "def point2gloves(point, embedding_index):\n",
    "    \"\"\"\n",
    "    Returns a list of word embeddings given a sentence\n",
    "    \"\"\"\n",
    "    word_vecs = np.array([word2glove(word, embedding_index) for word in tokenize_point(point)])\n",
    "    return word_vecs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def attention_vector(word, embedding_index, title_vecs):\n",
    "    \"\"\"\n",
    "    Returns the attention vector of a word w.r.t. the title (a_k in paper)\n",
    "    \"\"\"\n",
    "    word_vec = word2glove(word, embedding_index)\n",
    "    weights = cosine_similarity([word_vec], title_vecs)\n",
    "    attention_vec = np.matmul(title_vecs.T, weights.reshape((-1,1))).T[0]\n",
    "    return attention_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.concatenate((attention_vector('king', embedding_index, title_vecs), \\\n",
    "#                word2glove('the', embedding_index)), axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_vector(attention_vec, word, embedding_index):\n",
    "    \"\"\"\n",
    "    Returns the matching vector of a word w.r.t. the title by concatenating the \n",
    "    resulting attention vector and word embedding(m_k in paper)\n",
    "    \"\"\"\n",
    "    matching_vec = np.concatenate((attention_vec, word2glove(word, embedding_index)), axis = None)\n",
    "    return matching_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debate Title: Capitalism Is a Blessing\n"
     ]
    }
   ],
   "source": [
    "fid = 'd20191112'\n",
    "title = main_points.loc[main_points['id'] == fid]['title'].iloc[0]\n",
    "for_points, against_points = get_main_points(fid, main_points)\n",
    "print('Debate Title:', title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'socialism'\n",
    "title_vecs = point2gloves(title, embedding_index)\n",
    "attention_vec = attention_vector(word, embedding_index, title_vecs)\n",
    "matching_vec = matching_vector(attention_vec, word, embedding_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: socialism\n",
      "Similarities between attention vector and words in title: [[0.89212716 0.623381   0.53955615 0.40743887]]\n"
     ]
    }
   ],
   "source": [
    "print('word:', word)\n",
    "print('Similarities between attention vector and words in title:', cosine_similarity([attention_vec], title_vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3015426 ,  0.9216185 ,  0.9031023 , -0.07591914, -0.00535155,\n",
       "        0.29403263, -0.47589275, -0.699059  , -0.01627889, -0.251849  ,\n",
       "       -0.57344663,  0.6658845 ,  0.09023698,  0.04401395,  0.37690887,\n",
       "       -0.0772756 ,  0.4640494 ,  0.4316342 , -0.51178044, -0.19788025,\n",
       "        0.33429575, -0.10098885, -0.35101748, -0.24833116,  0.17554505,\n",
       "        0.41560915, -0.49203956, -0.19756055, -0.11192715, -0.00694678,\n",
       "       -0.24993534,  1.2522714 , -0.39274085, -0.31340644,  0.26661408,\n",
       "        0.18764499,  0.09789918, -0.2171377 , -0.40555012, -0.42812616,\n",
       "       -0.58505064, -0.20553707, -0.2493966 ,  0.50509006, -0.18823734,\n",
       "       -0.69646555,  0.8033727 ,  0.27810642, -0.3216776 , -0.19422434,\n",
       "       -0.5528731 ,  0.3381607 , -0.25321126,  1.1384412 , -0.3097309 ,\n",
       "       -1.947628  ,  0.04279271,  0.34267896,  1.11995   ,  0.01181408,\n",
       "       -0.04970998, -0.30868697, -0.49640337, -0.45260602,  0.7727301 ,\n",
       "       -0.0720768 ,  0.6050939 , -0.694137  ,  0.1374662 , -0.6827831 ,\n",
       "       -0.05935139, -0.38913152, -0.5537234 ,  0.20190582,  0.00900021,\n",
       "       -0.9655199 , -0.23224224, -0.08754849, -1.3047184 , -0.23446798,\n",
       "        0.533195  ,  0.35055444, -0.7456346 ,  0.50665754, -0.8385333 ,\n",
       "        0.24463849, -0.34820673, -0.5513921 , -0.16797295, -1.2214959 ,\n",
       "        0.87758094, -0.7839321 , -0.0303722 ,  0.67882806,  0.19776304,\n",
       "       -0.7188908 ,  0.01897669, -1.0327722 ,  0.42653677,  0.7102831 ,\n",
       "        0.58774   ,  1.0136    ,  0.12154   ,  0.3809    ,  0.27997   ,\n",
       "       -0.18086   , -0.046417  , -1.4825    , -0.24103   ,  0.15077   ,\n",
       "       -0.30181   ,  0.43132   ,  0.092594  , -0.25449   ,  0.46139   ,\n",
       "       -0.49253   ,  0.3396    ,  0.41709   , -0.21526   , -0.84969   ,\n",
       "        0.46405   ,  0.095926  , -0.19822   , -0.40473   , -0.15237   ,\n",
       "       -0.11712   , -0.52181   , -0.31084   ,  0.30088   , -0.012459  ,\n",
       "       -0.25249   ,  1.4309    , -0.26403   , -0.10035   ,  0.0049937 ,\n",
       "        0.20879   ,  0.82909   , -0.44195   , -1.0374    , -0.10698   ,\n",
       "       -1.0712    , -0.12075   ,  0.10138   ,  0.20281   , -0.56851   ,\n",
       "       -0.65964   ,  0.75446   ,  0.38425   , -0.9565    ,  0.017219  ,\n",
       "       -0.63366   ,  0.62114   , -0.54883   ,  1.0189    ,  0.054783  ,\n",
       "       -0.12669   ,  0.39561   ,  0.99479   ,  0.46916   ,  0.22406   ,\n",
       "       -0.35348   , -0.21162   , -0.56721   , -0.21819   ,  0.66092   ,\n",
       "        0.20119   , -0.16577   , -0.80408   , -0.39377   , -0.64361   ,\n",
       "        0.19505   ,  0.46522   , -0.32829   , -0.52918   ,  0.33002   ,\n",
       "       -0.50982   , -0.12484   ,  0.13296   , -1.0507    , -0.64784   ,\n",
       "       -0.72755   ,  0.49911   , -0.62907   ,  0.5289    , -0.15827   ,\n",
       "        0.669     , -0.64447   , -0.28142   , -0.17425   , -0.74145   ,\n",
       "        0.78399   , -0.8087    ,  0.12779   ,  1.1449    , -0.048511  ,\n",
       "       -0.94489   , -0.08465   , -1.2694    ,  0.22564   ,  0.47859   ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
