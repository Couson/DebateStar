{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Text Cleaning\n",
    "This file cleans the text from a single debate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Script</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Kori Schake</td>\n",
       "      <td>So, Jake Sullivan raised a really important ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Jake Sullivan</td>\n",
       "      <td>You know, when your argument that the policy i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Kori Schake</td>\n",
       "      <td>Yep. I would say the national debt is number two.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Jake Sullivan</td>\n",
       "      <td>Well, I agree with Kori on the general directi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Michael Pillsbury</td>\n",
       "      <td>A related issue, which is hard to -- it takes ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Speaker                                             Script\n",
       "107        Kori Schake  So, Jake Sullivan raised a really important ch...\n",
       "108      Jake Sullivan  You know, when your argument that the policy i...\n",
       "109        Kori Schake  Yep. I would say the national debt is number two.\n",
       "110      Jake Sullivan  Well, I agree with Kori on the general directi...\n",
       "111  Michael Pillsbury  A related issue, which is hard to -- it takes ..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read a single speach from csv file\n",
    "scripts = pd.read_csv('cleaned_transcript_data/cleaned_transcript_d20190802.csv')\n",
    "scripts = scripts.drop(scripts.columns[0], axis=1)\n",
    "scripts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Thank you. Let me begin with my description or my definition of recent U.S. policy. I repeated several times. Barack Obama started going down the right path toward a tougher line toward China. I didn't get a chance to mention something he did in the South China Sea. He began to send U.S. Navy warships through excessive Chinese territorial claims. In one case, his team knew that, if you do acts of war inside the territorial zone, the other side could get quite excited. But President Obama had the courage to do it anyway. In September 2016, he sent a U.S. Navy destroyer that zig-zagged its way through a Chinese island claim. This is the beginning of showing that China is not going to get away with it in the South China Sea. A United Nations related body ruled against China's claims. This gets back to the liberal world order -- that somehow, the Chinese government has got to be dissuaded from these policies. So, Obama started it. Trump has continued it. It's not nearly enough, we seem to all agree. And I would just try to close, and get your vote, by saying, how much are we going to have to do to bring China around to what we all thought China was going to be 30 years ago? Free markets. Some kind of democracy. Pro-American, somehow -- and appreciation and gratitude for all we've done to build up China. That's the question of our debate. And Kori and I think we're on the right track now. Apparently, Graham and Jake are just negative-minded guys who can't see anything positive.\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a single speech\n",
    "speech = scripts.loc[105]['Script']\n",
    "speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cleaned words: 164 , removed meaningless words: 105\n",
      "['Thank', 'Let', 'begin', 'description', 'definition']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize words without punctuations\n",
    "words = word_tokenize(speech.translate(str.maketrans('', '', string.punctuation)))\n",
    "# Remove meaninglesss words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "cleaned_words = [w for w in words if w not in stop_words]\n",
    "print('Number of cleaned words:', len(cleaned_words), ', removed meaningless words:', len(words) - len(cleaned_words))\n",
    "print(cleaned_words[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thank you',\n",
       " 'Let me begin with my description or my definition of recent US policy',\n",
       " 'I repeated several times',\n",
       " 'Barack Obama started going down the right path toward a tougher line toward China',\n",
       " 'I didnt get a chance to mention something he did in the South China Sea']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenized sentences without punctuations\n",
    "sentences = sent_tokenize(speech)\n",
    "sentences = [s.translate(str.maketrans('', '', string.punctuation)) for s in sentences]\n",
    "sentences[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
