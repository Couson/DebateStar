side,script
for,"The debate gives me chills because it reminds me of two dates: 1789, the date the Constitution was ratified, and 1789, the date that the founding generation passed the Alien and Sedition Act indicating that debates about free speech have been alive as long as our Constitution has been alive. Well, you know, it's hard to choose so I'll just tell you about a recent case that was particularly fun. And that involved a situation where a group of activists took to the streets of Washington, D.C., and Philadelphia and New York, handing out spoof copies of the Washington Post in which the headline announced that Trump had at last resigned. It was lots of fun. They got lots of attention. The Washington Post also paid attention and was not happy. So they received a legal threat. They called us. We intervened, and we explained to The Washington Post what they should already know, which is that that spoof was protected by the First Amendment. Washington Post should know that. They realized it, they backed down. We called it a win."
against,"So, along with a Harvard professor named Gary King, I co-chair something called Social Science 1. And this is an attempt to make Facebook data available for the world's scientific community in a safe, privacy-protected way to ensure that we can figure out the answers as to how special media is affecting democracy around the world. Oh, it means – Yes, yes, yes. Yeah, yeah. So, for the past 10 years that I've had the pleasure of serving in the European Parliament, I tried to bring the world of technology and politics closer together because I think it is more important with every day that passes. Technology is everywhere. Digitization impacts all aspects of life, and it's very, very important that politicians are available to make the right decisions. So I suppose because I'm one of a few that's focused on this, that's a curious title."
for," Thank you for having me. I'm really excited to be here and to talk about this topic. I feel like this is what I live and breathe these days because that's -- the reality of defending speech online is talking about content moderation and trying to figure out what to do about it. Because I think one thing, we should surely be able to agree on is that it desperately needs saving. The content moderation system, what we call sometimes platform or private censorship, it's fundamentally broken. What Twitter, Facebook, Pinterest, Medium, everybody's trying to manage all the content on their platforms and make sure nobody ever says anything bad, and it's not working. In fact, it's fundamentally broken. Now, let me start by acknowledging something. The internet offers extraordinary tools for us to connect, to organize, to educate, access information. It's an amazing, amazing thing. But, the reality is, online speech can also be awful, ugly, and cause real world harm. So I want to get out of the gate by acknowledging that that is true. The question is, what the best way to address that problem? And the reality is that the current system of content moderation is not the answer. Let me count the ways. First of all, the fact of the matter is social media platforms are just really bad at deciding what speech should stay up and what should stay down. So, I’ll just give you a few examples. We’ve seen provisions on hate speech used to shut down conversations between women of color about online harassment. We’ve seen rules against harassment used to shut down the accounts of activists in Egypt and the United States and around the world. We’ve seen a ban on nudity used to take down graphic artworks, including -- the Philadelphia Museum of Art had its account flagged because it posted a so-called suggestive painting of a woman eating an ice-cream cone. That was taken down by Facebook. Queer and transgender youth hoping to connect with new communities are having difficulty doing so because of Facebook’s “real names” policy, which prevents them from engaging online anonymously. Regulations on violent content have been forced offline; documentation of police brutality, world trafficking, human rights abuses, and so on. In fact, it’s so bad that there were just two articles just last week detailing the difficulty that Facebook and other platforms are having trying to figure out a sane and coherent policy for online speech. They just can’t do it, and it may be because it’s impossible. Another thing that’s happening related to that is that this content moderation is to the moderators. They are -- end up having PTSD-like symptoms when they have to review all this awful content and make decisions about it. And then governments are getting into the mix, so they are inserting themselves into takedown decisions. And in Latin America just recently, campaigns against so-called fake news and misinformation are being used as an excuse to silence critics. So, we have a real problem here, and the final thing that makes me particularly frustrated is if the goal was to stop hate and counter extremism, it’s not working. So, for example, Facebook’s “real names” policy that prevents people from engaging anonymously didn’t stop Russia from gaming the system. Counterterrorism expert said, “Censorship is never an effective means of achieving security. Shuttering websites and suppressing content would be as unhelpful as smashing printing presses.” So, it strikes me as just a little bit crazy that so many people are pushing for the companies to double down on what is clearly a failing system. We need a better approach, and we can start by turning to our core constitutional principles. If we did that, if we looked to the First Amendment as a guidepost, we might have a few things. Perhaps we could get to clearer definitions of what content should and should not be restricted on what terms, while looking to, for example, decades of defamation law, where judges have wrestled with precisely this issue. Companies could apply a kind of strict scrutiny to their policies. Is doing accomplish a compelling public interest here? Is this the best way to do it, the most narrowly tailored way to do it? Our default could be that speech goes up rather than going down, following our long tradition of no prior restraints on speech in the United States. We would have stronger protections for anonymity, which would mean that ordinary users, activists, and organizers could find each other and activate communities with less fear of retaliation. And above all, we could have two process protections. In the First Amendment context, the burden of proving that speech is unprotected or shouldn’t be protected rests with the censor, and the censor has to, if it takes content down, go to court, get a review quickly. We should have the same situation with respect to social media, so we could have notice to users before the content is taken down, an opportunity to appeal. And again, the burden is on the censor to explain why the speech should be taken down, and in the meantime, it stays up because that is our default belief in this country. I’m going to close with a quote from Learned Hand, which I think should resonate particularly strongly here. Judge Hand said in 1943, another difficult time in our history -- he said, “The First Amendment presupposes that right conclusions are more likely to be gathered out of a multitude of tongues than through any kind of authoritative selection. And to many this is, and always will be, folly, but we have staked upon it our all.” Social media platforms allow the multitudes to speak in ways they never could before, but the owners of those platforms are engaging in precisely the kind of authoritative selection that Learned Hand warned against, with predictable results. I suspect that Judge Hand would support this motion, and so should you."
against,"So when I think about what might save social media companies from themselves, I think a little bit maybe about antitrust law, maybe about greater privacy protection. I rarely think that what we need is actually more hate speech, more pornography, more bots, more trolls, more foreign interference in elections. And that actually is what the First Amendment would require if these social media companies were to apply. Now, you can love the First Amendment like I do. And I do in fact get chills when I walk by Independence Hall and come into this meeting room. But the First Amendment is to restrict government. It's not actually to restrict private companies like Facebook. And, actually, if you believe in the First Amendment, you will actually believe that Facebook and other social media companies can apply different rules to the speech that's on their platform. Now, my arguments against this resolution are just a few short points. The first is that it's actually naive to think that you can apply the First Amendment in the context of a social media platform. The second is that it's actually undesirable. The third is that it's actually illegal. And the fourth is that it's actually hypocritical. Besides that, I agree with this resolution, okay? So, the first is that it's naive. What these social media companies do, the most important power that they do while we focus on these takedowns and the other types of restrictions that Corynne mentioned, is that they organize information, right? They tell you what goes at the top of your news feed and what goes at the bottom, right? These are inherently content-based decisions that they decide that some type of content is going to be served to you first and something's going to later. Any factor that's in the algorithm that is based on content violates the First Amendment, okay? And these decisions that they are making about, for example, whether they're going to put engage can content at the top, whether they're going to prioritize disinformation or non-disinformation, whether they are going to put hate speech at the top of your news feed. All of these decisions are going to be unconstitutional if they were applied by the government. That these products that they are delivering you, as powerful as they are, and as much as we should have oversight and government regulation on these platforms, it's not the place for the First Amendment. The second argument is that it's actually undesirable. So, let's just take a tour through the First Amendment for a second and First Amendment case law recently to give you a sense of what it would mean if the social media companies were to apply it. So, as Corynne mentioned, yes, there's the possibility that then you would end up having more nudity in your news feed. It's much more than that. Virtually all pornography is protected by the First Amendment, right? Because Facebook's not going to know it when it sees it, right? And so, do they actually have an obligation. Does Instagram, which has 13-year-olds on its platform, have an obligation to respect the same Constitutional restrictions on pornography that the government does? Similarly, with hate speech, it's perfectly well and good -- I have a real problem with federal or state or even university-banned hate speech laws. I think they're overbroad. But does Facebook actually have to decide that just because Nazis are allowed to March in Scoffey that they can march across your news feed, right? These are private companies that have different ideas and different values and different priorities as to what should be coming at you in your social media feeds. In addition, under Citizens United vs. FEC , a case familiar to many of you, right, does Facebook actually have to allow uncontrolled, unlimited corporate politic ad spending on their platform? You might think that that is actually protected by the First Amendment, but it doesn't mean that Facebook actually has to allow it on its platform. And you can go on and on. Violent video games, right? No prior restraints which would prevent all algorithmic curation. Or, as Corynne mentioned, the issue of anonymity, right? Can Facebook require that people actually use their real names and that they be sort of open and notorious in their speech in maybe not. Maybe it's desirable that they keep anonymity. And there are plenty of places on the internet that you can be anonymous. But, if Facebook is going to try to get at foreign interference in elections, hate speech and other kinds of unaccountable speech, it's going to have to force a real names policy as ineffective as it may be in the interim, right, in order to get at this critical problem of anonymity online. The third point is that it's actually illegal for Facebook to do this. We tend to think -- look at Facebook through the American lens here, right, that they think that, I mean, how could anybody be against applying American Constitutional principles, right, to American audiences? The truth is, Facebook is an international platform. And so, while holocaust denial is perfectly protected under the U.S. Constitution, right, and you can say all kinds of things that would be abhorrent. You know what? Germany might have a different view on this. Myanmar, in the condition of civil strife and racial hatred that is really a tinderbox -- they have different rules when it comes to hate speech, and for an American multinational corporation to then decide that there is one standard, a U.S. Constitutional standard, that then is going to apply around the world is a real problem. The last point is that it’s actually hypocritical. Like I said, I want to wrap myself in the First Amendment, okay? Because if you believe in the First Amendment, you actually believe that different social media companies can come up with different rules as to what kind of content should appear on their platform. If you want anarchy, if you want all the potential hate speech, pornography, and the like, there are plenty of places on the internet for you.  You can go to Gab if you’re worried about censorship of conservatives; you could go to Reddit and create your own subreddit for a particular issue. You could go to, you know, closed email lists and bulletin boards. But also, if you’re a social media company that’s a little bit worried about what might happen to the community under those circumstances, that maybe it would have an effect, whether it’s on elections, or whether it’s on the users themselves, that then you could make the decision that “you know what? There are going to be some rules that we don’t apply to government but would be particularly fitted in this case.” And for that reason, please vote that constitutional free -- yeah, I had a great closing there -- constitutional free speech principles cannot save social media companies from themselves."
for,"So, thank you very much for having me. I was going to go all good-cop and uplifting until your statement, but I’m going to have to rebut some -- go a little bad-cop and rebut it. And here’s what I’m -- I’m used to being a bad cop. I’m used to being a civil rights/civil liberties litigator. I used to brag that -- and I think it was true when I used to brag about it -- I sued more universities on free speech grounds than any living lawyer. And so, I’m very used to arguing about how censors mess things up, and if there’s one thing that we know, and one thing that we have seen over 200-plus years of attempted censorship in the United States of America, it’s that censors constantly and consistently mess things up and exacerbate divisions. But I’m not going to dwell on that, because, you know, one of the things that we often end up doing is sort of talking about “how do we control the negative aspects of free speech?” What do we do with what’s bad about free speech? I want to talk about what’s good about free speech for a moment. So, last March there was an interesting poll that the New York Times reported on. It was a poll of college students, and it said to college students, “If you had to choose between inclusion and free speech, which would you choose? Inclusion or free speech?’ And a majority of college students chose inclusion. Now, first I was mad about this poll. I was like, “That’s not the choice.” That is absolutely not the choice. It’s the choice that we tend to think is being made here on social media, that we need to censor people to protect, for example, disadvantaged or historically marginalized communities, that there is some sort of battle between inclusion and free speech, when the reality is exactly the opposite. What history has shown us is that free speech facilitates inclusion, free speech facilitates justice. As Frederick Douglass said, “Free speech is the great moral renovator of society.” And you don’t have to look anywhere besides the history of the United States of America to see this truth. We often talk about what’s bad about free speech; we often talk about the bad things that have occurred. But you know what? We have not lived in a truly free free-speech environment in this country for very long. It wasn’t until the 1920s that the First Amendment of the United States Constitution actually applied to the actions of state and local governments. A lot of us forget that for much of our history the First Amendment was -- didn’t apply in states. It suppressed, for example, abolitionist speech before the Civil War. What has happened in the United States of America? Ask yourself, since free speech has been applied at every level of American government, since the First Amendment has been applied at every level of the American government since the 1920s, are we more free? Are we less free? Is the United States a more inclusive society, or is it a less inclusive society? I think if you looked at the state of civil liberties in this country in the 1920s, and you compare it to 2019, there is absolutely no comparison. Frederick Douglas' words were accurate and prophetic. Free speech is a great moral renovator. Now, that does not mean that free speech doesn't carry with it some negative effects and negative consequences and negative actions. There is such a thing as bad speech. But, you know, we tend to make fun of college students these days. We call them snowflakes because they don't like to hear bad speech. But you know what? College students have to hear a lot more than the users of social media. Why is this? There's something we haven't talked about yet. One thing that every user of social media has the ability to do is block or mute. And that has no problem and no impact on the First Amendment. When I was in law school, there are people who would boo and hiss me when I taught. They didn't like what I had to say. Think how much better they would feel if they'd been able to mute me live? You know, it would have gone something like this: ""I disagree the establishment clause --"" I mean, they would be relieved of any obligation to ever hear from me again. You know, that's a feature that we have in every major social media platform. If you don't like to see speech, you don't have to see it anymore. So what we're talking about first -- and when we're talking about social media censorship, we're often not talking about protecting your own eyes, because you can protect your own eyes in the same way that you can choose not to watch Game of Thrones and miss out on the greatest show in the history of television. You can make that choice. I can choose not to follow people on Twitter. Or more satisfyingly, I can choose to mute them so they're just screaming into the void, not knowing I never see it. I have an ability to cure rate and manage my own feed. And so when we're talking about sanctioning social media censorship, what we're talking about is enabling me, enabling a panel, enabling a board somewhere, some distance from me, of often incompetent composition, as my debating partner has indicated, to decide not just what I am going to see, because I can decide that, consistent with the First Amendment, but to decide what everyone else will see on the basis of criteria that are broad and that are vague and that the very action of arguing about this facilitates the division that is right now tearing this country apart. The answer traditionally in American history to bad speech is better speech. In social media, the answer to bad speech can be better speech, or it can just be blocking. But what we should not do in these new platforms that span the globe, that dominate much of American political discourse, is to unlearn the lesson that we have learned since the incorporation of the Bill of Rights in the 1920s to every state, local branch of government, and that is this: The free speech, for all of its problems, is the great moral renovator of our society, and we still have renovation to do. So I would urge you to vote yes on this resolution."
against,"As a student of American studies, it's really quite special to be here in the National Constitutional Center. And part of what I just heard reminded me a little bit of those history lessons that I followed at Amsterdam University when I was trying to understand America, including the First Amendment and the American Constitution. And I can assure you that the First Amendment is the envy of many people in the world. But will it save social media companies from themselves? And that is the question this evening. So that -- the resounding answer is no. Because if the First Amendment could save social media companies from themselves, why hasn't it? And why are these companies in so much trouble? Because last time I checked, but you know this better than I do as Americans, the First Amendment does apply in this country. But privacy violations, illegal collecting and selling of data, the live streaming of a gang rape all happens. And also, if the First Amendment could save Facebook, Google, YouTube, Twitter from themselves, why would Mark Zuckerberg and other CEOs have to mislead so much about their company practices? Secondly, I don't think billion-dollar companies need to be saved. I think people do. Free speech protection in this country goes very far. Hear it is. Tweet: Hitler was right. Question: What about the holocaust? Answer: it was made up. Question: what race is the most evil to you? Answer: Mexican and black. Question: do you support genocide? Answer: I do indeed. The person is free to say this under the First Amendment, but the artificial intelligence bot called Ted that Microsoft developed was the one running the Twitter account that I was just quoting with the questions to people’s answers, and many, many more. And 10 to 15 percent of accounts on Twitter are bots, and in other platforms and in other countries, these numbers are even higher. Now, rights apply to people and persons, and I really spare you my thoughts about Citizens United, but clearly a bot does not and should not enjoy the same protection of rights as people’s speech does. But the problem is on social media platforms like Facebook, Twitter, or YouTube, you and I cannot tell the difference. Thirdly, the First Amendment is not the only law that applies to people and the protection of their rights online. The rights of privacy, data protection standards, intellectual property protection, children’s rights, public health -- they all require safeguards, too. And thankfully, tobacco companies are not protected by the First Amendment if they were to go out and advertise that smoking is the best thing you can do for your health. So, why are people and bots alike on social media suggesting that vaccinations will cure children, that methamphetamines are excellent for teenagers if they want to lose weight, or that a better life awaits after taking a suicide pill or after blowing oneself up, taking others along? And lastly, there is not enough oversight over algorithms that govern social media companies’ business models over the data that they collect and that they sell, and without this oversight, social media companies can make all kinds of lofty claims about how they’re going to filter out fake news, or how they’re going to avoid the posting of copyright-violating messages, but whether and how this is done -- this filtering-out of harmful content -- while respecting the First Amendment, and we’ve just heard how important that is -- it is entirely unknown how these algorithms are working. So, concluding, while I believe that the First Amendment is crucially important, it is not at all enough to save social media companies from themselves from doing harm to children, to people, to societies, and the world. Tech companies do not distinguish between expression of a person and a bot, and they actively want to avoid oversight. I say this to you as a serving member of European Parliament who has been on the receiving end of lobby effort after lobby effort. These tech companies are allergic to regulation. Now, for the social media companies to save themselves, I believe they have to put people over profit. Oh, and let me just stress this before I really end, especially being the only non-American on the panel this evening. It is very important to remember that social media companies reach people all over the world, so that looking at American law for American people only is always going to fall short. So, I ask you to vote against the motion. No, I'm not pro censorship. But the problem, again, is that you have no choice here, right. What the social media companies are doing is organizing information for you, right? They make a -- they have to make some decision as to what goes at the top and what goes at the bottom. That, in and of itself, right, if it's done by the government, is going to violate the First Amendment. So you can call it censorship, right, but it's essentially what the platform is, which is that it's cure rating and delivering information to you, right? And so it -- there's certainly the case that there are -- you know, there are a parade of horribles on the other side, right, that, you know, you could -- and Corynne mentioned many of them, that they could be overinclusive in their content. But the slope is slippery in both directions, okay? And so all of us are going to dig our heels in on some part of that slope. We're not going to say that the -- you know, Facebook has to allow everything onto the platform, right? The question is, is it the First Amendment? And I've given you the whole sort of array of First Amendment cases that would constrain Facebook, whether it's Citizens United, whether it's the ban on -- or the prevention of a ban on anonymity and the like. All of those things are then going to apply to Facebook, and they really wouldn't be able to regulate the platform."
for,"Sure, absolutely. So I think what we call it is private censorship. I mean, traditionally, when I'm thinking about censorship is censorship by governments. And this is different from that. But I would posit that if, in some ways, given how important social media platforms are right now, the decisions that are being made by a few corporations in Silicon Valley are having as much effect on online speech and the future of online speech as anything any government is doing at the moment, although I would flag that, by the way, governments often participate in these takedown decisions. Of governments take advantage of community standards policies to force content off line that they could never do officially, but they do it via a community standards flag. Well, so one thing that's happening is that, as I understand it, the government of France is embedding -- it's either France or Germany is embedding someone at Facebook to help them make decisions about what content should stay up and take down. We also get a lot of sort of quiet reports from companies where they don't want to admit publicly that this is what's happening, but it nevertheless is what is happening."
against,"Well, I think there should be an independent assessment of whether a takedown is appropriate or not based on the law. But what we see now is indeed that these private companies also, for their own business decisions, are taking down content for a variety of reasons. So while the First Amendment, at least in this country -- and, you know, you mentioned France, but let's -- I'm going to try to stay focused on the area where these companies are incorporated and where the First Amendment applies. They are themselves not respecting it. So how is the First Amendment going to save these companies from themselves if they've had all the opportunity in the world to actually live by the Constitution and make the law leading? They haven't. So I just don't think it's going to save social media companies from themselves. That's right. Well, I believe one of the main challenges that we face both in Europe and in the United States is that currently, these social media companies, the platforms specifically, they enjoy an exception of liability, and this is in our law part of the ecommerce directive. I think it is U.S. §230, for the lawyers in the room. But it basically means that they are claiming under this law that they are the neutral platform. They’re simply just connecting a – Like the phone company, or like eBay, you know. Does eBay know that a stolen car is being sold, for example? No, it would say, “We’re not liable for that. We’re simply connecting the seller and the buyer.” So, this exemption has gone, I think, very, very far, and it is at friction with all kinds of business decisions that the ranking -- that Professor Persily talks about, but also the takedowns that these companies do. So, it is way too narrow to look at the problem that social media companies present only through the First Amendment lens. That is the problem. And then there’s also the right to privacy, which has long been seen in the United States as a European sensitivity, and I think we are right to be sensitive about it, looking at our history. But I see a big awakening in the United States that privacy should be worth something, and so we have to look at the broad spectrum to understand what the threats are that the social media companies –"
for,"Let me lodge a really strong objection to the characterization of the world that the First Amendment creates.  I feel like we’re creating a bit of a strawman that says, “The First Amendment world is anything goes at any time, no matter how awful and horrible.” But we have 200 years of jurisprudence in the United States of America that has established -- there are multiple situations where there are categories of conduct and behavior that are not protected by the First Amendment, such as targeted harassment, such as libel and slander and defamation. We have viewpoint-neutral decency rules that govern the airwaves that are constitutional to prevent children from seeing pornography on broadcast television. So, when we’re talking about the First Amendment, we’re not talking about a strawman First Amendment here. We’re talking about the world we understand and experience, a world that protects people from harassment, that protects people from invasion of privacy, that protects people from libel, slander, and defamation. The cardinal virtue of the Second Amendment is not “anything goes no matter how much of a nightmare it is.” It is viewpoint neutrality. It is that the government is not discriminating amongst viewpoints to determine which viewpoints are going to be privileged and which viewpoints are going to be suppressed. That’s the cardinal rule of the First Amendment. There are time, place, and manner restrictions; there are anti-harassment regulations. But viewpoint neutrality is a cardinal rule, and that’s what the social media companies struggle with so darn much. It took a village of people at Facebook, according to a recent Vanity Fair article, to decide whether feminists could argue, “Men are scum.” Okay? I’ll tell you, I don’t care. If they want to say men are scum, I might either engage, or I might block them. But the idea that we’re going to trust to Silicon Valley executives the determination of how feminists make their case is -- I believe that is what is repugnant to the First Amendment. "
against,"   So, you know, the strategy that I think they’re taking is to narrow the First Amendment to basically 10 percent of First Amendment --"
for,Not to the actual First Amendment.
against,"Well, no, take the -- let’s just talk about anonymity, because that part, I think, really kind of crystallizes the issue, right? This is an area where the government has to respect anonymous speech. In fact, the Federalist Papers, right? Written not too far from here, and Publius as the author.  You know, proud tradition of anonymous speech. It is right for the government to respect anonymity, but it’s anonymity which gives us the bot problem that Marietje talked about. It gives us the foreign interference in elections problem. It gives us the unaccountable hate speech problem online.  Now, again, you can clothe yourselves, as I’m trying to do, in the First Amendment and say that this should be the restriction on government, and in fact, that social media companies, if they want to let everything go, they can, or, just to adopt the First Amendment, they could. But the point is different -- what the First Amendment provides, right, is that each one of these companies, if they want to decide that, hey, we're going to have a different type of environment on our platform, we're not going to allow foreign interference in elections because we're worried about what the impact is going to be. We're not going to allow sort of sexualizing the children and alike. By the way, this is really -- and if I could, just to give you a real concrete example that I just learned about, Reddit. Reddit, which is one of the most libertarian, anything-goes kinds of platforms, has adopted a rule not about child pornography, it's about, you know what? On our platform, you can't sexualize children because what they found was that there were these communities that were developing on Reddit where there were perfectly sort of legal photos, but then the way people were talking about it, right, was really, really scary, right? And to be honest, if a platform wants to allow that kind of speech, they have to right to. But they also have the right to make a decision that that's not appropriate on the platform."
for,"Well, I think that the best way to approach -- there's actually a lot of people who are trying to do research right now to figure out what's the best way to get at the fake news problem. It is not obvious to me that asking Silicon Valley to solve it for us is the right path forward any more than asking Silicon Valley to solve any many, many other problems that we have. Just, if you let me digress just for a second, I notice that Pinterest is now taking down content that's part of the sort of anti-vaccination movement. It seems to me that if you're worried about parents not vaccinating their children, maybe you shouldn't look to Pinterest to fix that problem for you. Maybe there are more effective ways of getting at that issue. And I feel the same way about a lot of the concerns that we have around protecting our elections. If we're worried about protecting democracy and protecting elections, maybe we should be thinking about things like, I don't know, sharing Android or any number of millions of other things that are affecting our elections and perhaps focus a little bit less on this one symptom that we think maybe we can get at by calling Mark Zuckerberg on the carpet and asking him to do more and double down on what is already a completely failed system."
against,"Well, we need much more scrutiny on what the companies are doing already. Call me a passivist, but I don't like to think about armies. I think -- So, but what are the main selectors of what information comes first? This was the gentleman's question as well. And what information shoots to the top or goes down to the bottom is determined by algorithms. These algorithms are extremely influential. I'm the daughter and the sister of a doctor, and I recently saw a sign that I thought was very clear in explaining this, which was in a doctor’s office, saying, “Please don’t confuse your Google search with my medical degree.” And unfortunately, the consequences of these searches are actually not that funny. There are people who think that by drinking olive oil or doing some kind of rain dance to be cured from cancer, even though they are very, very ill. So, I believe that the way in which information is ranked and the deeper impact on our democracy, on our rights -- constitutional rights, universal human rights -- needs to be scrutinized much more, so the oversight over the algorithms, in order to even know what the decisions are that they’re making – -- and whether the intended and unintended consequences are not causing unacceptable harm.   But there . Like the regulator."
for,"I think more transparency would be fantastic. I could not agree more. But I don’t think it changes the outcome of this. What I do think -- what I would say is that rather than -- in answer to your concern, one of the things that was great about the internet is that we didn’t have so many gatekeepers, and that was actually very important and continues to be really important that you don’t have just a few gatekeepers making decisions about what you do and do not see. But picking up on what David said, maybe part of the answer is to ask the social media companies that do have more money than God to take some of that, and rather than investing in an army or a mob or whatever of content moderators that are then going to be psychologically damaged, take that energy and invest it in user tools, in empowering the users to control their own internet experience rather than taking the power unto themselves. I think it’s an enhancement to democracy for -- I think it’s an enhancement to democracy for a couple of reasons. Now, I will say, and I will acknowledge, that social media is a divided place. America is a divided place. It was getting very divided before social media. It’s continuing to be divided. But the fundamental reality is that censorship itself is extraordinarily divisive. Censorship itself generates intense disagreement. Censorship itself can also even generate violence. The problem is when we talk about the dichotomy -- the negative effects of free speech -- and there’s bad political -- there’s been bad political free speech forever. I mean, we act as if bad political speech is created -- is just now creating problems. I mean, they made a musical about a vice president shooting a former secretary of the Treasury in a duel. I mean, this is something that’s been going on for a long time, and the answer is to empower the user, this . It is not to turn to Silicon Valley and say, “Save me from fake news.” It is not to turn Silicon Valley and say, “Save my delicate eyes” when I can press a button and save my eyes myself. This is one of the fundamental problems. When we say -- turn to Silicon Valley and say, “Save me,” what we almost always mean is “punish them.” That’s what we tend to mean. Looking to somebody else to fight our political battle for us, and that is not Silicon Valley’s place."
against,"Again, they make these choices no matter what. Well, the answer is that -- No, but the First -- they cannot respect the First Amendment in the way that they’re proposing here because they are making content-based decisions. Well, it's important to understand that there's more than just the American democracy at stake here, right? There are different democracies around the world that have different values. And so, you know, my personal view is, look, I do take a more Libertarian approach for what I want to see on my feed. But you know what? I go and I go into those dark corners of the internet and I see what people are saying. But you have that right. All this user power that he's talking about, you have that right right now. Sometimes yes, sometimes no. And that is an extremely difficult decision for them, right? So holocaust denial, right, they will take down. Actually, in Egypt, they wouldn't. And they're -- and this is -- you know, they have really difficult choices that they have to make in different situations. Well -- I think the example of Egypt is a very important one because this is not about what social media companies are doing and not doing only. This is the about the rights that protect people. And people in countries where the rule of law does not apply are not protected. Yes, they are subject to all kinds of information that's being shared. Now, I believe very much that sharing more information and having more freedoms is good for democracy, but we should not confuse those rights with the behavior of those companies. And I feel like that is not clear enough in the arguments that the other team are making. I would like to see how social media companies are then actually applying the First Amendment besides the point that people might be empowered because I personally don't think we could put all the responsibility to understand the terms of use of all these tech platforms that would take hours if not days to read for nonlawyers, 16-year-old children, my 80-year-old neighbor alike. I mean, do you understand what you're saying yes to?"
for,"Well, you know, look, the default position of an American company, a social media platform that is seeking in its purpose, its founding purpose of these companies are to provide platforms for people's expression."
against,"No, it's to sell ads."
for,"This is part of the founding purpose of many of these -- of these organizations. That should be their default position. Now, if a law in another country is prohibiting them from following this platform, then they have a choice to make. Do they comply with the law, or do they pull out from that country? And we're passing a lot of these laws, guys, as if these laws are all really -- all the laws out there are laws against holocaust denial.   If you're operating in China, if you're operating in so many other countries, the laws are suppressing dissent in a truly authoritarian and brutal way. And so some of these companies need to make hard choices and say, ""That's just -- you know, the buck is not compatible with the purpose of this platform,"" and pull out. And so that -- we are continually casting censorship. I feel like my worthy opponents here are casting censorship as this beneficially and well-intentioned move. Internationally, censorship is not the same thing as like a bunch of administrators at Brown or Dartmouth trying to figure out a way to make their universities more welcoming. Internationally, censorship is, more often than not, a bunch of authoritarian thugs trying to make sure that they retain a decade's or generation's-long hold on power. So let's not sugar-coat what this is here. And I believe Silicon Valley, if its going to advocate, and if it's going to be a part of trying to foster and cultivate a healthy democracy needs to think long and hard before it's going to operate in some of these countries."
against,"Well -- But just quickly, because they already do, we need to think more about what freedom after speech really means in these countries. What about being incentivized to share all kinds of political opinions on a platform like Facebook, like young people in Syria, Egypt, Turkey do? And then they're on the record, great, because their rights are not protected in those countries. So it is an illusion to think that this is about the companies. It is about the laws in these other countries. And I truly think -- and this is -- this is really beyond sort of the resolution that we're discussing -- that American companies and possibly also the American people do not appreciate sufficiently what the impact is of these company models in countries where human rights are not protected and people can be dragged to prisons, tortured, or killed."
for,"But either way, should they be making the decision? Do you want Mark Zuckerberg to decide for a Syrian journalist whether she is going to take the risk of putting that video online. I don't want Mark Zuckerberg deciding that; I want the journalist deciding it for herself. Of course, she can take that risk. So, I want to speak directly to that point, because I think that speaks to the irony of this whole proposition. We -- let's take it as a given that we don't trust Facebook or any of these other companies very much.  Maybe about as far as we can throw them?  Why in the world, then, do we nonetheless trust them to make good content moderation decisions? Why would we put those things together? Of course, we don't trust them either way, which is why we have to ask them to adhere to a higher standard and demand it."
against,"No, you know, we’re here to bury Facebook, not to praise it. "
for," My job at the Electronic Frontier Foundation is to fight for your digital rights, and there's a reason I do that job. And that’s because I'm still a little bit of an idealist about the internet. Now, I know that a free and open internet -- well, it's never been fully free, and it's never been fully open, so that's an ongoing project. But still the internet represents an extraordinary, extraordinary idea that anyone with a computing device can connect to anyone else around the world to speak, to be heard, and to learn. Private censorship is fundamentally incompatible with that idea, but if the social media platforms are going to insist on putting themselves in the role of judge and jury, drawing lines between what speech is okay and what speech is not. Then it seems to me that at the very least, they could be looking to the work of judges who have struggled for years to figure out exactly -- to draw those lines for themselves and for the nation. Again, what we are saying here is they should look to First Amendment principles to guide their conduct. My opponents had said, ""I wish that they would apply the First Amendment. They never have."" Well, exactly. Maybe they should start. Maybe they should start. Maybe they should make that choice. Just a few months ago, in the Packingham case, the Supreme Court observed that social media can provide the most powerful mechanism available to a private citizen to make his or her voice heard. That's extraordinary. Now, we're here in the Constitution Center, a very special place. It seems to me that in this place, in this center devoted to Constitutional principles, it would be very strange for us to decide that powerful corporations shouldn't respect those principles when they are deciding whose voices will be heard and what those voices can say. I urge you to support the motion. "
against,"So, an old law professor once said that when the facts are on your side, you pound the facts. When the law is on your side, you pound the law. When neither is on your side, you pound the table, right? I kind of think that our opponents are pounding the table here a little bit, right? To bring the specter of China, to bring up the specter of these censors as if that is what we are arguing for is really misrepresenting the argument, okay? The facts and the law are on our side. So if you look at the facts of what is happening out there, the internet is this incredible, liberating technology that allows people to talk to anyone around the world, right? It also has these deep, dark spaces. You can choose what space you want to be in. The question is, should these companies be serving up this kind of information to you at the top of your news feed, at the top of your Twitter feed and the like? Now, again, you can choose to go into Gab, you can choose to go into Twitter. David French is wrong that each one of these platforms has said what they're about is providing free speech opportunities for every person around the world and the like. That actually is Twitter's principle position, that they are trying to allow individuals to broadcast everywhere around the world. And you know? For what reason, they have an anonymity policy. They have 10 to 15 percent of their accounts are bots and the like. Facebook actually has a different mission, so does Google, right? These companies, they decide, you know what? We're going to build transnational safe communities and the like, something along those lines. Now, it's not as if the resolution forces us in the position of saying, yes, Mark Zuckerberg should censor Republicans, right? That's not what we're arguing here. We are simply saying that the same rules that apply to governments are not the rules that should apply to platforms. And so that's why I focus in the rebuttal on anonymity, right? We all agree that anonymity is Constitutionally protected. But if you are going to get at any of the problems that we all agree are happening online, whether it's foreign election interference, hate speech, right, bots that are essentially polluting the marketplace of ideas, you cannot respect the Constitutional right of anonymity in online conversations. The final point, and one that Marietje I think made very well, which is that you cannot just think of these as American platforms with an American audience. 80 percent of Facebook users are outside the United States. It's wrong for this company to then export its values to the rest of the world."
for,"So let's be really clear here. My worthy opponent said he came to bury these companies, not to praise them. It is a very odd method of burying them to grant them greater power over your speech, to grant them greater authority over the reach of your words. We're talking about companies that, in many ways, have demonstrated their untrustworthiness not just with your privacy, but with your voice. That is not burying the company. That is empowering a company. If you vote ""no"" on this resolution, if you vote ""no"" on this resolution, you're voting yes to a committee somewhere -- no, that's best case. Real world, you're voting yes to a person who's in a cubicle somewhere halfway across the country looking at pictures and deciding with a click of a mouse, ""yes,"" ""no,"" after a PowerPoint training in community standards who’s maybe seen enough weird stuff that they’re now a flat-earther. That was actually a report recently. Some of these content moderators are now flat-earthers and 9/11 truthers, and they're deciding whether you get to speak.   The bottom line is the person who decides whether you speak or not should be you. You do -- you have the power to see what you want to see on social media. You should also have the power to say what you want to say on social media, and if you don't like what's out there, the answer is to mute. The answer is to block, or, God forbid, shut down the app or put down the phone. Now, I can't do that as a journalist. I'm just hopelessly addicted. But that is something that you have in your power. The last thing that you should do when troubled by speech is to turn to Silicon Valley and say, “Help me, Mark Zuckerberg, you're our only hope.” And that's why you should vote for viewpoint neutrality and say yes to this motion."
against,"I think from everything we've heard from both sides, it is safe to conclude that technology is not neutral and that no one wants censorship, at least not here in either one of the teams, or that a minister of truth, so to say, would be a very bad idea, and I appreciate your concerns about that even more with a president who calls out journalists as being of the fake news media on a daily basis. But there are many places in the world where we should be very concerned about the notion of a minister of truth. So, then why would we have effectively except that someone like Mark Zuckerberg, but the other CEOs of the other social media companies are in a position of power to operate with their business models like ministers of truth? And this is far beyond free speech and the First Amendment. We're talking about the collection of data, the selling of data, the micro-targeting of people with ads to categories such as fans or interested in Josef Goebbels or having searched for information about depression and suicide. So, what I find baffling and unacceptable is that these companies, on the one hand, have made billions and billions of dollars by perfecting the targeting of ads to people on the basis of ever more precise categories, and yet they claim, “How can we be part of preventing conspiracies and all kinds of lies that jeopardize the public health, for example, to go from spreading around, or child pornography for that matter?” The reason why they do not want to engage in it is that it would make them liable, and if they would be liable, their entire business would be over. And the idea that it should be all the responsibility of the individual -- anyone from you all -- to decide what you want to see, what you want to engage in, what you don't want to engage in to what we heard is the responsibility of the Syrian journalist to want to engage or not -- I believe that people are not informed enough currently to know what they're saying yes to, and in fact, these companies have violated agreements by selling and collecting data invisibly all the time. So, I think it is safe to say that people don't know enough to make informed decisions; that this is not only about free speech and the First Amendment, but about much more; and that certainly we can conclude that the First Amendment cannot save social media companies from themselves. So, I urge you to vote against the motion.  Well, I think one of the problem -- I am worried about, because the social media companies have dropped the ball on getting at some issues like foreign interference, that then the governments are going to overreach, right, and really have an impact on free speech online. And we are seeing that around the world, where -- that the governments are then saying, well, our Facebook isn't able to clean up this mess, so therefore they're going to pass real -- whether it's viewpoint-based discrimination or something else like that. So I am concerned about that. You know, at the risk of getting too complicated here, all the different areas of law that regulate the internet intersect with each other. So whether you're talking about antitrust, you're talking about privacy or you're talking about these content moderation issues, I actually think Europe may be the tail that wags the American dog here a little bit, and so the decisions that Marietje makes is going to be very important. Well, we -- We also have elections, and the concerns are actually very, very similar. And what we see is that a number of these social media companies are now coming out with some initial measures of, for example, making transparent who is buying political ads. Well, hallelujah. You know, that should not be rocket science, frankly. I mean, if you want to put an ad in the newspaper, it should be identifiable as an ad, not as a report. And if it's a political message, I believe especially also here in the U.S., you get some kind of notification that this is approved by the super Pac of whichever side. And so, this kind of transparency, I believe, is a first step. But it doesn't even begin to touch on the impact of the business models and the algorithms that I mentioned earlier that we don't know enough about. So I believe algorithmic accountability will be coming, and I also believe that this exemption from liability that I briefly mentioned to you is going to come under a lot of pressure in both U.S. and the E.U. because it simply doesn't add up anymore."
for,"Well, so a couple things. One thing I see most immediately is that a bunch of the major companies desperate to avoid regulation are going to be ever more aggressive in their content moderation in the hopes that somehow that that will stave off the regulators. And I think that effort's going to fail. But nonetheless, that's what we're going to see immediately. What I would like to see, or what it is I worry about is that we are going to have regulations proposed here and abroad that are going to backfire in the sense not just that they might be too heavy handed and shut down certain kinds of speech, but also that may be difficult to comply with. And what that's going to mean is that only the big companies like Facebook, like Google can afford to comply with whatever the new regulations are and put in place all the, you know, filtering mechanisms or whatever that they have to. And that means we're going to be stuck with only Facebook and Google, you know, for time immemorial, like I want the next Google, I want the next Pinterest, I want the next YouTube, I want all -- you know, a thousand flowers to bloom so that people can really choose between more and less moderated forums. But you can only do that if you actually have those choices out there. Yeah, you know, I think that the danger of government overreach is very big, but I think that one of the problems that we have here is that social media has put human nature on blast. So, we're able to see our fellow citizens’ political perspective more readily and easily than we ever have in the past, and a shocking number of people are -- find it compelling that there's -- when they see in the name of Jesus arm-wrestling Satan, you know, or when they see a news story that, if you're somebody who's closely and carefully engaged in the process, seems to you to be facially ridiculous that they find extremely compelling. And what this has done is expose a massive problem we have in this country on two fronts: polarization and civic ignorance. And so, social media is not going to fix that, and we keep trying to look to social media to say, “Do something about all the crappy memes.” You know, “Do something about this ridiculous news story.” But the problem here is us, more broadly. It's the failure of civic education; it's the rise of contempt and hate, all of these things that long predated social media. And that's why, you know, I feel like the government is going to come in some of these regulatory efforts and say, “Well, human nature has been put on blast. We're going to have to tamp it down in some way.” terrible at that."
